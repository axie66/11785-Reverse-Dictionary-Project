{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit7cbf060f8ed4487591d975d6fad0a650",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "049faeb3947c48ac1b8702363c1a3bc597f6c2e1e1396be70d54511d980ab606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append('../code')\n",
    "from dataset import get_data, MaskedDataset, make_vocab\n",
    "\n",
    "from transformers import (\n",
    "    AdamW, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from models import MaskedRDModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in /Users/axie/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing MaskedRDModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing MaskedRDModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing MaskedRDModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MaskedRDModel.from_pretrained('bert-base-uncased')\n",
    "model.set_mask_size(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data...\n",
      "Training data: 675715 word-def pairs\n",
      "Dev data: 75873 word-def pairs\n",
      "Test data: 1200 word-def pairs\n"
     ]
    }
   ],
   "source": [
    "d = get_data('../wantwords-english-baseline/data', word2vec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_def, dev_data, test_data_seen, \\\n",
    "    test_data_unseen, test_data_desc = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_matrix, target2idx, idx2target = make_vocab(d, tokenizer, mask_size=5)\n",
    "train_dataset = MaskedDataset(train_data, tokenizer, target2idx, target_matrix, mask_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16187, tensor([2338,  103,  103,  103,  103]))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# target2idx maps target words to indices\n",
    "# target_matrix maps target indices to bpe sequences, padded/truncated to mask_size\n",
    "target2idx['book'], target_matrix[target2idx['book']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[100]\n",
    "x = x.unsqueeze(0)\n",
    "attention_mask = x > 0\n",
    "\n",
    "batchX, batchY = train_dataset.collate_fn([train_dataset[i] for i in range(40, 42)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  101,   103,   103,   103,   103,   103,   102,  2008,  2029,  3310,\n",
       "          2013, 19610,  2361,  1999,  1996,  2832,  1997, 11300, 18809,  2290],\n",
       "        [  101,   103,   103,   103,   103,   103,   102,  2000,  3395,  2000,\n",
       "          2019,  2552,  1997,  2061,  9527,  2100,  2926, 20951,     0,     0]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "batchX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matrix = torch.stack(target_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids=batchX, attention_mask=batchX > 0, target_matrix=target_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50477])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([4128])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "torch.argmax(out.sum(dim=1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unicyclist\n"
     ]
    }
   ],
   "source": [
    "for w in target2idx:\n",
    "    if target2idx[w] == 23413:\n",
    "        break\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] [SEP] characterized by three colors in a specific sense having the three fundamental color sensations of red green and purple as the normal eye in distinction from a color blind eye which can perceive only two of the fundamental colors'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(x[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedRD(nn.Module):\n",
    "    def __init__(self, )"
   ]
  }
 ]
}