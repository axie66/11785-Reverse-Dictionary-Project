{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import torchtext\n",
    "except ImportError:\n",
    "    sys.path.append('/usr/local/lib/python3.8/site-packages/')\n",
    "    import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_path = '../data/dictionary/reverse-dict-singleton.tsv'\n",
    "\n",
    "glove_embed_dim = 300 # other options are 100, 200, 300\n",
    "glove_embed_path = f'../data/glove_embed/glove.6B.{glove_embed_dim}d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary data\n",
    "# Assuming the .tsv files from Prof Oflazer are placed in the data/dictionary folder\n",
    "dict_data = pd.read_csv(dict_data_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 400000/400001 [00:11<00:00, 35331.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained GloVe embeddings\n",
    "# Download them from http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# and place them in the data/glove_embed folder\n",
    "glove_embed = torchtext.vocab.Vectors(glove_embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3170)\n",
      "tensor(16.4342)\n"
     ]
    }
   ],
   "source": [
    "s, p = glove_embed.get_vecs_by_tokens(['ice', 'gorilla'])\n",
    "print(s @ p)\n",
    "\n",
    "d, p = glove_embed.get_vecs_by_tokens(['ice', 'cold'])\n",
    "print(d @ p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, definitions, embeddings, embedding_dim, tokenizer=None):\n",
    "        super(DictDataset, self).__init__()\n",
    "        if tokenizer is None:\n",
    "            tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        f = lambda x: not torch.all(embeddings.get_vecs_by_tokens([x]) == 0)\n",
    "        # Filter out words that do not have embeddings\n",
    "        self.definitions = definitions.loc[definitions[0].apply(f)]\n",
    "        self.definitions.index = pd.RangeIndex(len(self.definitions.index))\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        word, def_text = self.definitions.loc[i] # definition, in plain text form\n",
    "        tokens = self.tokenizer(def_text)\n",
    "        return self.embeddings.get_vecs_by_tokens(tokens), self.embeddings.get_vecs_by_tokens([word]).squeeze()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.definitions)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        batch.sort(key=lambda elem: len(elem[0]), reverse=True)\n",
    "        Xs = [x for x, _ in batch]\n",
    "        Ys = ([y for _, y in batch])\n",
    "        return (torch.nn.utils.rnn.pack_sequence(Xs), \n",
    "                torch.stack(Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DictDataset(dict_data, glove_embed, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000th</td>\n",
       "      <td>the ordinal number of one thousand in counting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100th</td>\n",
       "      <td>the ordinal number of one hundred in counting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>being one more than one hundred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101st</td>\n",
       "      <td>the ordinal number of one hundred one in count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>being five more than one hundred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30821</th>\n",
       "      <td>winterize</td>\n",
       "      <td>prepare for winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30822</th>\n",
       "      <td>woosh</td>\n",
       "      <td>move with a sibilant sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30823</th>\n",
       "      <td>wreak</td>\n",
       "      <td>cause to happen or to occur as a consequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30824</th>\n",
       "      <td>wrest</td>\n",
       "      <td>obtain by seizing forcibly or violently, also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30825</th>\n",
       "      <td>writhe</td>\n",
       "      <td>to move in a twisting or contorted motion, (es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                                                  1\n",
       "0         1000th  the ordinal number of one thousand in counting...\n",
       "1          100th  the ordinal number of one hundred in counting ...\n",
       "2            101                    being one more than one hundred\n",
       "3          101st  the ordinal number of one hundred one in count...\n",
       "4            105                   being five more than one hundred\n",
       "...          ...                                                ...\n",
       "30821  winterize                                 prepare for winter\n",
       "30822      woosh                         move with a sibilant sound\n",
       "30823      wreak       cause to happen or to occur as a consequence\n",
       "30824      wrest  obtain by seizing forcibly or violently, also ...\n",
       "30825     writhe  to move in a twisting or contorted motion, (es...\n",
       "\n",
       "[30826 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(data, shuffle=True, batch_size=16, collate_fn=DictDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4699)\n",
      "100 tensor(0.4191)\n",
      "200 tensor(0.3966)\n",
      "300 tensor(0.4262)\n",
      "400 tensor(0.3349)\n",
      "500 tensor(0.3054)\n",
      "600 tensor(0.3089)\n",
      "700 tensor(0.3683)\n",
      "800 tensor(0.3783)\n",
      "900 tensor(0.3236)\n"
     ]
    }
   ],
   "source": [
    "# The below code is attempting to learn the word embedding from \n",
    "# the definition, which isn't exactly what we want to do\n",
    "model = torch.nn.LSTM(50, 50)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.train()\n",
    "for i, (x, y) in zip(range(1000), loader):\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    out, (h,c) = model(x)\n",
    "    (out_pad, out_lengths) = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "    \n",
    "    out_embeds = torch.stack(list(out_pad[j] for j in zip(out_lengths-1, range(len(out_lengths)))))\n",
    "    \n",
    "    loss = criterion(out_embeds, y)\n",
    "    if i % 100 == 0:\n",
    "        print(i, loss.detach())\n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (h,c) = model(x)\n",
    "(out_pad, out_lengths) = torch.nn.utils.rnn.pad_packed_sequence(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 50, 100]),\n",
       " tensor([40, 36, 33, 24, 24, 23, 21, 21, 20, 19, 19, 19, 17, 16, 16, 15, 15, 14,\n",
       "         14, 14, 13, 13, 12, 11, 11, 11, 11,  9,  9,  9,  9,  9,  8,  8,  8,  7,\n",
       "          6,  6,  6,  6,  6,  5,  5,  5,  5,  4,  3,  3,  2,  2]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pad.shape, out_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in list(zip(out_lengths-1, range(len(out_lengths)))):\n",
    "    r = out_pad[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit7cbf060f8ed4487591d975d6fad0a650"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
