{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append('../code')\n",
    "from dataset import get_data, MaskedDataset, make_vocab, read_json\n",
    "\n",
    "from transformers import (\n",
    "    AdamW, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from models import MaskedRDModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training data: 675715 word-def pairs\n",
      "Dev data: 75873 word-def pairs\n",
      "Test data: 1200 word-def pairs\n"
     ]
    }
   ],
   "source": [
    "d = get_data('../wantwords-english-baseline/data', word2vec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_def, dev_data, test_data_seen, \\\n",
    "    test_data_unseen, test_data_desc = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_size = 5\n",
    "target_matrix, target2idx, idx2target = make_vocab(d, tokenizer, mask_size=mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing MaskedRDModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing MaskedRDModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MaskedRDModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MaskedRDModel.from_pretrained('bert-base-uncased')\n",
    "model.initialize(mask_size=mask_size, multilabel=True, ww_vocab_size=len(target2idx), pos_weight=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16187, tensor([2338,  103,  103,  103,  103]), 'book')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target2idx maps target words to indices\n",
    "# target_matrix maps target indices to bpe sequences, padded/truncated to mask_size\n",
    "target2idx['book'], target_matrix[target2idx['book']], idx2target[target2idx['book']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_data = read_json('../data/wn_data.json')\n",
    "wn_categories = ['synonyms', 'hyponyms', 'hypernyms', 'related_forms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MaskedDataset(train_data + train_data_def, tokenizer, target2idx, wn_data=wn_data, wn_categories=wn_categories, mask_size=mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = MaskedDataset(dev_data, tokenizer, target2idx, \n",
    "                            wn_data=wn_data, wn_categories=wn_categories, mask_size=mask_size)\n",
    "test_dataset_seen = MaskedDataset(test_data_seen, tokenizer, target2idx, \n",
    "                                  wn_data=wn_data, wn_categories=wn_categories, mask_size=mask_size)\n",
    "test_dataset_unseen = MaskedDataset(test_data_unseen, tokenizer, target2idx, \n",
    "                                    wn_data=wn_data, wn_categories=wn_categories, mask_size=mask_size)\n",
    "test_dataset_desc = MaskedDataset(test_data_desc, tokenizer, target2idx, \n",
    "                                  wn_data=wn_data, wn_categories=wn_categories, mask_size=mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['classic',\n",
       "  'authorized',\n",
       "  'importance',\n",
       "  'authoritative',\n",
       "  'classical',\n",
       "  'definitive',\n",
       "  'important'],\n",
       " 'authoritative')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1593\n",
    "\n",
    "[idx2target[x] for x in dev_dataset[index][-1].coalesce().indices().squeeze(0)], idx2target[dev_dataset[index][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 0\n",
    "\n",
    "loader_params = {\n",
    "    'pin_memory': False,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'collate_fn': train_dataset.collate_fn\n",
    "}\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, **{'shuffle': True, **loader_params})\n",
    "dev_loader = data.DataLoader(dev_dataset, **{'shuffle': True, **loader_params})\n",
    "test_loader_seen = data.DataLoader(test_dataset_seen, **{'shuffle': False, **loader_params})\n",
    "test_loader_unseen = data.DataLoader(test_dataset_unseen, **{'shuffle': False, **loader_params})\n",
    "test_loader_desc = data.DataLoader(test_dataset_desc, **{'shuffle': False, **loader_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from epoch 2\n",
    "# weight_gt = 10\n",
    "# epochs = 9\n",
    "# lr = 1e-5 * 0.905\n",
    "# optim = AdamW(model.parameters(), lr=lr)\n",
    "# scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=1, \n",
    "#                                             num_training_steps=len(train_loader) * epochs)\n",
    "# epoch = 0\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "lr = 3e-5\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "warmup_duration = 0.05 # portion of the first epoch spent on lr warmup\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=len(train_loader) * warmup_duration, \n",
    "                                            num_training_steps=len(train_loader) * epochs)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_gt = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreverse-dict\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glorious-sunset-95</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary/runs/2zphjffh\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary/runs/2zphjffh</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/dl/11785-Reverse-Dictionary-Project/notebooks/wandb/run-20210506_144027-2zphjffh</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='reverse-dictionary', entity='reverse-dict')\n",
    "\n",
    "config = wandb.config\n",
    "config.learning_rate = lr\n",
    "config.epochs = epochs\n",
    "config.batch_size = batch_size\n",
    "config.optimizer = type(optim).__name__\n",
    "config.scheduler = type(scheduler).__name__\n",
    "# config.warmup_duration = warmup_duration\n",
    "\n",
    "# wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matrix = target_matrix.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, gt, test=False):\n",
    "    acc1 = acc10 = acc100 = 0\n",
    "    n = len(pred)\n",
    "    pred_rank = []\n",
    "    for p, word in zip(pred, gt):\n",
    "        if test:\n",
    "            loc = (p == word).nonzero(as_tuple=True)\n",
    "            if len(loc) != 0:\n",
    "                pred_rank.append(min(loc[-1], 1000))\n",
    "            else:\n",
    "                pred_rank.append(1000)\n",
    "        if word in p[:100]:\n",
    "            acc100 += 1\n",
    "            if word in p[:10]:\n",
    "                acc10 += 1\n",
    "                if word == p[0]:\n",
    "                    acc1 += 1\n",
    "    if test:\n",
    "        pred_rank = torch.tensor(pred_rank, dtype=torch.float32)\n",
    "        return (acc1, acc10, acc100, pred_rank)\n",
    "    else:\n",
    "        return acc1/n, acc10/n, acc100/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, name, log=False):\n",
    "    inc = 3\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc1 = test_acc10 = test_acc100 = test_rank_median = test_rank_variance = 0.0\n",
    "    total_seen = 0\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(loader)) as pbar:\n",
    "            for i, (x,y, wn_ids) in enumerate(loader):\n",
    "                if i % inc == 0 and i != 0:\n",
    "                    display_loss = test_loss / i\n",
    "                    pbar.set_description(f'Test Loss: {display_loss}')\n",
    "\n",
    "                x = x.to(device)\n",
    "                attention_mask = (x != train_dataset.pad_id)\n",
    "                y = y.to(device)\n",
    "                wn_ids = wn_ids.to_dense().to(device).float()\n",
    "\n",
    "#                 with autocast():\n",
    "                loss, out = model(input_ids=x, attention_mask=attention_mask, \n",
    "                                  target_matrix=target_matrix, ground_truth=y,\n",
    "                                  wn_ids=wn_ids, weight_gt=weight_gt)\n",
    "\n",
    "                test_loss += loss.detach()\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "                result, indices = torch.sort(out, descending=True)\n",
    "                \n",
    "                b = len(x)\n",
    "                acc1, acc10, acc100, pred_rank = evaluate(indices, y, test=True)\n",
    "                test_acc1 += acc1\n",
    "                test_acc10 += acc10\n",
    "                test_acc100 += acc100\n",
    "                total_seen += b\n",
    "                all_pred.extend(pred_rank)\n",
    "                \n",
    "                del x, y, out, loss\n",
    "                if i % 20 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "    test_loss /= len(loader)\n",
    "    test_acc1 /= total_seen\n",
    "    test_acc10 /= total_seen\n",
    "    test_acc100 /= total_seen\n",
    "    all_pred = torch.tensor(all_pred)\n",
    "    median = torch.median(all_pred)\n",
    "    var = torch.var(all_pred)**0.5\n",
    "    \n",
    "    print(f'{name}_test_loss:', test_loss)\n",
    "    print(f'{name}_test_acc1:', test_acc1)\n",
    "    print(f'{name}_test_acc10:', test_acc10)\n",
    "    print(f'{name}_test_acc100:', test_acc100)\n",
    "    print(f'{name}_test_rank_median:', median)\n",
    "    print(f'{name}_test_rank_variance', var)\n",
    "    \n",
    "    return {\n",
    "            f'{name}_test_loss': test_loss,\n",
    "            f'{name}_test_acc1': test_acc1,\n",
    "            f'{name}_test_acc10': test_acc10,\n",
    "            f'{name}_test_acc100': test_acc100,\n",
    "            f'{name}_test_rank_median': median,\n",
    "            f'{name}_test_rank_variance': var\n",
    "           }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training beginning!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a9c33c24ff44b9a848730af96073be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inc = 10\n",
    "losses = []\n",
    "print('Training beginning!')\n",
    "\n",
    "for p in optim.param_groups:\n",
    "    p['lr'] = 1e-5\n",
    "    \n",
    "warmup_duration = 0.05 # portion of the first epoch spent on lr warmup\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=len(train_loader) * warmup_duration, \n",
    "                                            num_training_steps=len(train_loader) * epochs)\n",
    "\n",
    "for epoch in range(epoch, epochs + 10):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    # Train on subset of training data to save time\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, (x, y, wn_ids) in enumerate(train_loader):\n",
    "            if i % inc == 0 and i != 0:\n",
    "                display_loss = train_loss / i\n",
    "                pbar.set_description(f'Epoch {epoch+1}, Train Loss: {train_loss / i}')\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            attention_mask = (x != train_dataset.pad_id)\n",
    "            y = y.to(device)\n",
    "            wn_ids = wn_ids.to_dense().to(device).float()\n",
    "            \n",
    "            loss, out = model(input_ids=x, attention_mask=attention_mask, \n",
    "                              target_matrix=target_matrix, ground_truth=y, \n",
    "                              wn_ids=wn_ids, weight_gt=weight_gt)\n",
    "            \n",
    "#             scaler.scale(loss).backward()\n",
    "            loss.backward()\n",
    "            \n",
    "#             scaler.unscale_(optim)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            \n",
    "#             scaler.step(optim)\n",
    "            optim.step()\n",
    "#             scaler.update()\n",
    "            \n",
    "            train_loss += loss.detach()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            del x, y, out, loss, attention_mask\n",
    "            \n",
    "    model_name = type(model).__name__\n",
    "    filename = f'../trained_models/{model_name} Epoch {epoch+1} at {datetime.datetime.now()}'.replace(' ', '_')\n",
    "    with open(filename, 'wb+') as f:\n",
    "        torch.save(model, f)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc1, val_acc10, val_acc100 = 0.0, 0.0, 0.0\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=len(dev_loader)) as pbar:\n",
    "                for i, (x, y, wn_ids) in enumerate(dev_loader):\n",
    "                    if i % inc == 0 and i != 0:\n",
    "                        display_loss = val_loss / i\n",
    "                        pbar.set_description(f'Epoch {epoch+1}, Val Loss: {val_loss / i}')\n",
    "\n",
    "                    x = x.to(device)\n",
    "                    attention_mask = (x != train_dataset.pad_id)\n",
    "                    y = y.to(device)\n",
    "                    wn_ids = wn_ids.to_dense().to(device).float()\n",
    "\n",
    "    #                 with autocast():\n",
    "                    loss, out = model(input_ids=x, attention_mask=attention_mask, \n",
    "                                      target_matrix=target_matrix, ground_truth=y,\n",
    "                                      wn_ids=wn_ids, weight_gt=weight_gt)\n",
    "\n",
    "                    val_loss += loss.detach()\n",
    "\n",
    "                    pbar.update(1)                \n",
    "\n",
    "                    result, indices = torch.topk(out, k=100, dim=-1, largest=True, sorted=True)\n",
    "\n",
    "                    acc1, acc10, acc100 = evaluate(indices, y)\n",
    "                    val_acc1 += acc1\n",
    "                    val_acc10 += acc10\n",
    "                    val_acc100 += acc100\n",
    "\n",
    "                    del x, y, out, loss\n",
    "    except:\n",
    "        print('Error encountered, aborting validation!')\n",
    "    \n",
    "    wandb.log({\n",
    "        'train_loss': train_loss / len(train_loader),\n",
    "        'val_loss': val_loss / len(dev_loader),\n",
    "        'val_acc1': val_acc1 / len(dev_loader),\n",
    "        'val_acc10': val_acc10 / len(dev_loader),\n",
    "        'val_acc100': val_acc100 / len(dev_loader),\n",
    "        **test(test_loader_seen, 'seen'),\n",
    "        **test(test_loader_unseen, 'unseen'),\n",
    "        **test(test_loader_desc, 'desc')\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredFromDesc(model, desc : str, mask_size=5, top_n=10):\n",
    "    desc = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(desc))\n",
    "    cls_id, mask_id, sep_id, pad_id = train_dataset.cls_id, train_dataset.mask_id, train_dataset.sep_id, train_dataset.pad_id\n",
    "    desc_ids = [cls_id] + [mask_id] * mask_size + [sep_id] + desc\n",
    "    x = torch.tensor(desc_ids).unsqueeze(0).to(device)\n",
    "    attention_mask = (x != pad_id)\n",
    "    out = model(input_ids=x, attention_mask=attention_mask, target_matrix=target_matrix)\n",
    "    result, indices = torch.topk(out, k=top_n, dim=-1, largest=True, sorted=True)\n",
    "    \n",
    "    indices = indices[0]\n",
    "    return [idx2target[i] for i in indices], indices, torch.sigmoid(result).squeeze(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../trained_models/MaskedRDModel_Epoch_1_at_2021-05-06_16:31:58.058170')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    (\"employee at a circus\", \"clown\"),\n",
    "    (\"a type of tree\", None), # type\n",
    "    (\"the opposite of being happy\", None), # type\n",
    "    (\"a road on which cars can go fast\", \"highway\"),\n",
    "    (\"a very intelligent person\", \"genius\"),\n",
    "    (\"a very smart person\", \"genius\"),\n",
    "    (\"something you use to measure your temperature\", \"thermometer\"),\n",
    "    (\"a dark time of day\", \"night\"),\n",
    "    (\"medieval social hierarchy where peasants and vassals served lords\", \"feudalism\"),\n",
    "    (\"very cute\", \"adorable\"),\n",
    "    (\"\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('circus', 0.994208812713623),\n",
       " ('clown', 0.9391021728515625),\n",
       " ('clowning', 0.7502662539482117),\n",
       " ('stampede', 0.6639121174812317),\n",
       " ('busker', 0.6302651762962341),\n",
       " ('barker', 0.6152220368385315),\n",
       " ('somebody', 0.6016197800636292),\n",
       " ('showman', 0.591995358467102),\n",
       " ('jockey', 0.5682175159454346),\n",
       " ('ringer', 0.5543749928474426),\n",
       " ('ride', 0.512154221534729),\n",
       " ('scouter', 0.5062361359596252),\n",
       " ('performer', 0.491067111492157),\n",
       " ('handler', 0.4897576868534088),\n",
       " ('bulldozer', 0.45466405153274536),\n",
       " ('bullfighter', 0.4532380700111389),\n",
       " ('valet', 0.44002220034599304),\n",
       " ('bullhorn', 0.42381030321121216),\n",
       " ('theatergoer', 0.4092405438423157),\n",
       " ('exhibitor', 0.38998040556907654),\n",
       " ('gypsy', 0.3890130817890167),\n",
       " ('clownish', 0.3867891728878021),\n",
       " ('rider', 0.38242051005363464),\n",
       " ('crowder', 0.3685600459575653),\n",
       " ('flapper', 0.35859018564224243),\n",
       " ('comedian', 0.35737788677215576),\n",
       " ('equestrian', 0.3531621992588043),\n",
       " ('show', 0.34194135665893555),\n",
       " ('pincher', 0.3402089476585388),\n",
       " ('manipulator', 0.33921095728874207),\n",
       " ('ringleader', 0.33914896845817566),\n",
       " ('trouper', 0.3377748131752014),\n",
       " ('ringette', 0.32697921991348267),\n",
       " ('treater', 0.32337069511413574),\n",
       " ('conductor', 0.3223282992839813),\n",
       " ('grenadier', 0.31733712553977966),\n",
       " ('soul', 0.31627383828163147),\n",
       " ('gazpacho', 0.31200695037841797),\n",
       " ('impresario', 0.3090837895870209),\n",
       " ('carter', 0.30822089314460754),\n",
       " ('monkey', 0.30591028928756714),\n",
       " ('dragger', 0.30529388785362244),\n",
       " ('jobber', 0.30330365896224976),\n",
       " ('checker', 0.300991028547287),\n",
       " ('coiffeur', 0.2999979555606842),\n",
       " ('athlete', 0.28793999552726746),\n",
       " ('trainer', 0.2836650609970093),\n",
       " ('trombonist', 0.28023242950439453),\n",
       " ('person', 0.27701535820961),\n",
       " ('glamor', 0.2740058898925781),\n",
       " ('tenter', 0.2734309136867523),\n",
       " ('ring', 0.2731703817844391),\n",
       " ('parade', 0.2680269479751587),\n",
       " ('exponent', 0.25921541452407837),\n",
       " ('rollercoaster', 0.2584560215473175),\n",
       " ('mounter', 0.2575189769268036),\n",
       " ('crusher', 0.2552032172679901),\n",
       " ('placental', 0.25483858585357666),\n",
       " ('comic', 0.25367602705955505),\n",
       " ('showpiece', 0.2516440451145172),\n",
       " ('gringo', 0.250478059053421),\n",
       " ('dragster', 0.24694333970546722),\n",
       " ('horseman', 0.2442835122346878),\n",
       " ('puncher', 0.24284707009792328),\n",
       " ('scout', 0.2364911586046219),\n",
       " ('coworker', 0.2361314296722412),\n",
       " ('attendant', 0.22994273900985718),\n",
       " ('gatekeeper', 0.22841966152191162),\n",
       " ('mongo', 0.22350634634494781),\n",
       " ('castor', 0.2200533002614975),\n",
       " ('gogo', 0.21401554346084595),\n",
       " ('beefeater', 0.21385285258293152),\n",
       " ('butcher', 0.2130337506532669),\n",
       " ('fixer', 0.21185921132564545),\n",
       " ('chaperon', 0.21179446578025818),\n",
       " ('troupe', 0.21000555157661438),\n",
       " ('journeyman', 0.2089369297027588),\n",
       " ('job', 0.207253560423851),\n",
       " ('guy', 0.206063911318779),\n",
       " ('artisanal', 0.2046981304883957),\n",
       " ('jockeying', 0.2040598839521408),\n",
       " ('cubist', 0.20187290012836456),\n",
       " ('ratter', 0.20162111520767212),\n",
       " ('showstopper', 0.2001991719007492),\n",
       " ('veterinarian', 0.19976288080215454),\n",
       " ('policeman', 0.1983133852481842),\n",
       " ('noncombatant', 0.19821158051490784),\n",
       " ('hackney', 0.1965937316417694),\n",
       " ('placebo', 0.19600729644298553),\n",
       " ('stopper', 0.1957201361656189),\n",
       " ('bus', 0.1951250433921814),\n",
       " ('fagot', 0.19075734913349152),\n",
       " ('flurry', 0.18739615380764008),\n",
       " ('picador', 0.1872551292181015),\n",
       " ('jester', 0.18353545665740967),\n",
       " ('zookeeper', 0.1818380504846573),\n",
       " ('groomer', 0.1811385452747345),\n",
       " ('bodyguard', 0.1809312254190445),\n",
       " ('act', 0.18030954897403717),\n",
       " ('exhibitionist', 0.1779281347990036)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'employee at a circus', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linden', 0.8909744024276733),\n",
       " ('tree', 0.8873805403709412),\n",
       " ('stocked', 0.8616869449615479),\n",
       " ('lime', 0.8452991247177124),\n",
       " ('teakwood', 0.8133090138435364),\n",
       " ('chestnut', 0.7823934555053711),\n",
       " ('maple', 0.7769330143928528),\n",
       " ('plum', 0.7707264423370361),\n",
       " ('wood', 0.7617564797401428),\n",
       " ('shrub', 0.7613511681556702),\n",
       " ('hop', 0.760560154914856),\n",
       " ('cottonwood', 0.7386062145233154),\n",
       " ('cypress', 0.7183142900466919),\n",
       " ('oak', 0.7154815793037415),\n",
       " ('spruce', 0.6588332056999207),\n",
       " ('pinewood', 0.6537127494812012),\n",
       " ('olive', 0.6344695687294006),\n",
       " ('brazilwood', 0.6344084739685059),\n",
       " ('ebony', 0.6217503547668457),\n",
       " ('boxwood', 0.6095532178878784),\n",
       " ('mahogany', 0.5943478941917419),\n",
       " ('treed', 0.5928893685340881),\n",
       " ('coffee', 0.5916092395782471),\n",
       " ('barking', 0.5861811637878418),\n",
       " ('tea', 0.5833937525749207),\n",
       " ('evergreen', 0.5778738260269165),\n",
       " ('hardwood', 0.5618163347244263),\n",
       " ('eucalyptus', 0.5394592881202698),\n",
       " ('cork', 0.5355424284934998),\n",
       " ('oakleaf', 0.53113853931427),\n",
       " ('plumber', 0.5255903005599976),\n",
       " ('balsa', 0.520546019077301),\n",
       " ('gage', 0.5178087949752808),\n",
       " ('redwood', 0.5032972097396851),\n",
       " ('sequoia', 0.4984729588031769),\n",
       " ('locus', 0.4976775050163269),\n",
       " ('forest', 0.4910851716995239),\n",
       " ('bush', 0.48640844225883484),\n",
       " ('mangrove', 0.48128893971443176),\n",
       " ('buck', 0.4802466332912445),\n",
       " ('cotton', 0.4705781042575836),\n",
       " ('gum', 0.45896491408348083),\n",
       " ('logwood', 0.4533325135707855),\n",
       " ('tap', 0.4453604519367218),\n",
       " ('alu', 0.43769168853759766),\n",
       " ('vine', 0.4373871684074402),\n",
       " ('stocks', 0.4355120360851288),\n",
       " ('cedarwood', 0.43367624282836914),\n",
       " ('hazel', 0.43303632736206055),\n",
       " ('fir', 0.43287408351898193),\n",
       " ('tamarack', 0.4322037994861603),\n",
       " ('currant', 0.4221835136413574),\n",
       " ('pistachio', 0.41801807284355164),\n",
       " ('cordwood', 0.4178442656993866),\n",
       " ('bushwhack', 0.4160339832305908),\n",
       " ('tamaraw', 0.415057510137558),\n",
       " ('basil', 0.4115090072154999),\n",
       " ('pollard', 0.40514421463012695),\n",
       " ('bay', 0.40116649866104126),\n",
       " ('root', 0.40116265416145325),\n",
       " ('timber', 0.39597412943840027),\n",
       " ('liming', 0.3951144218444824),\n",
       " ('palm', 0.39455878734588623),\n",
       " ('treetop', 0.39197057485580444),\n",
       " ('hem', 0.39039120078086853),\n",
       " ('buckthorn', 0.3857373297214508),\n",
       " ('saint', 0.3808528184890747),\n",
       " ('soursop', 0.37914448976516724),\n",
       " ('mast', 0.37300071120262146),\n",
       " ('pine', 0.37258070707321167),\n",
       " ('limes', 0.3717513084411621),\n",
       " ('woodcut', 0.3678218424320221),\n",
       " ('touchwood', 0.36559775471687317),\n",
       " ('bau', 0.3651582896709442),\n",
       " ('juniper', 0.35550275444984436),\n",
       " ('stemmed', 0.3553351163864136),\n",
       " ('brazil', 0.3531128168106079),\n",
       " ('dogwood', 0.35139212012290955),\n",
       " ('blackwood', 0.35073742270469666),\n",
       " ('sourwood', 0.3466761112213135),\n",
       " ('silva', 0.3457285463809967),\n",
       " ('spring', 0.3401244282722473),\n",
       " ('sap', 0.3360830545425415),\n",
       " ('applewood', 0.33605387806892395),\n",
       " ('poplar', 0.33211004734039307),\n",
       " ('laurel', 0.3304128050804138),\n",
       " ('satinwood', 0.3304097056388855),\n",
       " ('hawthorn', 0.3294590711593628),\n",
       " ('box', 0.3293500542640686),\n",
       " ('willow', 0.3281029760837555),\n",
       " ('beechwood', 0.326452374458313),\n",
       " ('mango', 0.3223787844181061),\n",
       " ('gin', 0.320232093334198),\n",
       " ('hemlock', 0.31898295879364014),\n",
       " ('rootstock', 0.3170911967754364),\n",
       " ('alyssum', 0.3168700635433197),\n",
       " ('elder', 0.3123213052749634),\n",
       " ('hold', 0.3109148144721985),\n",
       " ('ironwood', 0.3103075325489044),\n",
       " ('birch', 0.30932289361953735)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'a type of tree', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('superhighway', 0.9432564377784729),\n",
       " ('freeway', 0.831933319568634),\n",
       " ('expressway', 0.8186946511268616),\n",
       " ('road', 0.7954754829406738),\n",
       " ('highway', 0.7796876430511475),\n",
       " ('speed', 0.7761233448982239),\n",
       " ('haste', 0.7701517343521118),\n",
       " ('move', 0.7681809067726135),\n",
       " ('race', 0.7569608092308044),\n",
       " ('speedway', 0.7484490275382996),\n",
       " ('travel', 0.7474307417869568),\n",
       " ('drive', 0.7294769287109375),\n",
       " ('parkway', 0.7202438712120056),\n",
       " ('beltway', 0.7067565321922302),\n",
       " ('roadster', 0.7067355513572693),\n",
       " ('hurry', 0.691335916519165),\n",
       " ('motor', 0.6897876858711243),\n",
       " ('maneuver', 0.6633190512657166),\n",
       " ('zip', 0.6555811762809753),\n",
       " ('shoot', 0.6417109966278076),\n",
       " ('street', 0.6287841796875),\n",
       " ('driveway', 0.6164090037345886),\n",
       " ('runway', 0.6096982955932617),\n",
       " ('taxiway', 0.6056353449821472),\n",
       " ('route', 0.6033530235290527),\n",
       " ('straightway', 0.6019049286842346),\n",
       " ('lanes', 0.600609540939331),\n",
       " ('roads', 0.5971937775611877),\n",
       " ('flyway', 0.5926243662834167),\n",
       " ('chase', 0.5788533687591553),\n",
       " ('autobahn', 0.5780101418495178),\n",
       " ('clip', 0.5677281618118286),\n",
       " ('cutting', 0.5554919242858887),\n",
       " ('trackway', 0.5518191456794739),\n",
       " ('motorway', 0.5402682423591614),\n",
       " ('motorcade', 0.521027684211731),\n",
       " ('pass', 0.5190837383270264),\n",
       " ('drag', 0.5178160071372986),\n",
       " ('quickstep', 0.5169949531555176),\n",
       " ('glide', 0.516629695892334),\n",
       " ('pike', 0.5043076872825623),\n",
       " ('swift', 0.4875653088092804),\n",
       " ('thoroughfare', 0.4773692190647125),\n",
       " ('straightaway', 0.47444361448287964),\n",
       " ('clearway', 0.471720427274704),\n",
       " ('flyaway', 0.4648335874080658),\n",
       " ('fast', 0.46397557854652405),\n",
       " ('flash', 0.4606478810310364),\n",
       " ('tearaway', 0.4491777718067169),\n",
       " ('drift', 0.43516749143600464),\n",
       " ('rush', 0.43371856212615967),\n",
       " ('raceway', 0.433284729719162),\n",
       " ('roundabout', 0.4326895773410797),\n",
       " ('cutaway', 0.43044471740722656),\n",
       " ('belt', 0.4245774745941162),\n",
       " ('thruway', 0.42334115505218506),\n",
       " ('slipway', 0.41254299879074097),\n",
       " ('driveline', 0.376211553812027),\n",
       " ('designate', 0.3696770668029785),\n",
       " ('rally', 0.3661853075027466),\n",
       " ('ramp', 0.36563411355018616),\n",
       " ('ride', 0.3645355701446533),\n",
       " ('go', 0.36409616470336914),\n",
       " ('busway', 0.36384016275405884),\n",
       " ('dash', 0.3634474575519562),\n",
       " ('turnpike', 0.3607173264026642),\n",
       " ('velodrome', 0.35721808671951294),\n",
       " ('rushing', 0.35538744926452637),\n",
       " ('slide', 0.3523537814617157),\n",
       " ('whip', 0.352182537317276),\n",
       " ('hit', 0.34997138381004333),\n",
       " ('takeaway', 0.34284791350364685),\n",
       " ('strip', 0.336293488740921),\n",
       " ('sluice', 0.3355291783809662),\n",
       " ('taxi', 0.3197999894618988),\n",
       " ('career', 0.318716824054718),\n",
       " ('straight', 0.31641754508018494),\n",
       " ('crossway', 0.31467965245246887),\n",
       " ('smooth', 0.31370699405670166),\n",
       " ('racetrack', 0.31057223677635193),\n",
       " ('turn', 0.309817373752594),\n",
       " ('traveling', 0.3091495931148529),\n",
       " ('fly', 0.30813172459602356),\n",
       " ('driving', 0.2998105585575104),\n",
       " ('roll', 0.2988916337490082),\n",
       " ('rave', 0.2985535264015198),\n",
       " ('tear', 0.29484596848487854),\n",
       " ('motoring', 0.2927367687225342),\n",
       " ('run', 0.29101574420928955),\n",
       " ('chaste', 0.2897379398345947),\n",
       " ('slick', 0.2849600911140442),\n",
       " ('sleigh', 0.2825291156768799),\n",
       " ('hop', 0.2796058654785156),\n",
       " ('avenue', 0.27675861120224),\n",
       " ('track', 0.2737518548965454),\n",
       " ('dart', 0.2735345959663391),\n",
       " ('flyer', 0.2720451354980469),\n",
       " ('motorcycle', 0.2717132568359375),\n",
       " ('quick', 0.26834988594055176),\n",
       " ('maneuvering', 0.2683253586292267)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'a road on which cars can go quickly without stopping', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('genius', 0.9899966716766357),\n",
       " ('brains', 0.9687216281890869),\n",
       " ('brain', 0.9671897888183594),\n",
       " ('intellect', 0.9648787975311279),\n",
       " ('einstein', 0.9598327279090881),\n",
       " ('brainstem', 0.9438502788543701),\n",
       " ('intelligence', 0.9433559775352478),\n",
       " ('brilliant', 0.9343078136444092),\n",
       " ('intelligent', 0.9325506091117859),\n",
       " ('brainstorming', 0.9114322066307068),\n",
       " ('brainy', 0.8861953020095825),\n",
       " ('brainpower', 0.8857043981552124),\n",
       " ('somebody', 0.858609676361084),\n",
       " ('intellectual', 0.852242648601532),\n",
       " ('brainiac', 0.84941565990448),\n",
       " ('braincase', 0.8284827470779419),\n",
       " ('smart', 0.8238560557365417),\n",
       " ('person', 0.8067717552185059),\n",
       " ('brilliance', 0.8000427484512329),\n",
       " ('wit', 0.7959452867507935),\n",
       " ('expert', 0.7734217643737793),\n",
       " ('brainchild', 0.7488033175468445),\n",
       " ('cypher', 0.7206608653068542),\n",
       " ('smartness', 0.7182350158691406),\n",
       " ('psychic', 0.7109935283660889),\n",
       " ('spark', 0.7096468806266785),\n",
       " ('brainwash', 0.6831423044204712),\n",
       " ('soul', 0.6703240275382996),\n",
       " ('expertness', 0.6503920555114746),\n",
       " ('shoot', 0.6471215486526489),\n",
       " ('fool', 0.6260147094726562),\n",
       " ('intelligentsia', 0.6215336322784424),\n",
       " ('cynic', 0.6044334173202515),\n",
       " ('hotshot', 0.6039747595787048),\n",
       " ('intellection', 0.5777412056922913),\n",
       " ('visionary', 0.5640668272972107),\n",
       " ('smarty', 0.55267733335495),\n",
       " ('mastermind', 0.5490358471870422),\n",
       " ('smarting', 0.5476147532463074),\n",
       " ('sagacity', 0.5430288314819336),\n",
       " ('scientist', 0.5368516445159912),\n",
       " ('insight', 0.5208315849304199),\n",
       " ('bullhead', 0.5180933475494385),\n",
       " ('mind', 0.5167943239212036),\n",
       " ('psyche', 0.4960271120071411),\n",
       " ('clever', 0.4879215657711029),\n",
       " ('vision', 0.47296151518821716),\n",
       " ('hothead', 0.4696577489376068),\n",
       " ('creativity', 0.46911367774009705),\n",
       " ('blastocyst', 0.4655363857746124),\n",
       " ('cyclops', 0.46552905440330505),\n",
       " ('idiot', 0.44404083490371704),\n",
       " ('supernova', 0.4423191249370575),\n",
       " ('bright', 0.4314180910587311),\n",
       " ('brightness', 0.41396385431289673),\n",
       " ('superstar', 0.4091299772262573),\n",
       " ('being', 0.4078708589076996),\n",
       " ('minder', 0.4039371907711029),\n",
       " ('sparky', 0.39232948422431946),\n",
       " ('sight', 0.39155125617980957),\n",
       " ('sage', 0.39118412137031555),\n",
       " ('personality', 0.3879380524158478),\n",
       " ('sparking', 0.38746345043182373),\n",
       " ('individual', 0.3865841031074524),\n",
       " ('pothead', 0.38591670989990234),\n",
       " ('scholar', 0.3855782151222229),\n",
       " ('skunk', 0.38549134135246277),\n",
       " ('student', 0.36885327100753784),\n",
       " ('knowledge', 0.3657156229019165),\n",
       " ('arrowhead', 0.35801854729652405),\n",
       " ('brave', 0.34812772274017334),\n",
       " ('smarts', 0.3471727669239044),\n",
       " ('nerve', 0.3467690050601959),\n",
       " ('brilliantly', 0.3453863263130188),\n",
       " ('cleverness', 0.34179753065109253),\n",
       " ('intelligently', 0.3390207886695862),\n",
       " ('intellectualism', 0.33254942297935486),\n",
       " ('seeker', 0.3260982036590576),\n",
       " ('grass', 0.32457974553108215),\n",
       " ('levelheaded', 0.32163557410240173),\n",
       " ('figurehead', 0.320872038602829),\n",
       " ('blimp', 0.31869634985923767),\n",
       " ('cy', 0.3173483908176422),\n",
       " ('earwig', 0.31683844327926636),\n",
       " ('blackhead', 0.3150053918361664),\n",
       " ('eye', 0.3093416690826416),\n",
       " ('head', 0.30820232629776),\n",
       " ('cognition', 0.3073404133319855),\n",
       " ('souled', 0.30625125765800476),\n",
       " ('fooling', 0.3022725582122803),\n",
       " ('masturbator', 0.3019002079963684),\n",
       " ('sensitive', 0.30017271637916565),\n",
       " ('soulmate', 0.3000718951225281),\n",
       " ('sentient', 0.2930479645729065),\n",
       " ('blast', 0.29121628403663635),\n",
       " ('brainwashed', 0.2905728220939636),\n",
       " ('masthead', 0.2896629869937897),\n",
       " ('larkspur', 0.2886572778224945),\n",
       " ('foolhardy', 0.2884681820869446),\n",
       " ('fox', 0.2869347333908081)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'a very intelligent person', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smart', 0.992626965045929),\n",
       " ('smarty', 0.9777527451515198),\n",
       " ('smartness', 0.976097583770752),\n",
       " ('smarting', 0.9745392799377441),\n",
       " ('smarts', 0.9617751836776733),\n",
       " ('shoot', 0.9205918908119202),\n",
       " ('hothead', 0.9074836373329163),\n",
       " ('hotdog', 0.9038079977035522),\n",
       " ('flash', 0.871448814868927),\n",
       " ('hotshot', 0.8312650322914124),\n",
       " ('hotchpotch', 0.7926220893859863),\n",
       " ('shot', 0.7819179892539978),\n",
       " ('flasher', 0.7720305323600769),\n",
       " ('sharpshooter', 0.7085450291633606),\n",
       " ('smartly', 0.7082189321517944),\n",
       " ('dart', 0.7061830163002014),\n",
       " ('darts', 0.7058963775634766),\n",
       " ('flashy', 0.688761830329895),\n",
       " ('blast', 0.6872258186340332),\n",
       " ('sharp', 0.6670240759849548),\n",
       " ('hot', 0.6640612483024597),\n",
       " ('hotpot', 0.5960732102394104),\n",
       " ('ache', 0.5757908225059509),\n",
       " ('hotfoot', 0.5692092776298523),\n",
       " ('genius', 0.5527622103691101),\n",
       " ('darter', 0.5455978512763977),\n",
       " ('hunger', 0.540242075920105),\n",
       " ('torpedo', 0.5259228348731995),\n",
       " ('blaster', 0.5232740044593811),\n",
       " ('bullet', 0.5100688934326172),\n",
       " ('burn', 0.509605348110199),\n",
       " ('spark', 0.5078340172767639),\n",
       " ('blaze', 0.5065729022026062),\n",
       " ('missile', 0.506401002407074),\n",
       " ('hotspot', 0.5009092092514038),\n",
       " ('sting', 0.497726172208786),\n",
       " ('fired', 0.49533236026763916),\n",
       " ('arrowhead', 0.4638668894767761),\n",
       " ('flashiness', 0.46353256702423096),\n",
       " ('brilliant', 0.45820727944374084),\n",
       " ('brains', 0.45265763998031616),\n",
       " ('fool', 0.45259609818458557),\n",
       " ('pothead', 0.43947097659111023),\n",
       " ('flashpoint', 0.4375486671924591),\n",
       " ('firedamp', 0.4346074163913727),\n",
       " ('bullseye', 0.419620543718338),\n",
       " ('quick', 0.40732669830322266),\n",
       " ('brain', 0.405076265335083),\n",
       " ('blackhead', 0.40117383003234863),\n",
       " ('blastocyst', 0.39294466376304626),\n",
       " ('clip', 0.3850494921207428),\n",
       " ('hit', 0.3843933045864105),\n",
       " ('speed', 0.3837137222290039),\n",
       " ('cannon', 0.3820880353450775),\n",
       " ('sharpness', 0.3779655396938324),\n",
       " ('jerk', 0.3774346709251404),\n",
       " ('hotness', 0.3748413622379303),\n",
       " ('prick', 0.3720738887786865),\n",
       " ('blazer', 0.36866435408592224),\n",
       " ('sucker', 0.3629467785358429),\n",
       " ('move', 0.36029133200645447),\n",
       " ('lightning', 0.3517599403858185),\n",
       " ('trigger', 0.3472912609577179),\n",
       " ('brightness', 0.34368976950645447),\n",
       " ('snap', 0.34353724122047424),\n",
       " ('burner', 0.341730535030365),\n",
       " ('fiery', 0.3378928601741791),\n",
       " ('stinger', 0.3311223089694977),\n",
       " ('clipper', 0.3224579989910126),\n",
       " ('punk', 0.320321261882782),\n",
       " ('speedball', 0.3177829086780548),\n",
       " ('cannonball', 0.3162931203842163),\n",
       " ('bullhead', 0.31610941886901855),\n",
       " ('spikes', 0.3143599033355713),\n",
       " ('grass', 0.3137945234775543),\n",
       " ('pain', 0.3099559545516968),\n",
       " ('thirst', 0.30944138765335083),\n",
       " ('sharpie', 0.3079351782798767),\n",
       " ('fox', 0.3038303256034851),\n",
       " ('hurting', 0.2997289001941681),\n",
       " ('darting', 0.29780223965644836),\n",
       " ('burst', 0.2890009880065918),\n",
       " ('beast', 0.2885648310184479),\n",
       " ('snapper', 0.28457111120224),\n",
       " ('crack', 0.28357020020484924),\n",
       " ('guttersnipe', 0.2797040045261383),\n",
       " ('blowhard', 0.2785567045211792),\n",
       " ('scooter', 0.2783568203449249),\n",
       " ('shootdown', 0.27583277225494385),\n",
       " ('flaming', 0.2714935839176178),\n",
       " ('hots', 0.269770085811615),\n",
       " ('snappy', 0.2670170068740845),\n",
       " ('aching', 0.26641127467155457),\n",
       " ('flare', 0.26409125328063965),\n",
       " ('attack', 0.26192253828048706),\n",
       " ('bright', 0.261750191450119),\n",
       " ('spot', 0.26035794615745544),\n",
       " ('mad', 0.26002469658851624),\n",
       " ('bulleted', 0.25975608825683594),\n",
       " ('dragon', 0.25828108191490173)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'a very smart person', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unhappiness', 0.9564859867095947),\n",
       " ('happiness', 0.9440613389015198),\n",
       " ('sadness', 0.9340919256210327),\n",
       " ('misbehavior', 0.926218569278717),\n",
       " ('misanthropy', 0.9002848267555237),\n",
       " ('unhappy', 0.8268434405326843),\n",
       " ('misery', 0.771747350692749),\n",
       " ('happy', 0.7376412749290466),\n",
       " ('misanthrope', 0.7179532051086426),\n",
       " ('sorrow', 0.6878830194473267),\n",
       " ('sorrowing', 0.6854086518287659),\n",
       " ('aggravation', 0.6803992390632629),\n",
       " ('loneliness', 0.6780133247375488),\n",
       " ('discontent', 0.5803792476654053),\n",
       " ('complacency', 0.5688847899436951),\n",
       " ('sadomasochism', 0.5650791525840759),\n",
       " ('lethargic', 0.5404712557792664),\n",
       " ('misfortunate', 0.5287728905677795),\n",
       " ('sorrowful', 0.5277866721153259),\n",
       " ('discoloration', 0.5162428617477417),\n",
       " ('miscarry', 0.5112969279289246),\n",
       " ('complacence', 0.5023670196533203),\n",
       " ('joyousness', 0.4918251931667328),\n",
       " ('uneasiness', 0.48316457867622375),\n",
       " ('inactivity', 0.47422292828559875),\n",
       " ('selfishness', 0.4702393412590027),\n",
       " ('moodiness', 0.4695213735103607),\n",
       " ('disconcert', 0.46892499923706055),\n",
       " ('misanthropic', 0.4673250615596771),\n",
       " ('calamity', 0.4474116563796997),\n",
       " ('dissipation', 0.4357851445674896),\n",
       " ('misfortune', 0.41744112968444824),\n",
       " ('changeover', 0.4129270911216736),\n",
       " ('queasiness', 0.39732709527015686),\n",
       " ('nonviolent', 0.3968028724193573),\n",
       " ('emotion', 0.3926781713962555),\n",
       " ('regretting', 0.39028632640838623),\n",
       " ('imbecility', 0.38340625166893005),\n",
       " ('emotionless', 0.37183430790901184),\n",
       " ('regret', 0.3688034117221832),\n",
       " ('feeling', 0.366934597492218),\n",
       " ('unfriendliness', 0.36513546109199524),\n",
       " ('peacefulness', 0.3566672205924988),\n",
       " ('sleepiness', 0.34722787141799927),\n",
       " ('tediousness', 0.342108815908432),\n",
       " ('contentedness', 0.3324263393878937),\n",
       " ('melancholia', 0.33108386397361755),\n",
       " ('desensitisation', 0.32934144139289856),\n",
       " ('dissatisfaction', 0.3222178816795349),\n",
       " ('want', 0.3200775980949402),\n",
       " ('sadism', 0.31640201807022095),\n",
       " ('misbehave', 0.3143349289894104),\n",
       " ('failure', 0.30739983916282654),\n",
       " ('desire', 0.29896965622901917),\n",
       " ('guiltiness', 0.2933301031589508),\n",
       " ('compunction', 0.290614515542984),\n",
       " ('heartbreak', 0.2890870273113251),\n",
       " ('heartbreaking', 0.2867294251918793),\n",
       " ('squeamishness', 0.2844983637332916),\n",
       " ('adrenergic', 0.283403605222702),\n",
       " ('endosperm', 0.2816380262374878),\n",
       " ('cholelithiasis', 0.2803798317909241),\n",
       " ('erythropoietin', 0.2797979414463043),\n",
       " ('erythropoietic', 0.2797979414463043),\n",
       " ('miserable', 0.2759033441543579),\n",
       " ('desiring', 0.27559542655944824),\n",
       " ('desirability', 0.2699238061904907),\n",
       " ('frugality', 0.2654435932636261),\n",
       " ('discontented', 0.26481109857559204),\n",
       " ('joyfulness', 0.26445871591567993),\n",
       " ('pathos', 0.26133617758750916),\n",
       " ('heartbreaker', 0.25079357624053955),\n",
       " ('aplenty', 0.2505113482475281),\n",
       " ('depression', 0.2504284083843231),\n",
       " ('endurable', 0.24862171709537506),\n",
       " ('pity', 0.24431738257408142),\n",
       " ('stagnancy', 0.2413511723279953),\n",
       " ('complaisance', 0.23912717401981354),\n",
       " ('sadhana', 0.2357565313577652),\n",
       " ('amenity', 0.23551571369171143),\n",
       " ('indolence', 0.2339484691619873),\n",
       " ('regretful', 0.22858251631259918),\n",
       " ('peacetime', 0.22173897922039032),\n",
       " ('despondency', 0.22024044394493103),\n",
       " ('dissipative', 0.21573898196220398),\n",
       " ('boredom', 0.2153421938419342),\n",
       " ('frivolity', 0.21445736289024353),\n",
       " ('nonmilitary', 0.21062670648097992),\n",
       " ('greediness', 0.20976075530052185),\n",
       " ('melancholy', 0.20656158030033112),\n",
       " ('sleepover', 0.20343336462974548),\n",
       " ('dreaminess', 0.19933603703975677),\n",
       " ('apathy', 0.19847001135349274),\n",
       " ('malevolence', 0.19717778265476227),\n",
       " ('bliss', 0.19575975835323334),\n",
       " ('discontinuity', 0.19396740198135376),\n",
       " ('status', 0.192633256316185),\n",
       " ('pragmatism', 0.19040338695049286),\n",
       " ('envy', 0.18902811408042908),\n",
       " ('miserliness', 0.18789216876029968)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'the opposite of being happy', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thermometer', 0.9870902895927429),\n",
       " ('calorimeter', 0.9651489853858948),\n",
       " ('temperature', 0.9647976756095886),\n",
       " ('heat', 0.8819329738616943),\n",
       " ('speedometer', 0.8643578886985779),\n",
       " ('pyrometer', 0.8432449698448181),\n",
       " ('fahrenheit', 0.8431944847106934),\n",
       " ('magnetometer', 0.7803845405578613),\n",
       " ('heater', 0.7791886329650879),\n",
       " ('refrigerate', 0.7783988118171692),\n",
       " ('seismometer', 0.7512844204902649),\n",
       " ('gasometer', 0.6834492683410645),\n",
       " ('isotherm', 0.6559324860572815),\n",
       " ('hygrometer', 0.6509665846824646),\n",
       " ('densitometer', 0.644676685333252),\n",
       " ('barometer', 0.6405194401741028),\n",
       " ('refractor', 0.6307488679885864),\n",
       " ('heating', 0.6181195974349976),\n",
       " ('aether', 0.5048888921737671),\n",
       " ('gage', 0.5039142966270447),\n",
       " ('interferometer', 0.4987775385379791),\n",
       " ('rheometer', 0.49652099609375),\n",
       " ('cold', 0.4597109258174896),\n",
       " ('quicklime', 0.44842100143432617),\n",
       " ('spirometer', 0.4475388824939728),\n",
       " ('tachometer', 0.44367653131484985),\n",
       " ('refrigerant', 0.4419322609901428),\n",
       " ('isoelectric', 0.43211835622787476),\n",
       " ('reflectometer', 0.4105180501937866),\n",
       " ('refrigerating', 0.39975082874298096),\n",
       " ('control', 0.3882819414138794),\n",
       " ('thermostat', 0.3811030983924866),\n",
       " ('atmosphere', 0.3805195093154907),\n",
       " ('estimator', 0.3754914402961731),\n",
       " ('cooler', 0.37432757019996643),\n",
       " ('anemometer', 0.37348827719688416),\n",
       " ('photodetector', 0.3604740798473358),\n",
       " ('inclinometer', 0.35024768114089966),\n",
       " ('climate', 0.3467922508716583),\n",
       " ('furnace', 0.3376629054546356),\n",
       " ('chill', 0.32747387886047363),\n",
       " ('feel', 0.3172577917575836),\n",
       " ('heatwave', 0.3108181655406952),\n",
       " ('supply', 0.3019070327281952),\n",
       " ('heated', 0.3005370497703552),\n",
       " ('device', 0.29454538226127625),\n",
       " ('coldness', 0.2930483818054199),\n",
       " ('hyperthermia', 0.2918025851249695),\n",
       " ('cook', 0.29089391231536865),\n",
       " ('fannish', 0.28869375586509705),\n",
       " ('indicator', 0.2869377136230469),\n",
       " ('photometer', 0.2780497968196869),\n",
       " ('refrigeration', 0.27632999420166016),\n",
       " ('calorimetry', 0.2753680646419525),\n",
       " ('thermopile', 0.2641275227069855),\n",
       " ('stove', 0.2582068145275116),\n",
       " ('pressure', 0.255695104598999),\n",
       " ('measure', 0.24923138320446014),\n",
       " ('cool', 0.246880903840065),\n",
       " ('tether', 0.24549047648906708),\n",
       " ('falsifier', 0.23912131786346436),\n",
       " ('photoelectric', 0.23758597671985626),\n",
       " ('collimator', 0.23312459886074066),\n",
       " ('turn', 0.22774054110050201),\n",
       " ('ventilator', 0.22728568315505981),\n",
       " ('tested', 0.22544126212596893),\n",
       " ('celsius', 0.22322870790958405),\n",
       " ('het', 0.22282050549983978),\n",
       " ('conditions', 0.22259366512298584),\n",
       " ('quizzer', 0.22127430140972137),\n",
       " ('deceleration', 0.2202691286802292),\n",
       " ('photomicrograph', 0.21667318046092987),\n",
       " ('radiometer', 0.21489842236042023),\n",
       " ('methamphetamine', 0.21081678569316864),\n",
       " ('manometer', 0.2106887698173523),\n",
       " ('geometer', 0.20527994632720947),\n",
       " ('provide', 0.20475827157497406),\n",
       " ('thermometry', 0.2024693489074707),\n",
       " ('airdate', 0.20178425312042236),\n",
       " ('setup', 0.2004879117012024),\n",
       " ('degree', 0.19859559834003448),\n",
       " ('actuator', 0.198268324136734),\n",
       " ('weather', 0.19821031391620636),\n",
       " ('timed', 0.19778455793857574),\n",
       " ('predetermine', 0.19691155850887299),\n",
       " ('icy', 0.19541862607002258),\n",
       " ('modify', 0.1951574683189392),\n",
       " ('sublimate', 0.19034737348556519),\n",
       " ('cooling', 0.18973904848098755),\n",
       " ('condition', 0.18892043828964233),\n",
       " ('tonometer', 0.18809084594249725),\n",
       " ('fluoridate', 0.18787911534309387),\n",
       " ('chiller', 0.18701070547103882),\n",
       " ('refuel', 0.18509480357170105),\n",
       " ('change', 0.18299782276153564),\n",
       " ('flux', 0.18250426650047302),\n",
       " ('moderation', 0.18165189027786255),\n",
       " ('ice', 0.1811804175376892),\n",
       " ('fever', 0.18063388764858246),\n",
       " ('run', 0.17968539893627167)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'something you use to measure your temperature', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dusk', 0.9902498126029968),\n",
       " ('night', 0.9843398332595825),\n",
       " ('twilight', 0.983363151550293),\n",
       " ('dau', 0.970775306224823),\n",
       " ('darkness', 0.968502938747406),\n",
       " ('nightfall', 0.9646450281143188),\n",
       " ('day', 0.9296711683273315),\n",
       " ('nightly', 0.9182392954826355),\n",
       " ('nighttime', 0.9147279858589172),\n",
       " ('hour', 0.8999171257019043),\n",
       " ('moon', 0.8985822796821594),\n",
       " ('nightgown', 0.8807250261306763),\n",
       " ('da', 0.8677366375923157),\n",
       " ('dusky', 0.8567270636558533),\n",
       " ('eve', 0.8546727299690247),\n",
       " ('tide', 0.8473078608512878),\n",
       " ('daylight', 0.8041820526123047),\n",
       " ('period', 0.7880057692527771),\n",
       " ('evening', 0.7875092029571533),\n",
       " ('forenoon', 0.7712737917900085),\n",
       " ('none', 0.7663474678993225),\n",
       " ('dak', 0.7646946907043457),\n",
       " ('daytime', 0.7641853094100952),\n",
       " ('tomorrow', 0.7562503814697266),\n",
       " ('midnight', 0.7519458532333374),\n",
       " ('morrow', 0.7462226152420044),\n",
       " ('dace', 0.7396567463874817),\n",
       " ('dah', 0.7387454509735107),\n",
       " ('daunt', 0.7087877988815308),\n",
       " ('morning', 0.6945293545722961),\n",
       " ('afternoon', 0.6938912272453308),\n",
       " ('daybreak', 0.681481659412384),\n",
       " ('dawah', 0.6469714045524597),\n",
       " ('noonday', 0.6423055529594421),\n",
       " ('sou', 0.6325821280479431),\n",
       " ('dawn', 0.6316150426864624),\n",
       " ('dap', 0.6112871766090393),\n",
       " ('overnight', 0.5876274108886719),\n",
       " ('dayan', 0.5752809643745422),\n",
       " ('epoch', 0.5604112148284912),\n",
       " ('daw', 0.5492730736732483),\n",
       " ('nonet', 0.5466485023498535),\n",
       " ('moonshine', 0.5418456196784973),\n",
       " ('halloween', 0.5144819617271423),\n",
       " ('nightlight', 0.511386513710022),\n",
       " ('daf', 0.5109420418739319),\n",
       " ('fore', 0.5056940913200378),\n",
       " ('nightie', 0.49252957105636597),\n",
       " ('nightside', 0.4832049608230591),\n",
       " ('aurora', 0.4814503490924835),\n",
       " ('souq', 0.4794750511646271),\n",
       " ('far', 0.4740481376647949),\n",
       " ('late', 0.4735713601112366),\n",
       " ('sunset', 0.46737515926361084),\n",
       " ('nightmarish', 0.4654301702976227),\n",
       " ('sunrise', 0.4652356803417206),\n",
       " ('shadow', 0.4600909352302551),\n",
       " ('dawdle', 0.45897334814071655),\n",
       " ('time', 0.4463985860347748),\n",
       " ('sunna', 0.4442380666732788),\n",
       " ('sun', 0.4434744417667389),\n",
       " ('passu', 0.44241929054260254),\n",
       " ('id', 0.4402540624141693),\n",
       " ('doomsday', 0.43947163224220276),\n",
       " ('daydreaming', 0.4392821192741394),\n",
       " ('shade', 0.4350009560585022),\n",
       " ('moonrise', 0.42939093708992004),\n",
       " ('nights', 0.4268493056297302),\n",
       " ('today', 0.42595526576042175),\n",
       " ('dag', 0.4254012405872345),\n",
       " ('no', 0.41610848903656006),\n",
       " ('daylights', 0.40274035930633545),\n",
       " ('dac', 0.39775899052619934),\n",
       " ('shades', 0.3875143229961395),\n",
       " ('hours', 0.38478994369506836),\n",
       " ('shadowed', 0.3811855912208557),\n",
       " ('gloaming', 0.37285876274108887),\n",
       " ('feu', 0.36678260564804077),\n",
       " ('dagga', 0.3636432886123657),\n",
       " ('daffy', 0.3615912199020386),\n",
       " ('noose', 0.3596864640712738),\n",
       " ('nones', 0.35003164410591125),\n",
       " ('come', 0.347204327583313),\n",
       " ('dauber', 0.3442225158214569),\n",
       " ('moony', 0.34282386302948),\n",
       " ('nine', 0.3356744647026062),\n",
       " ('vest', 0.3225136399269104),\n",
       " ('clock', 0.3147849440574646),\n",
       " ('noon', 0.3141002655029297),\n",
       " ('even', 0.31336113810539246),\n",
       " ('mooning', 0.31060296297073364),\n",
       " ('fark', 0.3086579740047455),\n",
       " ('foregone', 0.30846092104911804),\n",
       " ('gloom', 0.3035339117050171),\n",
       " ('dacron', 0.29072198271751404),\n",
       " ('four', 0.28965499997138977),\n",
       " ('thu', 0.28693777322769165),\n",
       " ('primed', 0.28659042716026306),\n",
       " ('moonlight', 0.28108394145965576),\n",
       " ('doom', 0.2810719907283783)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'a dark time of day', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oligarchy', 0.9340060353279114),\n",
       " ('aristocracy', 0.9111836552619934),\n",
       " ('nobility', 0.8552895188331604),\n",
       " ('government', 0.8252381682395935),\n",
       " ('order', 0.8251005411148071),\n",
       " ('feudalism', 0.8089253902435303),\n",
       " ('celibacy', 0.7787441611289978),\n",
       " ('homage', 0.7786471843719482),\n",
       " ('dukedom', 0.761428952217102),\n",
       " ('familly', 0.7329322099685669),\n",
       " ('hierarchy', 0.7318239808082581),\n",
       " ('autocracy', 0.7199180722236633),\n",
       " ('peerage', 0.7192471027374268),\n",
       " ('lords', 0.7177726626396179),\n",
       " ('noblesse', 0.70628422498703),\n",
       " ('commune', 0.6935475468635559),\n",
       " ('obedience', 0.6930590271949768),\n",
       " ('lordship', 0.6775382161140442),\n",
       " ('court', 0.65690678358078),\n",
       " ('bureaucracy', 0.6550346612930298),\n",
       " ('principality', 0.6500912308692932),\n",
       " ('domain', 0.6483148336410522),\n",
       " ('fiefdom', 0.636286735534668),\n",
       " ('feudal', 0.6148019433021545),\n",
       " ('inquisition', 0.6092568039894104),\n",
       " ('chapter', 0.6073670983314514),\n",
       " ('heterosis', 0.6024513840675354),\n",
       " ('regency', 0.5921065807342529),\n",
       " ('lord', 0.5854981541633606),\n",
       " ('monarchy', 0.578682541847229),\n",
       " ('estate', 0.5735321640968323),\n",
       " ('status', 0.570546567440033),\n",
       " ('commonwealth', 0.564805805683136),\n",
       " ('oligarch', 0.5395818948745728),\n",
       " ('gentry', 0.5362626314163208),\n",
       " ('baron', 0.5327486991882324),\n",
       " ('kingdom', 0.5325689911842346),\n",
       " ('vassalage', 0.5314797759056091),\n",
       " ('justice', 0.5209547281265259),\n",
       " ('anarchy', 0.5150484442710876),\n",
       " ('count', 0.5113381147384644),\n",
       " ('society', 0.49262920022010803),\n",
       " ('polis', 0.49052101373672485),\n",
       " ('regimen', 0.48224514722824097),\n",
       " ('samurai', 0.4749405086040497),\n",
       " ('theocracy', 0.47387075424194336),\n",
       " ('feud', 0.4730187952518463),\n",
       " ('serval', 0.4667142331600189),\n",
       " ('regime', 0.4663405120372772),\n",
       " ('paunchy', 0.46600085496902466),\n",
       " ('dynasty', 0.46555766463279724),\n",
       " ('guild', 0.45698338747024536),\n",
       " ('guildhall', 0.4565770924091339),\n",
       " ('polity', 0.44259095191955566),\n",
       " ('manor', 0.4411846995353699),\n",
       " ('law', 0.4411669075489044),\n",
       " ('patrician', 0.4388298988342285),\n",
       " ('barony', 0.43729275465011597),\n",
       " ('vassal', 0.43629756569862366),\n",
       " ('nobleman', 0.43330061435699463),\n",
       " ('ecru', 0.418742835521698),\n",
       " ('duke', 0.4058135747909546),\n",
       " ('oligarchical', 0.3983520269393921),\n",
       " ('rule', 0.3977510333061218),\n",
       " ('family', 0.3874630928039551),\n",
       " ('bailiwick', 0.3865739703178406),\n",
       " ('landlady', 0.3863220512866974),\n",
       " ('district', 0.37700220942497253),\n",
       " ('administration', 0.37696725130081177),\n",
       " ('numeracy', 0.3744256794452667),\n",
       " ('matriarchy', 0.36403751373291016),\n",
       " ('ruled', 0.3613169491291046),\n",
       " ('governed', 0.36115917563438416),\n",
       " ('plutocracy', 0.361098974943161),\n",
       " ('juju', 0.34369105100631714),\n",
       " ('office', 0.33988288044929504),\n",
       " ('govern', 0.3368401527404785),\n",
       " ('aristocratic', 0.3366760313510895),\n",
       " ('dietician', 0.3260839879512787),\n",
       " ('oligarchic', 0.3218582570552826),\n",
       " ('noble', 0.3214403986930847),\n",
       " ('manorial', 0.32138732075691223),\n",
       " ('prior', 0.31160178780555725),\n",
       " ('dietitian', 0.3079868257045746),\n",
       " ('ascendency', 0.3078664243221283),\n",
       " ('states', 0.3068523705005646),\n",
       " ('dependency', 0.3062724471092224),\n",
       " ('nobleness', 0.303364634513855),\n",
       " ('regiment', 0.2970724403858185),\n",
       " ('constable', 0.29421114921569824),\n",
       " ('curacy', 0.29395559430122375),\n",
       " ('franchising', 0.29258993268013),\n",
       " ('household', 0.2901865839958191),\n",
       " ('landis', 0.2878052890300751),\n",
       " ('palace', 0.2869635224342346),\n",
       " ('chastity', 0.28400060534477234),\n",
       " ('counting', 0.2825706899166107),\n",
       " ('taxation', 0.28200823068618774),\n",
       " ('magnate', 0.2799706757068634),\n",
       " ('bureaucratism', 0.27939581871032715)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'medieval social hierarchy where peasants and vassals served lords', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('study', 0.9601989388465881),\n",
       " ('learning', 0.910089910030365),\n",
       " ('deep', 0.9032861590385437),\n",
       " ('indoctrination', 0.8831983208656311),\n",
       " ('education', 0.8816927075386047),\n",
       " ('learn', 0.8657744526863098),\n",
       " ('catechumen', 0.848861575126648),\n",
       " ('deepness', 0.8403034210205078),\n",
       " ('analysis', 0.8245221972465515),\n",
       " ('science', 0.8152496814727783),\n",
       " ('catechism', 0.8136394619941711),\n",
       " ('instructive', 0.8025436401367188),\n",
       " ('drill', 0.8013206124305725),\n",
       " ('lyceum', 0.8002776503562927),\n",
       " ('graphology', 0.7923668026924133),\n",
       " ('depth', 0.7837069630622864),\n",
       " ('concentration', 0.7835208773612976),\n",
       " ('deepening', 0.7703989744186401),\n",
       " ('instruct', 0.7556796669960022),\n",
       " ('training', 0.7527759075164795),\n",
       " ('instruction', 0.7248058915138245),\n",
       " ('teach', 0.7106432914733887),\n",
       " ('exercise', 0.7100815773010254),\n",
       " ('catechol', 0.6653569936752319),\n",
       " ('profound', 0.6645328402519226),\n",
       " ('analyst', 0.6405267715454102),\n",
       " ('studying', 0.6402386426925659),\n",
       " ('cryptology', 0.635059118270874),\n",
       " ('seminary', 0.6283536553382874),\n",
       " ('understand', 0.5964438319206238),\n",
       " ('schooling', 0.5863648653030396),\n",
       " ('phrenology', 0.5772497057914734),\n",
       " ('musicology', 0.5769248604774475),\n",
       " ('acquisition', 0.5731056928634644),\n",
       " ('lycee', 0.5722630023956299),\n",
       " ('immersion', 0.5660001635551453),\n",
       " ('audit', 0.557610034942627),\n",
       " ('humanities', 0.550436794757843),\n",
       " ('educate', 0.5466814637184143),\n",
       " ('invigilation', 0.5433785319328308),\n",
       " ('educative', 0.5397241711616516),\n",
       " ('auditing', 0.5371165871620178),\n",
       " ('didacticism', 0.5295622944831848),\n",
       " ('profoundness', 0.5274137258529663),\n",
       " ('phonics', 0.5151469707489014),\n",
       " ('scientism', 0.5097929239273071),\n",
       " ('penetration', 0.5052178502082825),\n",
       " ('take', 0.49205726385116577),\n",
       " ('homework', 0.49003058671951294),\n",
       " ('knowledge', 0.4733510911464691),\n",
       " ('school', 0.4720895290374756),\n",
       " ('culture', 0.4663127362728119),\n",
       " ('philosophizing', 0.4636949896812439),\n",
       " ('thought', 0.4520867168903351),\n",
       " ('research', 0.45107561349868774),\n",
       " ('matriculation', 0.44840511679649353),\n",
       " ('bluenose', 0.4475036561489105),\n",
       " ('indoctrinate', 0.44608354568481445),\n",
       " ('examination', 0.44591933488845825),\n",
       " ('gnosis', 0.44231557846069336),\n",
       " ('sophistication', 0.44124501943588257),\n",
       " ('deepen', 0.4351956248283386),\n",
       " ('systematics', 0.43064332008361816),\n",
       " ('scholar', 0.43002402782440186),\n",
       " ('catecholamine', 0.4239727556705475),\n",
       " ('inquiry', 0.4214877784252167),\n",
       " ('philosophy', 0.4141358435153961),\n",
       " ('catechu', 0.41400739550590515),\n",
       " ('memorization', 0.41203558444976807),\n",
       " ('sci', 0.41086095571517944),\n",
       " ('mastermind', 0.4105743169784546),\n",
       " ('comprehension', 0.406663715839386),\n",
       " ('arts', 0.40430930256843567),\n",
       " ('train', 0.40068718791007996),\n",
       " ('conservatory', 0.4004192650318146),\n",
       " ('dips', 0.39542368054389954),\n",
       " ('theory', 0.3946838676929474),\n",
       " ('nosology', 0.38983404636383057),\n",
       " ('lecture', 0.3898242712020874),\n",
       " ('literacy', 0.3882256746292114),\n",
       " ('biology', 0.3811797797679901),\n",
       " ('tech', 0.3801466226577759),\n",
       " ('maths', 0.37617748975753784),\n",
       " ('meditation', 0.37509801983833313),\n",
       " ('psychology', 0.374799519777298),\n",
       " ('scholasticism', 0.37301602959632874),\n",
       " ('discipline', 0.36928707361221313),\n",
       " ('prepare', 0.36805590987205505),\n",
       " ('preparatory', 0.36652252078056335),\n",
       " ('investigate', 0.3651367425918579),\n",
       " ('course', 0.36504873633384705),\n",
       " ('academy', 0.3636804521083832),\n",
       " ('communications', 0.36293989419937134),\n",
       " ('prescience', 0.35883694887161255),\n",
       " ('wisdom', 0.3586363196372986),\n",
       " ('core', 0.3585495352745056),\n",
       " ('intussusception', 0.3585391342639923),\n",
       " ('inexperience', 0.3580760955810547),\n",
       " ('intellect', 0.35126978158950806),\n",
       " ('seismology', 0.3474348783493042)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'deep learning', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('give', 0.9956091046333313),\n",
       " ('gift', 0.9803848266601562),\n",
       " ('giving', 0.9600266218185425),\n",
       " ('take', 0.9423472285270691),\n",
       " ('giver', 0.9335689544677734),\n",
       " ('treat', 0.9269536733627319),\n",
       " ('deal', 0.9230650067329407),\n",
       " ('donate', 0.9195953607559204),\n",
       " ('have', 0.9164474010467529),\n",
       " ('use', 0.8981136679649353),\n",
       " ('gifting', 0.8838661313056946),\n",
       " ('receive', 0.8785077929496765),\n",
       " ('administer', 0.876017153263092),\n",
       " ('delivery', 0.8690775632858276),\n",
       " ('drink', 0.8679701685905457),\n",
       " ('change', 0.8615391850471497),\n",
       " ('present', 0.8581041097640991),\n",
       " ('handing', 0.8442950248718262),\n",
       " ('make', 0.8227622509002686),\n",
       " ('distribute', 0.8207599520683289),\n",
       " ('supply', 0.8196119666099548),\n",
       " ('deliver', 0.8173937797546387),\n",
       " ('initiate', 0.7992436289787292),\n",
       " ('accept', 0.7902272939682007),\n",
       " ('offer', 0.7816919684410095),\n",
       " ('share', 0.7715913653373718),\n",
       " ('get', 0.7598951458930969),\n",
       " ('payment', 0.7582589387893677),\n",
       " ('treats', 0.7529175281524658),\n",
       " ('communicate', 0.7516933679580688),\n",
       " ('provide', 0.7478413581848145),\n",
       " ('leave', 0.7477261424064636),\n",
       " ('dedication', 0.7388249635696411),\n",
       " ('grant', 0.7378513216972351),\n",
       " ('assign', 0.7302519679069519),\n",
       " ('fee', 0.7198696136474609),\n",
       " ('given', 0.7154681086540222),\n",
       " ('thing', 0.7140315175056458),\n",
       " ('possession', 0.7135124802589417),\n",
       " ('submit', 0.7114238142967224),\n",
       " ('sacrifice', 0.7080602645874023),\n",
       " ('undergo', 0.7056466937065125),\n",
       " ('parcel', 0.7042392492294312),\n",
       " ('return', 0.6895549297332764),\n",
       " ('substance', 0.6861202716827393),\n",
       " ('dow', 0.6859692335128784),\n",
       " ('hold', 0.6857151389122009),\n",
       " ('trust', 0.6848066449165344),\n",
       " ('receiver', 0.6837596893310547),\n",
       " ('handle', 0.679414689540863),\n",
       " ('recipient', 0.6720951795578003),\n",
       " ('condition', 0.6716526746749878),\n",
       " ('treatment', 0.6682977080345154),\n",
       " ('utilize', 0.667330265045166),\n",
       " ('feeding', 0.6643150448799133),\n",
       " ('reward', 0.662228524684906),\n",
       " ('render', 0.6601279377937317),\n",
       " ('pledge', 0.6583383679389954),\n",
       " ('hand', 0.6537803411483765),\n",
       " ('create', 0.6533758640289307),\n",
       " ('portion', 0.6516016721725464),\n",
       " ('experience', 0.6445440649986267),\n",
       " ('offering', 0.6436116695404053),\n",
       " ('dowry', 0.6339167356491089),\n",
       " ('content', 0.6300723552703857),\n",
       " ('received', 0.6219139695167542),\n",
       " ('move', 0.6205219030380249),\n",
       " ('throw', 0.6073371171951294),\n",
       " ('lot', 0.6067367196083069),\n",
       " ('regard', 0.6054825186729431),\n",
       " ('acquisition', 0.6040263772010803),\n",
       " ('carry', 0.6014811396598816),\n",
       " ('acceptance', 0.5993167757987976),\n",
       " ('turn', 0.59927898645401),\n",
       " ('inherit', 0.5981221199035645),\n",
       " ('deed', 0.595973789691925),\n",
       " ('touch', 0.5950790643692017),\n",
       " ('nurse', 0.5939299464225769),\n",
       " ('let', 0.5913963913917542),\n",
       " ('presentment', 0.5868543982505798),\n",
       " ('produce', 0.5849933624267578),\n",
       " ('baby', 0.5836294889450073),\n",
       " ('drop', 0.5818378925323486),\n",
       " ('lead', 0.5783410668373108),\n",
       " ('fix', 0.576930046081543),\n",
       " ('taking', 0.5762290954589844),\n",
       " ('buy', 0.568422257900238),\n",
       " ('request', 0.5680055618286133),\n",
       " ('distribution', 0.5645627975463867),\n",
       " ('modify', 0.5627875328063965),\n",
       " ('serve', 0.5621833205223083),\n",
       " ('refer', 0.5616294145584106),\n",
       " ('consume', 0.5603103637695312),\n",
       " ('transfer', 0.5602866411209106),\n",
       " ('spend', 0.5601588487625122),\n",
       " ('sharing', 0.5489369630813599),\n",
       " ('will', 0.5473456382751465),\n",
       " ('suck', 0.5472273826599121),\n",
       " ('release', 0.5463894009590149),\n",
       " ('snap', 0.5460473895072937)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'when somebody gives something to you and afterwards you have it', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trust', 0.9927996397018433),\n",
       " ('trusty', 0.9561113119125366),\n",
       " ('betrayal', 0.9532467722892761),\n",
       " ('cheat', 0.8850262761116028),\n",
       " ('betray', 0.8843281865119934),\n",
       " ('trustworthy', 0.871504545211792),\n",
       " ('faith', 0.8544620871543884),\n",
       " ('gamble', 0.8512130975723267),\n",
       " ('deception', 0.8467381596565247),\n",
       " ('compromised', 0.8375467658042908),\n",
       " ('distrust', 0.8366779685020447),\n",
       " ('cheated', 0.8210803866386414),\n",
       " ('venture', 0.8131632208824158),\n",
       " ('trusting', 0.7965644001960754),\n",
       " ('fuck', 0.7916842699050903),\n",
       " ('trustor', 0.7729158997535706),\n",
       " ('trustful', 0.7722510695457458),\n",
       " ('job', 0.7710670232772827),\n",
       " ('confidence', 0.7629819512367249),\n",
       " ('manipulate', 0.7540766596794128),\n",
       " ('misconduct', 0.7507216334342957),\n",
       " ('fraud', 0.7440340518951416),\n",
       " ('false', 0.7437525987625122),\n",
       " ('pretend', 0.7307678461074829),\n",
       " ('judas', 0.7197650074958801),\n",
       " ('confide', 0.7180337309837341),\n",
       " ('believe', 0.7108274698257446),\n",
       " ('bets', 0.7078320384025574),\n",
       " ('pawn', 0.7063281536102295),\n",
       " ('rely', 0.7038103342056274),\n",
       " ('blackmail', 0.6930459141731262),\n",
       " ('trustable', 0.6917220950126648),\n",
       " ('misadventure', 0.6913524866104126),\n",
       " ('traitor', 0.671515703201294),\n",
       " ('surmise', 0.6713006496429443),\n",
       " ('suspect', 0.6668158173561096),\n",
       " ('jeopardy', 0.6551527976989746),\n",
       " ('expose', 0.6417138576507568),\n",
       " ('trustworthiness', 0.638171374797821),\n",
       " ('buy', 0.6305404305458069),\n",
       " ('assuring', 0.6298799514770508),\n",
       " ('surcharge', 0.6213890314102173),\n",
       " ('cartel', 0.6206115484237671),\n",
       " ('betraying', 0.617327868938446),\n",
       " ('rob', 0.606483519077301),\n",
       " ('lie', 0.5995945930480957),\n",
       " ('sham', 0.5866491794586182),\n",
       " ('violate', 0.5696079134941101),\n",
       " ('peradventure', 0.5689677596092224),\n",
       " ('bet', 0.5687515735626221),\n",
       " ('depend', 0.5673779845237732),\n",
       " ('reliance', 0.5625299215316772),\n",
       " ('bribe', 0.5603240132331848),\n",
       " ('stake', 0.558402419090271),\n",
       " ('sell', 0.5570483803749084),\n",
       " ('fraudster', 0.5509077310562134),\n",
       " ('gambler', 0.5478554964065552),\n",
       " ('breach', 0.5429452061653137),\n",
       " ('betide', 0.5423001050949097),\n",
       " ('crook', 0.5354780554771423),\n",
       " ('friendship', 0.5330724120140076),\n",
       " ('commiserate', 0.5257847905158997),\n",
       " ('cheater', 0.5219888687133789),\n",
       " ('steal', 0.5204278826713562),\n",
       " ('betrayer', 0.5202812552452087),\n",
       " ('guess', 0.5148141384124756),\n",
       " ('suspicious', 0.509877622127533),\n",
       " ('liar', 0.5092313289642334),\n",
       " ('accuse', 0.5041293501853943),\n",
       " ('endanger', 0.503318727016449),\n",
       " ('screw', 0.49410340189933777),\n",
       " ('crime', 0.4901725947856903),\n",
       " ('mistake', 0.488399475812912),\n",
       " ('involvement', 0.4807293117046356),\n",
       " ('venturer', 0.47965100407600403),\n",
       " ('somebody', 0.4788859188556671),\n",
       " ('swear', 0.47824737429618835),\n",
       " ('falseness', 0.4729747772216797),\n",
       " ('bribery', 0.47139912843704224),\n",
       " ('confidential', 0.470358669757843),\n",
       " ('dependency', 0.46556609869003296),\n",
       " ('lies', 0.46410542726516724),\n",
       " ('error', 0.45918914675712585),\n",
       " ('surcharged', 0.4591740369796753),\n",
       " ('fake', 0.45580679178237915),\n",
       " ('compromise', 0.451487272977829),\n",
       " ('betcha', 0.4511880874633789),\n",
       " ('failure', 0.4447384178638458),\n",
       " ('falsehood', 0.4425085484981537),\n",
       " ('sulfide', 0.4407697916030884),\n",
       " ('deal', 0.4337957501411438),\n",
       " ('fuckup', 0.43327009677886963),\n",
       " ('investiture', 0.4330025315284729),\n",
       " ('lying', 0.4319751262664795),\n",
       " ('treacherous', 0.431511253118515),\n",
       " ('suspicion', 0.42461124062538147),\n",
       " ('credit', 0.4242776930332184),\n",
       " ('buyout', 0.4213581085205078),\n",
       " ('charge', 0.419428288936615),\n",
       " ('act', 0.4193337857723236)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'when someone you trust does something that breaks your trust', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('teach', 0.9946306943893433),\n",
       " ('educate', 0.9796843528747559),\n",
       " ('learn', 0.9754385948181152),\n",
       " ('tutor', 0.9596310257911682),\n",
       " ('train', 0.956894040107727),\n",
       " ('prepare', 0.9506540298461914),\n",
       " ('education', 0.9429842829704285),\n",
       " ('training', 0.927601158618927),\n",
       " ('trainer', 0.9044510722160339),\n",
       " ('instruction', 0.8917723298072815),\n",
       " ('trainee', 0.8876506090164185),\n",
       " ('develop', 0.8800643682479858),\n",
       " ('help', 0.8763608932495117),\n",
       " ('drill', 0.8746880292892456),\n",
       " ('instruct', 0.8685868978500366),\n",
       " ('tutoring', 0.8648293018341064),\n",
       " ('aid', 0.8603531122207642),\n",
       " ('inform', 0.8338075280189514),\n",
       " ('preparation', 0.8322434425354004),\n",
       " ('coach', 0.8235621452331543),\n",
       " ('groom', 0.8183148503303528),\n",
       " ('trained', 0.8138930797576904),\n",
       " ('instructive', 0.8135185837745667),\n",
       " ('improve', 0.8075883984565735),\n",
       " ('school', 0.8013655543327332),\n",
       " ('mentor', 0.798274576663971),\n",
       " ('support', 0.7881101369857788),\n",
       " ('tutorship', 0.7843430638313293),\n",
       " ('doctor', 0.7829017043113708),\n",
       " ('initiate', 0.7770995497703552),\n",
       " ('encourage', 0.7769811153411865),\n",
       " ('teacher', 0.768692672252655),\n",
       " ('change', 0.7540296912193298),\n",
       " ('instructor', 0.7511905431747437),\n",
       " ('read', 0.7501072287559509),\n",
       " ('lesson', 0.7449134588241577),\n",
       " ('learner', 0.7362695336341858),\n",
       " ('moderate', 0.7282755374908447),\n",
       " ('study', 0.7174226641654968),\n",
       " ('schooling', 0.7143806219100952),\n",
       " ('foster', 0.7051140069961548),\n",
       " ('preparing', 0.7033674716949463),\n",
       " ('guide', 0.6987031698226929),\n",
       " ('teachable', 0.6895352005958557),\n",
       " ('coaching', 0.6829950213432312),\n",
       " ('condition', 0.6803297996520996),\n",
       " ('tutorial', 0.673484206199646),\n",
       " ('preparer', 0.6610311269760132),\n",
       " ('cultivate', 0.6594364643096924),\n",
       " ('advance', 0.6533259153366089),\n",
       " ('follow', 0.6519191861152649),\n",
       " ('correct', 0.6504087448120117),\n",
       " ('preserve', 0.6503652930259705),\n",
       " ('resource', 0.6404168605804443),\n",
       " ('apprentice', 0.6403798460960388),\n",
       " ('readied', 0.6368281841278076),\n",
       " ('ready', 0.6336385011672974),\n",
       " ('give', 0.6183310747146606),\n",
       " ('provide', 0.6146432757377625),\n",
       " ('guiding', 0.6100024580955505),\n",
       " ('nurture', 0.6094933152198792),\n",
       " ('polish', 0.6067390441894531),\n",
       " ('check', 0.6046160459518433),\n",
       " ('lecture', 0.5999085903167725),\n",
       " ('discipline', 0.5987319350242615),\n",
       " ('take', 0.5899157524108887),\n",
       " ('disciple', 0.5847138166427612),\n",
       " ('handle', 0.5845144391059875),\n",
       " ('make', 0.582670271396637),\n",
       " ('preparatory', 0.5804764628410339),\n",
       " ('hold', 0.5788623690605164),\n",
       " ('substantiate', 0.5776742100715637),\n",
       " ('control', 0.5756844878196716),\n",
       " ('point', 0.5723004937171936),\n",
       " ('treat', 0.5608134269714355),\n",
       " ('supply', 0.5600990056991577),\n",
       " ('edify', 0.5515807867050171),\n",
       " ('address', 0.5499743223190308),\n",
       " ('improvement', 0.549046516418457),\n",
       " ('grooming', 0.5479718446731567),\n",
       " ('traineeship', 0.5472674369812012),\n",
       " ('translate', 0.543857753276825),\n",
       " ('accommodate', 0.5393438935279846),\n",
       " ('lead', 0.5327476263046265),\n",
       " ('educationist', 0.52836674451828),\n",
       " ('indulge', 0.5241977572441101),\n",
       " ('undergird', 0.5214686393737793),\n",
       " ('book', 0.5207694172859192),\n",
       " ('facilitate', 0.5186902284622192),\n",
       " ('drilled', 0.5167309045791626),\n",
       " ('usher', 0.5100717544555664),\n",
       " ('keep', 0.5079155564308167),\n",
       " ('cover', 0.507490873336792),\n",
       " ('better', 0.5039682388305664),\n",
       " ('apprenticed', 0.5034644603729248),\n",
       " ('nurse', 0.49859634041786194),\n",
       " ('strengthen', 0.495001882314682),\n",
       " ('doctoring', 0.49254149198532104),\n",
       " ('move', 0.48827776312828064),\n",
       " ('conduct', 0.4864210784435272)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'to help someone else learn', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalize', 0.9985143542289734),\n",
       " ('normalization', 0.9941756725311279),\n",
       " ('normal', 0.9729980230331421),\n",
       " ('regularize', 0.9526902437210083),\n",
       " ('modify', 0.9470736384391785),\n",
       " ('naturalise', 0.9366539120674133),\n",
       " ('change', 0.9286817908287048),\n",
       " ('amend', 0.9210201501846313),\n",
       " ('naturalize', 0.9168502688407898),\n",
       " ('secularize', 0.8821982741355896),\n",
       " ('alter', 0.8583032488822937),\n",
       " ('civilize', 0.8575515747070312),\n",
       " ('normalcy', 0.8489350080490112),\n",
       " ('regularization', 0.8364447951316833),\n",
       " ('modernize', 0.8240464329719543),\n",
       " ('acclimatize', 0.8122901916503906),\n",
       " ('normale', 0.7942690849304199),\n",
       " ('moralise', 0.7790758013725281),\n",
       " ('sublimate', 0.768255352973938),\n",
       " ('assimilate', 0.7592564225196838),\n",
       " ('standardize', 0.750598132610321),\n",
       " ('naturalization', 0.736865222454071),\n",
       " ('normality', 0.7347490191459656),\n",
       " ('specialize', 0.7294057607650757),\n",
       " ('improve', 0.682942807674408),\n",
       " ('rationalize', 0.6667715907096863),\n",
       " ('secularization', 0.6553975939750671),\n",
       " ('acclimate', 0.633479118347168),\n",
       " ('adjustment', 0.5933986902236938),\n",
       " ('acclimatise', 0.5834763050079346),\n",
       " ('condition', 0.5809730291366577),\n",
       " ('adjust', 0.55823814868927),\n",
       " ('norm', 0.5552682280540466),\n",
       " ('regulate', 0.5504721999168396),\n",
       " ('sublimated', 0.5479874610900879),\n",
       " ('regenerate', 0.5464208126068115),\n",
       " ('customize', 0.5426816940307617),\n",
       " ('correct', 0.5402244925498962),\n",
       " ('sanctify', 0.5401428937911987),\n",
       " ('regular', 0.5191425085067749),\n",
       " ('acclimatization', 0.5014768242835999),\n",
       " ('formalize', 0.49744713306427),\n",
       " ('amends', 0.49272844195365906),\n",
       " ('generalize', 0.447688490152359),\n",
       " ('educate', 0.4469294250011444),\n",
       " ('accommodate', 0.4296874403953552),\n",
       " ('regulation', 0.41907501220703125),\n",
       " ('etiolated', 0.4130633473396301),\n",
       " ('revivify', 0.40642890334129333),\n",
       " ('rectified', 0.40174901485443115),\n",
       " ('adapt', 0.4010692834854126),\n",
       " ('moralization', 0.4004298448562622),\n",
       " ('rectify', 0.3986433148384094),\n",
       " ('canonize', 0.3908371925354004),\n",
       " ('decentralize', 0.39015671610832214),\n",
       " ('make', 0.3890742063522339),\n",
       " ('acclimated', 0.38727709650993347),\n",
       " ('humanise', 0.38104796409606934),\n",
       " ('determine', 0.3763822913169861),\n",
       " ('changeover', 0.3678833246231079),\n",
       " ('changeability', 0.3611217737197876),\n",
       " ('extenuate', 0.3597114682197571),\n",
       " ('propertied', 0.35675477981567383),\n",
       " ('order', 0.35597673058509827),\n",
       " ('privatize', 0.3551945388317108),\n",
       " ('stylize', 0.3490907549858093),\n",
       " ('alternation', 0.3452437222003937),\n",
       " ('reformulate', 0.3419474959373474),\n",
       " ('rationalization', 0.33694392442703247),\n",
       " ('dress', 0.33016496896743774),\n",
       " ('regulating', 0.3295690715312958),\n",
       " ('conform', 0.321815550327301),\n",
       " ('humanize', 0.31464266777038574),\n",
       " ('sublimation', 0.3140943944454193),\n",
       " ('alterative', 0.31337228417396545),\n",
       " ('reform', 0.31226858496665955),\n",
       " ('universalize', 0.31120505928993225),\n",
       " ('substantiate', 0.3101885914802551),\n",
       " ('attenuate', 0.29575932025909424),\n",
       " ('nationalize', 0.2949710786342621),\n",
       " ('parasitize', 0.2941223084926605),\n",
       " ('optimize', 0.2937735617160797),\n",
       " ('develop', 0.29195401072502136),\n",
       " ('secular', 0.2864779829978943),\n",
       " ('regiment', 0.2862743139266968),\n",
       " ('adjusting', 0.2839316725730896),\n",
       " ('liberalize', 0.2823280990123749),\n",
       " ('actualize', 0.2795051038265228),\n",
       " ('right', 0.2786289155483246),\n",
       " ('rule', 0.2709861099720001),\n",
       " ('substitute', 0.2696237862110138),\n",
       " ('animistic', 0.26705580949783325),\n",
       " ('strategize', 0.26683276891708374),\n",
       " ('parallelize', 0.26670148968696594),\n",
       " ('decriminalize', 0.26541194319725037),\n",
       " ('ordinary', 0.2561621069908142),\n",
       " ('improvement', 0.25289276242256165),\n",
       " ('pattern', 0.25270408391952515),\n",
       " ('subliminal', 0.25026804208755493),\n",
       " ('purify', 0.24762549996376038)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, idx, probs = getPredFromDesc(model, 'to make something normal', 5, 100)\n",
    "[(word, prob.item()) for word, prob in zip(words, probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training beginning!\n",
    "\n",
    "Epoch 1, Train Loss: 1291.271240234375: 100%\n",
    "21117/21117 [1:51:20<00:00, 2.56it/s]\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "Epoch 1, Val Loss: 1454.054443359375: 100%\n",
    "2372/2372 [04:24<00:00, 8.54it/s]\n",
    "Test Loss: 687.0896606445312: 100%\n",
    "16/16 [00:01<00:00, 9.53it/s]\n",
    "\n",
    "seen_test_loss: tensor(672.2285, device='cuda:0')\n",
    "seen_test_acc1: 0.162\n",
    "seen_test_acc10: 0.512\n",
    "seen_test_acc100: 0.764\n",
    "seen_test_rank_median: tensor(8.)\n",
    "seen_test_rank_variance tensor(310.8351)\n",
    "\n",
    "Test Loss: 987.5115356445312: 100%\n",
    "16/16 [00:01<00:00, 11.16it/s]\n",
    "\n",
    "unseen_test_loss: tensor(980.4160, device='cuda:0')\n",
    "unseen_test_acc1: 0.112\n",
    "unseen_test_acc10: 0.33\n",
    "unseen_test_acc100: 0.59\n",
    "unseen_test_rank_median: tensor(47.)\n",
    "unseen_test_rank_variance tensor(401.8403)\n",
    "\n",
    "Test Loss: 1049.1865234375: 100%\n",
    "7/7 [00:00<00:00, 14.02it/s]\n",
    "\n",
    "desc_test_loss: tensor(980.0026, device='cuda:0')\n",
    "desc_test_acc1: 0.275\n",
    "desc_test_acc10: 0.725\n",
    "desc_test_acc100: 0.925\n",
    "desc_test_rank_median: tensor(3.)\n",
    "desc_test_rank_variance tensor(70.2536)\n",
    "\n",
    "Epoch 2, Train Loss: 879.2266235351562: 100%\n",
    "21117/21117 [1:51:54<00:00, 3.18it/s]\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "Epoch 2, Val Loss: 1426.1895751953125: 100%\n",
    "2372/2372 [04:24<00:00, 10.73it/s]\n",
    "Test Loss: 488.4723205566406: 100%\n",
    "16/16 [00:01<00:00, 9.56it/s]\n",
    "\n",
    "seen_test_loss: tensor(472.8967, device='cuda:0')\n",
    "seen_test_acc1: 0.214\n",
    "seen_test_acc10: 0.698\n",
    "seen_test_acc100: 0.894\n",
    "seen_test_rank_median: tensor(3.)\n",
    "seen_test_rank_variance tensor(215.4854)\n",
    "\n",
    "Test Loss: 947.445556640625: 100%\n",
    "16/16 [00:01<00:00, 11.18it/s]\n",
    "\n",
    "unseen_test_loss: tensor(940.1313, device='cuda:0')\n",
    "unseen_test_acc1: 0.102\n",
    "unseen_test_acc10: 0.362\n",
    "unseen_test_acc100: 0.636\n",
    "unseen_test_rank_median: tensor(30.)\n",
    "unseen_test_rank_variance tensor(380.8903)\n",
    "\n",
    "Test Loss: 944.8580322265625: 100%\n",
    "7/7 [00:00<00:00, 13.99it/s]\n",
    "\n",
    "desc_test_loss: tensor(878.2668, device='cuda:0')\n",
    "desc_test_acc1: 0.23\n",
    "desc_test_acc10: 0.715\n",
    "desc_test_acc100: 0.91\n",
    "desc_test_rank_median: tensor(3.)\n",
    "desc_test_rank_variance tensor(125.0875)\n",
    "\n",
    "Epoch 3, Train Loss: 686.5811157226562: 100%\n",
    "21117/21117 [1:52:03<00:00, 2.94it/s]\n",
    "Epoch 3, Val Loss: 1403.363525390625: 100%\n",
    "2372/2372 [04:23<00:00, 9.02it/s]\n",
    "Test Loss: 431.358642578125: 100%\n",
    "16/16 [00:01<00:00, 9.43it/s]\n",
    "\n",
    "seen_test_loss: tensor(417.4239, device='cuda:0')\n",
    "seen_test_acc1: 0.296\n",
    "seen_test_acc10: 0.772\n",
    "seen_test_acc100: 0.92\n",
    "seen_test_rank_median: tensor(2.)\n",
    "seen_test_rank_variance tensor(197.4330)\n",
    "\n",
    "Test Loss: 913.62841796875: 100%\n",
    "16/16 [00:01<00:00, 11.11it/s]\n",
    "\n",
    "unseen_test_loss: tensor(902.2078, device='cuda:0')\n",
    "unseen_test_acc1: 0.112\n",
    "unseen_test_acc10: 0.382\n",
    "unseen_test_acc100: 0.654\n",
    "unseen_test_rank_median: tensor(22.)\n",
    "unseen_test_rank_variance tensor(364.8770)\n",
    "\n",
    "Test Loss: 940.71826171875: 100%\n",
    "7/7 [00:00<00:00, 14.08it/s]\n",
    "\n",
    "desc_test_loss: tensor(870.6017, device='cuda:0')\n",
    "desc_test_acc1: 0.26\n",
    "desc_test_acc10: 0.675\n",
    "desc_test_acc100: 0.905\n",
    "desc_test_rank_median: tensor(4.)\n",
    "desc_test_rank_variance tensor(185.5576)\n",
    "\n",
    "Epoch 4, Train Loss: 560.3533935546875: 100%\n",
    "21117/21117 [1:51:45<00:00, 3.08it/s]\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "Epoch 6, Val Loss: 1457.1527099609375: 100%\n",
    "2372/2372 [04:23<00:00, 8.24it/s]\n",
    "Test Loss: 349.925048828125: 100%\n",
    "16/16 [00:01<00:00, 9.44it/s]\n",
    "\n",
    "seen_test_loss: tensor(335.5642, device='cuda:0')\n",
    "seen_test_acc1: 0.362\n",
    "seen_test_acc10: 0.86\n",
    "seen_test_acc100: 0.95\n",
    "seen_test_rank_median: tensor(1.)\n",
    "seen_test_rank_variance tensor(190.8087)\n",
    "\n",
    "Test Loss: 951.2265014648438: 100%\n",
    "16/16 [00:01<00:00, 11.15it/s]\n",
    "\n",
    "unseen_test_loss: tensor(932.3807, device='cuda:0')\n",
    "unseen_test_acc1: 0.112\n",
    "unseen_test_acc10: 0.434\n",
    "unseen_test_acc100: 0.696\n",
    "unseen_test_rank_median: tensor(16.)\n",
    "unseen_test_rank_variance tensor(358.9769)\n",
    "\n",
    "Test Loss: 1029.6146240234375: 100%\n",
    "7/7 [00:00<00:00, 14.20it/s]\n",
    "\n",
    "desc_test_loss: tensor(948.0621, device='cuda:0')\n",
    "desc_test_acc1: 0.215\n",
    "desc_test_acc10: 0.63\n",
    "desc_test_acc100: 0.87\n",
    "desc_test_rank_median: tensor(5.)\n",
    "desc_test_rank_variance tensor(235.2347)\n",
    "\n",
    "Epoch 7, Train Loss: 355.93682861328125: 4%\n",
    "902/21117 [04:48<2:05:44, 2.68it/s]\n",
    "\n",
    "Training beginning!\n",
    "\n",
    "Epoch 7, Train Loss: 354.0775146484375: 100%\n",
    "21117/21117 [1:51:25<00:00, 3.13it/s]\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "wandb: 500 encountered ({\"errors\":[{\"message\":\"Error 1040: Too many connections\",\"path\":[\"project\"]}],\"data\":{\"project\":null}}), retrying request\n",
    "wandb: Network error resolved after 0:00:56.213574, resuming normal operation.\n",
    "\n",
    "Epoch 7, Val Loss: 1486.6312255859375: 100%\n",
    "2372/2372 [04:23<00:00, 8.76it/s]\n",
    "Test Loss: 338.9664611816406: 100%\n",
    "16/16 [00:01<00:00, 9.56it/s]\n",
    "\n",
    "seen_test_loss: tensor(324.8030, device='cuda:0')\n",
    "seen_test_acc1: 0.378\n",
    "seen_test_acc10: 0.866\n",
    "seen_test_acc100: 0.948\n",
    "seen_test_rank_median: tensor(1.)\n",
    "seen_test_rank_variance tensor(174.6115)\n",
    "\n",
    "Test Loss: 961.43212890625: 100%\n",
    "16/16 [00:01<00:00, 11.15it/s]\n",
    "\n",
    "unseen_test_loss: tensor(949.6530, device='cuda:0')\n",
    "unseen_test_acc1: 0.11\n",
    "unseen_test_acc10: 0.45\n",
    "unseen_test_acc100: 0.71\n",
    "unseen_test_rank_median: tensor(14.)\n",
    "unseen_test_rank_variance tensor(355.9951)\n",
    "\n",
    "Test Loss: 1055.6123046875: 100%\n",
    "7/7 [00:00<00:00, 14.06it/s]\n",
    "\n",
    "desc_test_loss: tensor(986.2967, device='cuda:0')\n",
    "desc_test_acc1: 0.225\n",
    "desc_test_acc10: 0.625\n",
    "desc_test_acc100: 0.885\n",
    "desc_test_rank_median: tensor(4.)\n",
    "desc_test_rank_variance tensor(241.3334)\n",
    "\n",
    "Epoch 8, Train Loss: 317.3240051269531: 100%\n",
    "21117/21117 [1:51:37<00:00, 3.36it/s]\n",
    "Epoch 8, Val Loss: 1510.5469970703125: 100%\n",
    "2372/2372 [04:21<00:00, 8.90it/s]\n",
    "Test Loss: 326.8212585449219: 100%\n",
    "16/16 [00:01<00:00, 9.56it/s]\n",
    "\n",
    "seen_test_loss: tensor(312.5106, device='cuda:0')\n",
    "seen_test_acc1: 0.388\n",
    "seen_test_acc10: 0.876\n",
    "seen_test_acc100: 0.95\n",
    "seen_test_rank_median: tensor(1.)\n",
    "seen_test_rank_variance tensor(169.8056)\n",
    "\n",
    "Test Loss: 977.635498046875: 100%\n",
    "16/16 [00:01<00:00, 11.21it/s]\n",
    "\n",
    "unseen_test_loss: tensor(968.0921, device='cuda:0')\n",
    "unseen_test_acc1: 0.12\n",
    "unseen_test_acc10: 0.448\n",
    "unseen_test_acc100: 0.714\n",
    "unseen_test_rank_median: tensor(14.)\n",
    "unseen_test_rank_variance tensor(355.5157)\n",
    "\n",
    "Test Loss: 1053.174072265625: 100%\n",
    "7/7 [00:00<00:00, 14.09it/s]\n",
    "\n",
    "desc_test_loss: tensor(979.2820, device='cuda:0')\n",
    "desc_test_acc1: 0.21\n",
    "desc_test_acc10: 0.63\n",
    "desc_test_acc100: 0.88\n",
    "desc_test_rank_median: tensor(4.)\n",
    "desc_test_rank_variance tensor(249.2989)\n",
    "\n",
    "Epoch 9, Train Loss: 290.9953308105469: 100%\n",
    "21117/21117 [1:51:28<00:00, 2.83it/s]\n",
    "Epoch 9, Val Loss: 1540.5982666015625: 100%\n",
    "2372/2372 [04:21<00:00, 9.60it/s]\n",
    "Test Loss: 324.8987121582031: 100%\n",
    "16/16 [00:01<00:00, 9.66it/s]\n",
    "\n",
    "seen_test_loss: tensor(310.3402, device='cuda:0')\n",
    "seen_test_acc1: 0.4\n",
    "seen_test_acc10: 0.888\n",
    "seen_test_acc100: 0.95\n",
    "seen_test_rank_median: tensor(1.)\n",
    "seen_test_rank_variance tensor(176.8679)\n",
    "\n",
    "Test Loss: 988.954345703125: 100%\n",
    "16/16 [00:01<00:00, 11.23it/s]\n",
    "\n",
    "unseen_test_loss: tensor(977.1419, device='cuda:0')\n",
    "unseen_test_acc1: 0.114\n",
    "unseen_test_acc10: 0.454\n",
    "unseen_test_acc100: 0.722\n",
    "unseen_test_rank_median: tensor(13.)\n",
    "unseen_test_rank_variance tensor(359.3176)\n",
    "\n",
    "Test Loss: 1111.536376953125: 100%\n",
    "7/7 [00:00<00:00, 14.21it/s]\n",
    "\n",
    "desc_test_loss: tensor(1031.1094, device='cuda:0')\n",
    "desc_test_acc1: 0.17\n",
    "desc_test_acc10: 0.62\n",
    "desc_test_acc100: 0.88\n",
    "desc_test_rank_median: tensor(4.)\n",
    "desc_test_rank_variance tensor(260.9289)\n",
    "\n",
    "Epoch 10, Train Loss: 273.5261535644531: 84%\n",
    "17674/21117 [1:33:12<17:46, 3.23it/s]\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_msg_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "Test Loss: 324.5528869628906: 100%\n",
    "16/16 [00:01<00:00, 9.67it/s]\n",
    "\n",
    "seen_test_loss: tensor(309.9997, device='cuda:0')\n",
    "seen_test_acc1: 0.384\n",
    "seen_test_acc10: 0.892\n",
    "seen_test_acc100: 0.95\n",
    "seen_test_rank_median: tensor(1.)\n",
    "seen_test_rank_variance tensor(175.3214)\n",
    "\n",
    "Test Loss: 991.7783813476562: 100%\n",
    "16/16 [00:01<00:00, 11.24it/s]\n",
    "\n",
    "unseen_test_loss: tensor(979.3575, device='cuda:0')\n",
    "unseen_test_acc1: 0.124\n",
    "unseen_test_acc10: 0.444\n",
    "unseen_test_acc100: 0.726\n",
    "unseen_test_rank_median: tensor(13.)\n",
    "unseen_test_rank_variance tensor(358.8594)\n",
    "\n",
    "Test Loss: 1110.7630615234375: 100%\n",
    "7/7 [00:00<00:00, 14.23it/s]\n",
    "\n",
    "desc_test_loss: tensor(1029.1157, device='cuda:0')\n",
    "desc_test_acc1: 0.205\n",
    "desc_test_acc10: 0.64\n",
    "desc_test_acc100: 0.875\n",
    "desc_test_rank_median: tensor(5.)\n",
    "desc_test_rank_variance tensor(262.6233)\n",
    "\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'He is a programmer',\n",
       "  'score': 0.017467252910137177,\n",
       "  'token': 894,\n",
       "  'token_str': 'He'},\n",
       " {'sequence': 'Daniel is a programmer',\n",
       "  'score': 0.008494171313941479,\n",
       "  'token': 18322,\n",
       "  'token_str': 'Daniel'},\n",
       " {'sequence': ' who is a programmer',\n",
       "  'score': 0.006517456378787756,\n",
       "  'token': 54,\n",
       "  'token_str': ' who'},\n",
       " {'sequence': 'Who is a programmer',\n",
       "  'score': 0.006088791415095329,\n",
       "  'token': 12375,\n",
       "  'token_str': 'Who'},\n",
       " {'sequence': 'David is a programmer',\n",
       "  'score': 0.005976406391710043,\n",
       "  'token': 8773,\n",
       "  'token_str': 'David'},\n",
       " {'sequence': 'James is a programmer',\n",
       "  'score': 0.005649610422551632,\n",
       "  'token': 18031,\n",
       "  'token_str': 'James'},\n",
       " {'sequence': 'Craig is a programmer',\n",
       "  'score': 0.005570814944803715,\n",
       "  'token': 39230,\n",
       "  'token_str': 'Craig'},\n",
       " {'sequence': 'Smith is a programmer',\n",
       "  'score': 0.005305597558617592,\n",
       "  'token': 14124,\n",
       "  'token_str': 'Smith'},\n",
       " {'sequence': 'Cook is a programmer',\n",
       "  'score': 0.0049401517026126385,\n",
       "  'token': 32963,\n",
       "  'token_str': 'Cook'},\n",
       " {'sequence': 'Simon is a programmer',\n",
       "  'score': 0.004889666102826595,\n",
       "  'token': 37422,\n",
       "  'token_str': 'Simon'},\n",
       " {'sequence': 'Williams is a programmer',\n",
       "  'score': 0.004674334079027176,\n",
       "  'token': 23886,\n",
       "  'token_str': 'Williams'},\n",
       " {'sequence': 'Andrew is a programmer',\n",
       "  'score': 0.004664448089897633,\n",
       "  'token': 19843,\n",
       "  'token_str': 'Andrew'},\n",
       " {'sequence': 'She is a programmer',\n",
       "  'score': 0.004455982241779566,\n",
       "  'token': 2515,\n",
       "  'token_str': 'She'},\n",
       " {'sequence': 'Wilson is a programmer',\n",
       "  'score': 0.0043203202076256275,\n",
       "  'token': 38455,\n",
       "  'token_str': 'Wilson'},\n",
       " {'sequence': 'Ryan is a programmer',\n",
       "  'score': 0.0042943814769387245,\n",
       "  'token': 23287,\n",
       "  'token_str': 'Ryan'},\n",
       " {'sequence': 'who is a programmer',\n",
       "  'score': 0.004270573146641254,\n",
       "  'token': 8155,\n",
       "  'token_str': 'who'},\n",
       " {'sequence': 'Martin is a programmer',\n",
       "  'score': 0.0042494251392781734,\n",
       "  'token': 26690,\n",
       "  'token_str': 'Martin'},\n",
       " {'sequence': 'Paul is a programmer',\n",
       "  'score': 0.004148836247622967,\n",
       "  'token': 12083,\n",
       "  'token_str': 'Paul'},\n",
       " {'sequence': ' He is a programmer',\n",
       "  'score': 0.0040120347402989864,\n",
       "  'token': 91,\n",
       "  'token_str': ' He'},\n",
       " {'sequence': 'Anderson is a programmer',\n",
       "  'score': 0.0039228168316185474,\n",
       "  'token': 41186,\n",
       "  'token_str': 'Anderson'},\n",
       " {'sequence': 'Dan is a programmer',\n",
       "  'score': 0.003922334406524897,\n",
       "  'token': 25887,\n",
       "  'token_str': 'Dan'},\n",
       " {'sequence': 'Brian is a programmer',\n",
       "  'score': 0.0038770590908825397,\n",
       "  'token': 28915,\n",
       "  'token_str': 'Brian'},\n",
       " {'sequence': 'Lee is a programmer',\n",
       "  'score': 0.003714634571224451,\n",
       "  'token': 24403,\n",
       "  'token_str': 'Lee'},\n",
       " {'sequence': 'Michael is a programmer',\n",
       "  'score': 0.0036356947384774685,\n",
       "  'token': 14009,\n",
       "  'token_str': 'Michael'},\n",
       " {'sequence': ' he is a programmer',\n",
       "  'score': 0.0035508035216480494,\n",
       "  'token': 37,\n",
       "  'token_str': ' he'},\n",
       " {'sequence': 'Moore is a programmer',\n",
       "  'score': 0.003534129587933421,\n",
       "  'token': 34787,\n",
       "  'token_str': 'Moore'},\n",
       " {'sequence': 'he is a programmer',\n",
       "  'score': 0.003522943938151002,\n",
       "  'token': 700,\n",
       "  'token_str': 'he'},\n",
       " {'sequence': 'Thomas is a programmer',\n",
       "  'score': 0.00350892823189497,\n",
       "  'token': 25089,\n",
       "  'token_str': 'Thomas'},\n",
       " {'sequence': 'John is a programmer',\n",
       "  'score': 0.0034495647996664047,\n",
       "  'token': 10567,\n",
       "  'token_str': 'John'},\n",
       " {'sequence': 'Johnson is a programmer',\n",
       "  'score': 0.003331052139401436,\n",
       "  'token': 31894,\n",
       "  'token_str': 'Johnson'},\n",
       " {'sequence': 'Clark is a programmer',\n",
       "  'score': 0.003241533413529396,\n",
       "  'token': 36243,\n",
       "  'token_str': 'Clark'},\n",
       " {'sequence': 'Adam is a programmer',\n",
       "  'score': 0.0031087843235582113,\n",
       "  'token': 24671,\n",
       "  'token_str': 'Adam'},\n",
       " {'sequence': 'Taylor is a programmer',\n",
       "  'score': 0.0030480443965643644,\n",
       "  'token': 32799,\n",
       "  'token_str': 'Taylor'},\n",
       " {'sequence': 'Davis is a programmer',\n",
       "  'score': 0.0030007516033947468,\n",
       "  'token': 36787,\n",
       "  'token_str': 'Davis'},\n",
       " {'sequence': 'Luke is a programmer',\n",
       "  'score': 0.0029999518301337957,\n",
       "  'token': 34899,\n",
       "  'token_str': 'Luke'},\n",
       " {'sequence': 'Tyler is a programmer',\n",
       "  'score': 0.002975480630993843,\n",
       "  'token': 40270,\n",
       "  'token_str': 'Tyler'},\n",
       " {'sequence': 'Chris is a programmer',\n",
       "  'score': 0.0029628050979226828,\n",
       "  'token': 16084,\n",
       "  'token_str': 'Chris'},\n",
       " {'sequence': 'Nick is a programmer',\n",
       "  'score': 0.002948530949652195,\n",
       "  'token': 25602,\n",
       "  'token_str': 'Nick'},\n",
       " {'sequence': 'Brown is a programmer',\n",
       "  'score': 0.0029455418698489666,\n",
       "  'token': 24057,\n",
       "  'token_str': 'Brown'},\n",
       " {'sequence': 'Scott is a programmer',\n",
       "  'score': 0.0028679652605205774,\n",
       "  'token': 22041,\n",
       "  'token_str': 'Scott'},\n",
       " {'sequence': 'Lewis is a programmer',\n",
       "  'score': 0.002699116012081504,\n",
       "  'token': 32828,\n",
       "  'token_str': 'Lewis'},\n",
       " {'sequence': 'Aaron is a programmer',\n",
       "  'score': 0.0026974333450198174,\n",
       "  'token': 29934,\n",
       "  'token_str': 'Aaron'},\n",
       " {'sequence': 'Patrick is a programmer',\n",
       "  'score': 0.002683919155970216,\n",
       "  'token': 32811,\n",
       "  'token_str': 'Patrick'},\n",
       " {'sequence': 'Guy is a programmer',\n",
       "  'score': 0.0026313739363104105,\n",
       "  'token': 38624,\n",
       "  'token_str': 'Guy'},\n",
       " {'sequence': 'Jones is a programmer',\n",
       "  'score': 0.002583974041044712,\n",
       "  'token': 22681,\n",
       "  'token_str': 'Jones'},\n",
       " {'sequence': 'Peter is a programmer',\n",
       "  'score': 0.002574001904577017,\n",
       "  'token': 22611,\n",
       "  'token_str': 'Peter'},\n",
       " {'sequence': 'Thompson is a programmer',\n",
       "  'score': 0.002544101094827056,\n",
       "  'token': 41835,\n",
       "  'token_str': 'Thompson'},\n",
       " {'sequence': 'Tom is a programmer',\n",
       "  'score': 0.002471021842211485,\n",
       "  'token': 15691,\n",
       "  'token_str': 'Tom'},\n",
       " {'sequence': 'Allen is a programmer',\n",
       "  'score': 0.002467955695465207,\n",
       "  'token': 32291,\n",
       "  'token_str': 'Allen'},\n",
       " {'sequence': 'Graham is a programmer',\n",
       "  'score': 0.0022884972859174013,\n",
       "  'token': 42144,\n",
       "  'token_str': 'Graham'},\n",
       " {'sequence': 'Kelly is a programmer',\n",
       "  'score': 0.002243002178147435,\n",
       "  'token': 34313,\n",
       "  'token_str': 'Kelly'},\n",
       " {'sequence': 'Joshua is a programmer',\n",
       "  'score': 0.002238882938399911,\n",
       "  'token': 36706,\n",
       "  'token_str': 'Joshua'},\n",
       " {'sequence': 'Matthew is a programmer',\n",
       "  'score': 0.00221523130312562,\n",
       "  'token': 33667,\n",
       "  'token_str': 'Matthew'},\n",
       " {'sequence': 'Sullivan is a programmer',\n",
       "  'score': 0.002203534357249737,\n",
       "  'token': 26745,\n",
       "  'token_str': 'Sullivan'},\n",
       " {'sequence': 'Mike is a programmer',\n",
       "  'score': 0.0021850396879017353,\n",
       "  'token': 15827,\n",
       "  'token_str': 'Mike'},\n",
       " {'sequence': 'Bob is a programmer',\n",
       "  'score': 0.002166939899325371,\n",
       "  'token': 25158,\n",
       "  'token_str': 'Bob'},\n",
       " {'sequence': 'Joe is a programmer',\n",
       "  'score': 0.0021567903459072113,\n",
       "  'token': 18393,\n",
       "  'token_str': 'Joe'},\n",
       " {'sequence': 'Murray is a programmer',\n",
       "  'score': 0.0021430673077702522,\n",
       "  'token': 42463,\n",
       "  'token_str': 'Murray'},\n",
       " {'sequence': 'Harris is a programmer',\n",
       "  'score': 0.00214097136631608,\n",
       "  'token': 37302,\n",
       "  'token_str': 'Harris'},\n",
       " {'sequence': 'Lin is a programmer',\n",
       "  'score': 0.0020459075458347797,\n",
       "  'token': 40253,\n",
       "  'token_str': 'Lin'},\n",
       " {'sequence': 'Steve is a programmer',\n",
       "  'score': 0.0020350879058241844,\n",
       "  'token': 21976,\n",
       "  'token_str': 'Steve'},\n",
       " {'sequence': 'Blake is a programmer',\n",
       "  'score': 0.002030752832069993,\n",
       "  'token': 40856,\n",
       "  'token_str': 'Blake'},\n",
       " {'sequence': 'Jack is a programmer',\n",
       "  'score': 0.0020175615791231394,\n",
       "  'token': 20907,\n",
       "  'token_str': 'Jack'},\n",
       " {'sequence': 'Yang is a programmer',\n",
       "  'score': 0.001972184283658862,\n",
       "  'token': 47235,\n",
       "  'token_str': 'Yang'},\n",
       " {'sequence': 'Gordon is a programmer',\n",
       "  'score': 0.001955001149326563,\n",
       "  'token': 43226,\n",
       "  'token_str': 'Gordon'},\n",
       " {'sequence': 'Jackson is a programmer',\n",
       "  'score': 0.001933245686814189,\n",
       "  'token': 29951,\n",
       "  'token_str': 'Jackson'},\n",
       " {'sequence': 'Miller is a programmer',\n",
       "  'score': 0.001870697713457048,\n",
       "  'token': 34534,\n",
       "  'token_str': 'Miller'},\n",
       " {'sequence': 'Dave is a programmer',\n",
       "  'score': 0.0018666425021365285,\n",
       "  'token': 33857,\n",
       "  'token_str': 'Dave'},\n",
       " {'sequence': 'Robert is a programmer',\n",
       "  'score': 0.0018108129734173417,\n",
       "  'token': 25244,\n",
       "  'token_str': 'Robert'},\n",
       " {'sequence': 'Roberts is a programmer',\n",
       "  'score': 0.0018058961722999811,\n",
       "  'token': 42178,\n",
       "  'token_str': 'Roberts'},\n",
       " {'sequence': 'Charles is a programmer',\n",
       "  'score': 0.0017951257759705186,\n",
       "  'token': 29217,\n",
       "  'token_str': 'Charles'},\n",
       " {'sequence': ' Smith is a programmer',\n",
       "  'score': 0.0017854450270533562,\n",
       "  'token': 1259,\n",
       "  'token_str': ' Smith'},\n",
       " {'sequence': 'Rob is a programmer',\n",
       "  'score': 0.0017490206519141793,\n",
       "  'token': 18776,\n",
       "  'token_str': 'Rob'},\n",
       " {'sequence': 'Sanders is a programmer',\n",
       "  'score': 0.0017397089395672083,\n",
       "  'token': 45388,\n",
       "  'token_str': 'Sanders'},\n",
       " {'sequence': 'Hamilton is a programmer',\n",
       "  'score': 0.0017358680488541722,\n",
       "  'token': 31382,\n",
       "  'token_str': 'Hamilton'},\n",
       " {'sequence': 'Alexander is a programmer',\n",
       "  'score': 0.001724440953694284,\n",
       "  'token': 33409,\n",
       "  'token_str': 'Alexander'},\n",
       " {'sequence': 'Richard is a programmer',\n",
       "  'score': 0.0016933352453634143,\n",
       "  'token': 27845,\n",
       "  'token_str': 'Richard'},\n",
       " {'sequence': 'Andy is a programmer',\n",
       "  'score': 0.0016875381115823984,\n",
       "  'token': 32743,\n",
       "  'token_str': 'Andy'},\n",
       " {'sequence': 'Collins is a programmer',\n",
       "  'score': 0.0016791349044069648,\n",
       "  'token': 40380,\n",
       "  'token_str': 'Collins'},\n",
       " {'sequence': 'Eric is a programmer',\n",
       "  'score': 0.0016770896036177874,\n",
       "  'token': 24375,\n",
       "  'token_str': 'Eric'},\n",
       " {'sequence': 'Jacob is a programmer',\n",
       "  'score': 0.001666876021772623,\n",
       "  'token': 41884,\n",
       "  'token_str': 'Jacob'},\n",
       " {'sequence': 'Hart is a programmer',\n",
       "  'score': 0.001650165650062263,\n",
       "  'token': 39657,\n",
       "  'token_str': 'Hart'},\n",
       " {'sequence': 'Price is a programmer',\n",
       "  'score': 0.0016476683085784316,\n",
       "  'token': 36677,\n",
       "  'token_str': 'Price'},\n",
       " {'sequence': 'Grant is a programmer',\n",
       "  'score': 0.0016410356620326638,\n",
       "  'token': 41793,\n",
       "  'token_str': 'Grant'},\n",
       " {'sequence': 'Kevin is a programmer',\n",
       "  'score': 0.0016159559600055218,\n",
       "  'token': 21910,\n",
       "  'token_str': 'Kevin'},\n",
       " {'sequence': 'Mark is a programmer',\n",
       "  'score': 0.0015706343110650778,\n",
       "  'token': 10006,\n",
       "  'token_str': 'Mark'},\n",
       " {'sequence': 'Russell is a programmer',\n",
       "  'score': 0.001549956388771534,\n",
       "  'token': 40575,\n",
       "  'token_str': 'Russell'},\n",
       " {'sequence': 'Marco is a programmer',\n",
       "  'score': 0.0015467189950868487,\n",
       "  'token': 33441,\n",
       "  'token_str': 'Marco'},\n",
       " {'sequence': 'Matt is a programmer',\n",
       "  'score': 0.0015393737703561783,\n",
       "  'token': 19860,\n",
       "  'token_str': 'Matt'},\n",
       " {'sequence': 'Weiss is a programmer',\n",
       "  'score': 0.0015278976643458009,\n",
       "  'token': 48069,\n",
       "  'token_str': 'Weiss'},\n",
       " {'sequence': 'Alex is a programmer',\n",
       "  'score': 0.0015123935882002115,\n",
       "  'token': 16804,\n",
       "  'token_str': 'Alex'},\n",
       " {'sequence': 'Reilly is a programmer',\n",
       "  'score': 0.001509150373749435,\n",
       "  'token': 16626,\n",
       "  'token_str': 'Reilly'},\n",
       " {'sequence': 'Joseph is a programmer',\n",
       "  'score': 0.0014966822927817702,\n",
       "  'token': 36744,\n",
       "  'token_str': 'Joseph'},\n",
       " {'sequence': 'White is a programmer',\n",
       "  'score': 0.0014904307899996638,\n",
       "  'token': 15725,\n",
       "  'token_str': 'White'},\n",
       " {'sequence': 'Stephen is a programmer',\n",
       "  'score': 0.0014802126679569483,\n",
       "  'token': 30273,\n",
       "  'token_str': 'Stephen'},\n",
       " {'sequence': 'Josh is a programmer',\n",
       "  'score': 0.0014769386034458876,\n",
       "  'token': 32879,\n",
       "  'token_str': 'Josh'},\n",
       " {'sequence': 'Hall is a programmer',\n",
       "  'score': 0.0014766836538910866,\n",
       "  'token': 31908,\n",
       "  'token_str': 'Hall'},\n",
       " {'sequence': 'Doug is a programmer',\n",
       "  'score': 0.00146476028021425,\n",
       "  'token': 37036,\n",
       "  'token_str': 'Doug'},\n",
       " {'sequence': 'Adams is a programmer',\n",
       "  'score': 0.0014639608561992645,\n",
       "  'token': 36288,\n",
       "  'token_str': 'Adams'},\n",
       " {'sequence': 'Walker is a programmer',\n",
       "  'score': 0.0014625339535996318,\n",
       "  'token': 41388,\n",
       "  'token_str': 'Walker'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(\"<mask> is a programmer\", top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'oust',\n",
       " 'lexnames': ['verb.social'],\n",
       " 'root_affix': [],\n",
       " 'sememes': ['dismiss', 'expel'],\n",
       " 'definitions': 'remove and replace'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_unseen[442]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'bert', 'lexnames': [], 'root_affix': [], 'sememes': [], 'definitions': 'a diminutive form of male given names containing the element bert also used as a formal given name'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    if train_data[i]['word'] == 'bert':\n",
    "        print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synonyms': [],\n",
       " 'antonyms': [],\n",
       " 'related_forms': [],\n",
       " 'hyponyms': [],\n",
       " 'hypernyms': []}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "049faeb3947c48ac1b8702363c1a3bc597f6c2e1e1396be70d54511d980ab606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
