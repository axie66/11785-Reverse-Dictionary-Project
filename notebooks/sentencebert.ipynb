{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append('../code')\n",
    "from dataset import get_data, make_vocab, WantWordsDataset as WWDataset\n",
    "\n",
    "from transformers import (\n",
    "    AdamW, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from models import SentenceBERTForRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training data: 675715 word-def pairs\n",
      "Dev data: 75873 word-def pairs\n",
      "Test data: 1200 word-def pairs\n"
     ]
    }
   ],
   "source": [
    "d = get_data('../wantwords-english-baseline/data', word2vec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_def, dev_data, test_data_seen, \\\n",
    "    test_data_unseen, test_data_desc = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target2idx, idx2target = make_vocab(d, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16187, 'book')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target2idx maps target words to indices\n",
    "# target_matrix maps target indices to bpe sequences, padded/truncated to mask_size\n",
    "target2idx['book'], idx2target[target2idx['book']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can freeze for (part of) first epoch or so and then unfreeze to train the whole model\n",
    "model = SentenceBERTForRD('distilbert-base-nli-stsb-mean-tokens', \n",
    "                          len(target2idx), freeze_sbert=True, criterion=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = model.sbert.tokenizer\n",
    "train_dataset = WWDataset(train_data + train_data_def, T, target2idx)\n",
    "dev_dataset = WWDataset(dev_data, T, target2idx)\n",
    "test_dataset_seen = WWDataset(test_data_seen, T, target2idx)\n",
    "test_dataset_unseen = WWDataset(test_data_unseen, T, target2idx)\n",
    "test_dataset_desc = WWDataset(test_data_desc, T, target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "loader_params = {\n",
    "    'pin_memory': False,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'collate_fn': train_dataset.collate_fn\n",
    "}\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, **{'shuffle': True, **loader_params})\n",
    "dev_loader = data.DataLoader(dev_dataset, **{'shuffle': True, **loader_params})\n",
    "test_loader_seen = data.DataLoader(test_dataset_seen, **{'shuffle': False, **loader_params})\n",
    "test_loader_unseen = data.DataLoader(test_dataset_unseen, **{'shuffle': False, **loader_params})\n",
    "test_loader_desc = data.DataLoader(test_dataset_desc, **{'shuffle': False, **loader_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "lr = 2e-5\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "warmup_duration = 0.01 # portion of the first epoch spent on lr warmup\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=len(train_loader) * warmup_duration, \n",
    "                                            num_training_steps=len(train_loader) * epochs)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreverse-dict\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eternal-rain-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary/runs/3p9wf9hp\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary/runs/3p9wf9hp</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/dl/11785-Reverse-Dictionary-Project/notebooks/wandb/run-20210505_075722-3p9wf9hp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7fb0a7ec24d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='reverse-dictionary', entity='reverse-dict')\n",
    "\n",
    "config = wandb.config\n",
    "config.learning_rate = lr\n",
    "config.epochs = epochs\n",
    "config.batch_size = batch_size\n",
    "config.optimizer = type(optim).__name__\n",
    "config.scheduler = type(scheduler).__name__\n",
    "config.warmup_duration = warmup_duration\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, gt, test=False):\n",
    "    acc1 = acc10 = acc100 = 0\n",
    "    n = len(pred)\n",
    "    pred_rank = []\n",
    "    for p, word in zip(pred, gt):\n",
    "        if test:\n",
    "            loc = (p == word).nonzero(as_tuple=True)\n",
    "            if len(loc) != 0:\n",
    "                pred_rank.append(min(loc[-1], 1000))\n",
    "            else:\n",
    "                pred_rank.append(1000)\n",
    "        if word in p[:100]:\n",
    "            acc100 += 1\n",
    "            if word in p[:10]:\n",
    "                acc10 += 1\n",
    "                if word == p[0]:\n",
    "                    acc1 += 1\n",
    "    if test:\n",
    "        pred_rank = torch.tensor(pred_rank, dtype=torch.float32)\n",
    "        return (acc1, acc10, acc100, pred_rank)\n",
    "    else:\n",
    "        return acc1/n, acc10/n, acc100/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, name):\n",
    "    inc = 3\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc1 = test_acc10 = test_acc100 = 0.0\n",
    "    total_seen = 0\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(loader)) as pbar:\n",
    "            for i, ((x, attention_mask), y) in enumerate(loader):\n",
    "                if i % inc == 0 and i != 0:\n",
    "                    display_loss = test_loss / i\n",
    "                    pbar.set_description(f'Test Loss: {display_loss}')\n",
    "\n",
    "                x = x.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "#                 with autocast():\n",
    "                loss, out = model(input_ids=x, attention_mask=attention_mask,\n",
    "                                  ground_truth=y)\n",
    "\n",
    "                test_loss += loss.detach()\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "                result, indices = torch.sort(out, descending=True)\n",
    "                \n",
    "                b = len(x)\n",
    "                acc1, acc10, acc100, pred_rank = evaluate(indices, y, test=True)\n",
    "                test_acc1 += acc1\n",
    "                test_acc10 += acc10\n",
    "                test_acc100 += acc100\n",
    "                total_seen += b\n",
    "                all_pred.extend(pred_rank)\n",
    "                \n",
    "                del x, y, out, loss\n",
    "                if i % 20 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "    test_loss /= len(loader)\n",
    "    test_acc1 /= total_seen\n",
    "    test_acc10 /= total_seen\n",
    "    test_acc100 /= total_seen\n",
    "    all_pred = torch.tensor(all_pred)\n",
    "    median = torch.median(all_pred)\n",
    "    var = torch.var(all_pred)**0.5\n",
    "    \n",
    "    print(f'{name}_test_loss:', test_loss)\n",
    "    print(f'{name}_test_acc1:', test_acc1)\n",
    "    print(f'{name}_test_acc10:', test_acc10)\n",
    "    print(f'{name}_test_acc100:', test_acc100)\n",
    "    print(f'{name}_test_rank_median:', median)\n",
    "    print(f'{name}_test_rank_variance', var)\n",
    "    \n",
    "    return ({\n",
    "        f'{name}_test_loss': test_loss,\n",
    "        f'{name}_test_acc1': test_acc1,\n",
    "        f'{name}_test_acc10': test_acc10,\n",
    "        f'{name}_test_acc100': test_acc100,\n",
    "        f'{name}_test_rank_median': median,\n",
    "        f'{name}_test_rank_variance': var\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062a0358e4114c87b69adc9c78cf4d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2566e8a9e84e478fc82da2dc79e26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(5.4102, device='cuda:0')\n",
      "seen_test_acc1: 0.292\n",
      "seen_test_acc10: 0.556\n",
      "seen_test_acc100: 0.766\n",
      "seen_test_rank_median: tensor(5.)\n",
      "seen_test_rank_variance tensor(357.2637)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2226dede364228ac0423cb81a1aee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(15.1948, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.004\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(84.4202)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f56e55a333f4113923823618fb80f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.2677, device='cuda:0')\n",
      "desc_test_acc1: 0.29\n",
      "desc_test_acc10: 0.585\n",
      "desc_test_acc100: 0.85\n",
      "desc_test_rank_median: tensor(5.)\n",
      "desc_test_rank_variance tensor(212.4294)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8325e9777f904076b8842fc30f32d560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6689bcef3e0f432e9f612935db78e29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(4.5583, device='cuda:0')\n",
      "seen_test_acc1: 0.422\n",
      "seen_test_acc10: 0.67\n",
      "seen_test_acc100: 0.824\n",
      "seen_test_rank_median: tensor(1.)\n",
      "seen_test_rank_variance tensor(345.5203)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f74294f1444169ab55b178be9f569f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(16.1992, device='cuda:0')\n",
      "unseen_test_acc1: 0.002\n",
      "unseen_test_acc10: 0.004\n",
      "unseen_test_acc100: 0.008\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(87.3857)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4fa95df04941f8bc02d8ab7c8c67e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.1939, device='cuda:0')\n",
      "desc_test_acc1: 0.255\n",
      "desc_test_acc10: 0.575\n",
      "desc_test_acc100: 0.835\n",
      "desc_test_rank_median: tensor(6.)\n",
      "desc_test_rank_variance tensor(224.9331)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee06e2880754aba9424f1539335f20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7cf20e4b6849208ed731f6e261e7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e66efca0a6e48c3aec1781a5cca3c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(4.1312, device='cuda:0')\n",
      "seen_test_acc1: 0.46\n",
      "seen_test_acc10: 0.736\n",
      "seen_test_acc100: 0.844\n",
      "seen_test_rank_median: tensor(1.)\n",
      "seen_test_rank_variance tensor(345.2461)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84647901ea14067adeb4d349784a215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(17.0107, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.004\n",
      "unseen_test_acc100: 0.008\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(88.4190)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dcf8c5ec51402ea9aaa90799a6959a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.2017, device='cuda:0')\n",
      "desc_test_acc1: 0.26\n",
      "desc_test_acc10: 0.555\n",
      "desc_test_acc100: 0.845\n",
      "desc_test_rank_median: tensor(6.)\n",
      "desc_test_rank_variance tensor(219.3234)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c157929ae6d6473c985d0f4288dd1f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf07b658af346ed9e646713cb0df1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05abb2d753d4d9ca339924d99e5bfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(3.8241, device='cuda:0')\n",
      "seen_test_acc1: 0.508\n",
      "seen_test_acc10: 0.8\n",
      "seen_test_acc100: 0.848\n",
      "seen_test_rank_median: tensor(0.)\n",
      "seen_test_rank_variance tensor(341.1228)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd61b4795fc14805b91e99294faae03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(17.3610, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.006\n",
      "unseen_test_acc100: 0.008\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(88.6852)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c60e9abe4814b67995058c5265621d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.2648, device='cuda:0')\n",
      "desc_test_acc1: 0.265\n",
      "desc_test_acc10: 0.56\n",
      "desc_test_acc100: 0.85\n",
      "desc_test_rank_median: tensor(7.)\n",
      "desc_test_rank_variance tensor(235.8689)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41cbb2d82af42d3b02117fec3391afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76bf0320b2f4a2e99e5404fb578ea45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inc = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epoch, epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    # Train on subset of training data to save time\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, ((x, attention_mask), y) in enumerate(train_loader):\n",
    "            if i % inc == 0 and i != 0:\n",
    "                display_loss = train_loss / i\n",
    "                pbar.set_description(f'Epoch {epoch+1}, Train Loss: {train_loss / i}')\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            loss, out = model(input_ids=x, attention_mask=attention_mask, \n",
    "                              ground_truth=y)\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "            loss.backward()\n",
    "            \n",
    "#             scaler.unscale_(optim)\n",
    "            nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "            \n",
    "#             scaler.step(optim)\n",
    "            optim.step()\n",
    "#             scaler.update()\n",
    "            \n",
    "            train_loss += loss.detach()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            del x, y, out, loss, attention_mask\n",
    "            \n",
    "    model_name = type(model).__name__\n",
    "    filename = f'../trained_models/{model_name} Epoch {epoch+1} at {datetime.datetime.now()}'.replace(' ', '_')\n",
    "    with open(filename, 'wb+') as f:\n",
    "        torch.save({'state_dict': model.state_dict()}, f)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc1, val_acc10, val_acc100 = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(dev_loader)) as pbar:\n",
    "            for i, ((x, attention_mask), y) in enumerate(dev_loader):\n",
    "                if i % inc == 0 and i != 0:\n",
    "                    display_loss = val_loss / i\n",
    "                    pbar.set_description(f'Epoch {epoch+1}, Val Loss: {val_loss / i}')\n",
    "\n",
    "                x = x.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "#                 with autocast():\n",
    "                loss, out = model(input_ids=x, attention_mask=attention_mask,\n",
    "                                  ground_truth=y)\n",
    "\n",
    "                val_loss += loss.detach()\n",
    "\n",
    "                pbar.update(1)                \n",
    "                \n",
    "                result, indices = torch.topk(out, k=100, dim=-1, largest=True, sorted=True)\n",
    "                \n",
    "                acc1, acc10, acc100 = evaluate(indices, y)\n",
    "                val_acc1 += acc1\n",
    "                val_acc10 += acc10\n",
    "                val_acc100 += acc100\n",
    "\n",
    "                del x, y, out, loss\n",
    "    \n",
    "    wandb.log({\n",
    "        'train_loss': train_loss / len(train_loader),\n",
    "        'val_loss': val_loss / len(dev_loader),\n",
    "        'val_acc1': val_acc1 / len(dev_loader),\n",
    "        'val_acc10': val_acc10 / len(dev_loader),\n",
    "        'val_acc100': val_acc100 / len(dev_loader),\n",
    "        **test(test_loader_seen, 'seen'),\n",
    "        **test(test_loader_unseen, 'unseen'),\n",
    "        **test(test_loader_desc, 'desc')\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredFromDesc(model, desc : str, top_n=10):\n",
    "    desc = T(desc, return_tensors='pt', padding=True)\n",
    "    x = desc['input_ids'].to(device)\n",
    "    attention_mask = desc['attention_mask'].to(device)\n",
    "    out = model(input_ids=x, attention_mask=attention_mask)\n",
    "    result, indices = torch.topk(out, k=top_n, dim=-1, largest=True, sorted=True)\n",
    "    \n",
    "    indices = indices[0]\n",
    "    return [idx2target[i] for i in indices], indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df19f82996364728ac11ffbe7940f7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(4.9566, device='cuda:0')\n",
      "seen_test_acc1: 0.324\n",
      "seen_test_acc10: 0.628\n",
      "seen_test_acc100: 0.792\n",
      "seen_test_rank_median: tensor(3.)\n",
      "seen_test_rank_variance tensor(350.0158)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seen_test_loss': tensor(4.9566, device='cuda:0'),\n",
       " 'seen_test_acc1': 0.324,\n",
       " 'seen_test_acc10': 0.628,\n",
       " 'seen_test_acc100': 0.792,\n",
       " 'seen_test_rank_median': tensor(3.),\n",
       " 'seen_test_rank_variance': tensor(350.0158)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_seen, 'seen') # epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36c8120d0f04a6480b181441e2adb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(16.1984, device='cuda:0')\n",
      "unseen_test_acc1: 0.002\n",
      "unseen_test_acc10: 0.002\n",
      "unseen_test_acc100: 0.004\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(79.8172)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unseen_test_loss': tensor(16.1984, device='cuda:0'),\n",
       " 'unseen_test_acc1': 0.002,\n",
       " 'unseen_test_acc10': 0.002,\n",
       " 'unseen_test_acc100': 0.004,\n",
       " 'unseen_test_rank_median': tensor(1000.),\n",
       " 'unseen_test_rank_variance': tensor(79.8172)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_unseen, 'unseen') # epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdda7cc7e027402284fdbf90b2d7ccce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.5469, device='cuda:0')\n",
      "desc_test_acc1: 0.205\n",
      "desc_test_acc10: 0.51\n",
      "desc_test_acc100: 0.82\n",
      "desc_test_rank_median: tensor(9.)\n",
      "desc_test_rank_variance tensor(238.9242)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'desc_test_loss': tensor(4.5469, device='cuda:0'),\n",
       " 'desc_test_acc1': 0.205,\n",
       " 'desc_test_acc10': 0.51,\n",
       " 'desc_test_acc100': 0.82,\n",
       " 'desc_test_rank_median': tensor(9.),\n",
       " 'desc_test_rank_variance': tensor(238.9242)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_desc, 'desc') # epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95203a9209b45bcb538b4736fa668c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(16.4504, device='cuda:0')\n",
      "desc_test_acc1: 0.001410251341056766\n",
      "desc_test_acc10: 0.003980335560739657\n",
      "desc_test_acc100: 0.005693725040528251\n",
      "desc_test_rank_median: tensor(1000.)\n",
      "desc_test_rank_variance tensor(76.4954)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'desc_test_loss': tensor(16.4504, device='cuda:0'),\n",
       " 'desc_test_acc1': 0.001410251341056766,\n",
       " 'desc_test_acc10': 0.003980335560739657,\n",
       " 'desc_test_acc100': 0.005693725040528251,\n",
       " 'desc_test_rank_median': tensor(1000.),\n",
       " 'desc_test_rank_variance': tensor(76.4954)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(dev_loader, 'desc') # epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['neve',\n",
       "  'highlander',\n",
       "  'home',\n",
       "  'glacial',\n",
       "  'countryman',\n",
       "  'winters',\n",
       "  'frontiersman',\n",
       "  'lee',\n",
       "  'mansfield',\n",
       "  'sylvan',\n",
       "  'montane',\n",
       "  'snowbird',\n",
       "  'alien',\n",
       "  'overwinter',\n",
       "  'frontier',\n",
       "  'winter',\n",
       "  'icehouse',\n",
       "  'clime',\n",
       "  'provincial',\n",
       "  'in',\n",
       "  'pathan',\n",
       "  'mountaineer',\n",
       "  'european',\n",
       "  'glaciated',\n",
       "  'siberian',\n",
       "  'climate',\n",
       "  'interning',\n",
       "  'iceland',\n",
       "  'forester',\n",
       "  'icecap',\n",
       "  'district',\n",
       "  'elkhound',\n",
       "  'bohemian',\n",
       "  'denizen',\n",
       "  'himalayan',\n",
       "  'neighbor',\n",
       "  'cold',\n",
       "  'internal',\n",
       "  'thaw',\n",
       "  'familiar',\n",
       "  'outstation',\n",
       "  'afghan',\n",
       "  'snowfall',\n",
       "  'chilled',\n",
       "  'interior',\n",
       "  'refrigerated',\n",
       "  'cooler',\n",
       "  'villager',\n",
       "  'hole',\n",
       "  'grot',\n",
       "  'igloo',\n",
       "  'taiga',\n",
       "  'gypsy',\n",
       "  'refrigerant',\n",
       "  'frosty',\n",
       "  'hibernate',\n",
       "  'iceman',\n",
       "  'clown',\n",
       "  'snowcap',\n",
       "  'province',\n",
       "  'outerwear',\n",
       "  'den',\n",
       "  'malamute',\n",
       "  'swiss',\n",
       "  'hun',\n",
       "  'dweller',\n",
       "  'interglacial',\n",
       "  'immigrant',\n",
       "  'communist',\n",
       "  'visitor',\n",
       "  'bavarian',\n",
       "  'haft',\n",
       "  'logan',\n",
       "  'frozen',\n",
       "  'inhabitant',\n",
       "  'icing',\n",
       "  'coolly',\n",
       "  'subalpine',\n",
       "  'fronting',\n",
       "  'armenian',\n",
       "  'arcadian',\n",
       "  'turk',\n",
       "  'icebox',\n",
       "  'habitation',\n",
       "  'inside',\n",
       "  'rustication',\n",
       "  'ranch',\n",
       "  'breed',\n",
       "  'georgian',\n",
       "  'junco',\n",
       "  'greenland',\n",
       "  'circumpolar',\n",
       "  'northern',\n",
       "  'nordic',\n",
       "  'compatriot',\n",
       "  'czech',\n",
       "  'private',\n",
       "  'chilliness',\n",
       "  'foreign',\n",
       "  'inward'],\n",
       " tensor([37257,  9948, 19909, 35415, 26280, 14179, 42377,  5406,  3173, 36353,\n",
       "         42199, 33383, 34554, 41824, 43053, 26260, 43769,  1027, 29060, 43071,\n",
       "          7142, 37223, 11250,  8452,  8383,  2795, 24618, 17646, 33961, 41832,\n",
       "         18692,  7593,  4860, 21043, 19770, 39840, 13156, 17023, 21344, 38247,\n",
       "         39207, 42144, 15918, 13113, 37940, 32063, 11401, 44348,  2928, 12794,\n",
       "         30152, 40805, 15094, 39099, 42417,  5263, 29936, 40171,  5151,  9400,\n",
       "          6772,  5498,  6155, 44867,  2569,  8139,  8087, 17241, 22234, 42533,\n",
       "         31641, 20322, 20584, 33742, 27729, 21160, 44123, 38323, 10853,  3015,\n",
       "           169, 16555, 42428, 36012,  3009,  8328, 30273,  2424,  8350, 23695,\n",
       "         24323, 15673, 14713, 31187, 42323, 20818, 20546, 30305,  7360, 19143],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'an inhabitant of a cold country', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bughouse',\n",
       "  'sideshow',\n",
       "  'museology',\n",
       "  'clown',\n",
       "  'mountebank',\n",
       "  'impresario',\n",
       "  'butchers',\n",
       "  'fairground',\n",
       "  'loge',\n",
       "  'pageant',\n",
       "  'shew',\n",
       "  'shop',\n",
       "  'canteen',\n",
       "  'shopping',\n",
       "  'panopticon',\n",
       "  'cad',\n",
       "  'trapeze',\n",
       "  'butcher',\n",
       "  'professor',\n",
       "  'dpa',\n",
       "  'gypsy',\n",
       "  'carnival',\n",
       "  'exhibition',\n",
       "  'stunt',\n",
       "  'circus',\n",
       "  'bazaar',\n",
       "  'stalls',\n",
       "  'hostel',\n",
       "  'stunting',\n",
       "  'snark',\n",
       "  'museum',\n",
       "  'usher',\n",
       "  'nox',\n",
       "  'garter',\n",
       "  'sport',\n",
       "  'parquet',\n",
       "  'company',\n",
       "  'pavillion',\n",
       "  'pavilion',\n",
       "  'upstage',\n",
       "  'goat',\n",
       "  'serai',\n",
       "  'barnstorm',\n",
       "  'hosiery',\n",
       "  'roustabout',\n",
       "  'situation',\n",
       "  'bellboy',\n",
       "  'troupe',\n",
       "  'gripping',\n",
       "  'carrousel',\n",
       "  'fooling',\n",
       "  'laboratory',\n",
       "  'commissary',\n",
       "  'barrack',\n",
       "  'conservatory',\n",
       "  'publican',\n",
       "  'illusionist',\n",
       "  'circle',\n",
       "  'spectator',\n",
       "  'mansfield',\n",
       "  'expo',\n",
       "  'staged',\n",
       "  'showgrounds',\n",
       "  'town',\n",
       "  'amphitheater',\n",
       "  'acy',\n",
       "  'buffalo',\n",
       "  'spectacular',\n",
       "  'edmonton',\n",
       "  'theater',\n",
       "  'trapped',\n",
       "  'theatergoer',\n",
       "  'school',\n",
       "  'vault',\n",
       "  'lamasery',\n",
       "  'gymnasium',\n",
       "  'salesclerk',\n",
       "  'showroom',\n",
       "  'ostentation',\n",
       "  'harbor',\n",
       "  'loggia',\n",
       "  'job',\n",
       "  'miraculous',\n",
       "  'cribbed',\n",
       "  'gyp',\n",
       "  'balcony',\n",
       "  'pen',\n",
       "  'amazed',\n",
       "  'cody',\n",
       "  'entertainment',\n",
       "  'foyer',\n",
       "  'restaurateur',\n",
       "  'posing',\n",
       "  'insane',\n",
       "  'conservator',\n",
       "  'actor',\n",
       "  'institutionalize',\n",
       "  'gig',\n",
       "  'novelist',\n",
       "  'verger'],\n",
       " tensor([ 8533,  8174,   269, 40171,  7183, 21478, 22470,  9960, 34024, 34578,\n",
       "         29730, 15203, 27730, 16284,  6376, 22897,  4733, 31220,  2972,  2867,\n",
       "         15094, 30616, 20184, 21695, 27089, 31844, 37835,  5181, 18212, 43327,\n",
       "          9081, 26968,  8251, 32887, 11265,  1229, 27510, 10788, 31078, 14004,\n",
       "         33493, 40060, 39957, 23687, 29469, 13593,  6437, 24038,   757, 15999,\n",
       "         14092, 31803, 11735, 22359,  2901, 27683, 21687, 24459, 31770,  3173,\n",
       "         19875, 16817, 27398, 22613, 16475, 43651, 12620,  1408, 28167,  5493,\n",
       "         10465, 40052, 17639, 17266, 15634, 36786, 25085, 19040, 25323, 23090,\n",
       "         25128, 20043, 34539, 31268, 32252, 10957,  1702,  2269,  5803,  1619,\n",
       "         44286, 40822, 28741, 35847, 31787, 34683,  7926, 36685,  4808, 17123],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'employee at a circus', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['fasting',\n",
       "  'mobile',\n",
       "  'roll',\n",
       "  'motorcade',\n",
       "  'drive',\n",
       "  'speedster',\n",
       "  'csr',\n",
       "  'flash',\n",
       "  'streamed',\n",
       "  'fast',\n",
       "  'hitchhiking',\n",
       "  'crash',\n",
       "  'roadster',\n",
       "  'tracks',\n",
       "  'cab',\n",
       "  'speedway',\n",
       "  'rally',\n",
       "  'detroit',\n",
       "  'van',\n",
       "  'race',\n",
       "  'hollywood',\n",
       "  'street',\n",
       "  'driveway',\n",
       "  'combustion',\n",
       "  'concourse',\n",
       "  'slick',\n",
       "  'carpool',\n",
       "  'brisk',\n",
       "  'rushing',\n",
       "  'rolled',\n",
       "  'cruiser',\n",
       "  'compact',\n",
       "  'trotting',\n",
       "  'car',\n",
       "  'runs',\n",
       "  'chase',\n",
       "  'riad',\n",
       "  'tailgate',\n",
       "  'swarming',\n",
       "  'trucks',\n",
       "  'rattle',\n",
       "  'driving',\n",
       "  'rallying',\n",
       "  'carouse',\n",
       "  'taxiing',\n",
       "  'lurch',\n",
       "  'shuttle',\n",
       "  'bowled',\n",
       "  'zip',\n",
       "  'film',\n",
       "  'rushes',\n",
       "  'highway',\n",
       "  'jeep',\n",
       "  'speedo',\n",
       "  'run',\n",
       "  'fleet',\n",
       "  'dribble',\n",
       "  'highball',\n",
       "  'snowplow',\n",
       "  'bua',\n",
       "  'mush',\n",
       "  'corner',\n",
       "  'clatter',\n",
       "  'cannonball',\n",
       "  'pickup',\n",
       "  'bike',\n",
       "  'close',\n",
       "  'camber',\n",
       "  'rattling',\n",
       "  'ruck',\n",
       "  'banish',\n",
       "  'inside',\n",
       "  'cam',\n",
       "  'tipple',\n",
       "  'go',\n",
       "  'quickstep',\n",
       "  'motorized',\n",
       "  'boxcar',\n",
       "  'flicking',\n",
       "  'fender',\n",
       "  'alert',\n",
       "  'whip',\n",
       "  'hasten',\n",
       "  'float',\n",
       "  'lock',\n",
       "  'trailer',\n",
       "  'clip',\n",
       "  'stoplight',\n",
       "  'glare',\n",
       "  'skid',\n",
       "  'shunt',\n",
       "  'chrysler',\n",
       "  'mushing',\n",
       "  'drove',\n",
       "  'clearance',\n",
       "  'runabout',\n",
       "  'metropolis',\n",
       "  'expressway',\n",
       "  'city',\n",
       "  'center'],\n",
       " tensor([29769, 43703,  2701, 34224, 34151, 26101, 36911, 39649,  4080,  4241,\n",
       "           364, 10968, 15250,   261, 11404,  8640, 18694, 23994, 21076,  1162,\n",
       "         17221, 12457, 17262,  2864, 22094, 17171, 23846, 35755, 22518, 32914,\n",
       "           971, 21681, 19737, 37609, 43700, 19823,  3873, 26400, 16333, 16884,\n",
       "         13720,  6097, 17519, 10030, 36608,  3244, 22355, 38086, 38056, 34354,\n",
       "           795, 14565,  5187, 14411, 37921,  8168,  8042, 17491,   521,  6817,\n",
       "         35984, 31347, 14412, 37676, 11193, 42223,  9786, 33288, 19991, 42704,\n",
       "         11300,  3009, 39496,  6932, 15331, 13450, 12486,  7121,  7149, 16097,\n",
       "         38194,  1767, 16635, 23063, 37083, 38611, 29298, 38630,  2305, 26597,\n",
       "         43393, 20167,  9880, 26193, 27666,   380, 28657,  2538, 44995, 30918],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a road on which cars can go fast', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = type(model).__name__\n",
    "filename = f'../trained_models/{model_name} Epoch {epoch+1} at {datetime.datetime.now()}'.replace(' ', '_')\n",
    "with open(filename, 'wb+') as f:\n",
    "    torch.save({'state_dict': model.state_dict()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2017,  2024,  2025, 13346,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(\"you are not helpless\", return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "049faeb3947c48ac1b8702363c1a3bc597f6c2e1e1396be70d54511d980ab606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
