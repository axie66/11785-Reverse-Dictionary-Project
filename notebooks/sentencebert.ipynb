{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append('../code')\n",
    "from dataset import get_data, make_vocab, WantWordsDataset as WWDataset\n",
    "\n",
    "from transformers import (\n",
    "    AdamW, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from models import SentenceBERTForRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training data: 675715 word-def pairs\n",
      "Dev data: 75873 word-def pairs\n",
      "Test data: 1200 word-def pairs\n"
     ]
    }
   ],
   "source": [
    "d = get_data('../wantwords-english-baseline/data', word2vec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_data_def, dev_data, test_data_seen, \\\n",
    "    test_data_unseen, test_data_desc = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target2idx, idx2target = make_vocab(d, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16187, 'book')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target2idx maps target words to indices\n",
    "# target_matrix maps target indices to bpe sequences, padded/truncated to mask_size\n",
    "target2idx['book'], idx2target[target2idx['book']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can freeze for (part of) first epoch or so and then unfreeze to train the whole model\n",
    "model = SentenceBERTForRD('distilbert-base-nli-stsb-mean-tokens', \n",
    "                          len(target2idx), freeze_sbert=False, criterion=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = model.sbert.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WWDataset(train_data + train_data_def, T, target2idx)\n",
    "dev_dataset = WWDataset(dev_data, T, target2idx)\n",
    "test_dataset_seen = WWDataset(test_data_seen, T, target2idx)\n",
    "test_dataset_unseen = WWDataset(test_data_unseen, T, target2idx)\n",
    "test_dataset_desc = WWDataset(test_data_desc, T, target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 55\n",
    "num_workers = 4\n",
    "\n",
    "loader_params = {\n",
    "    'pin_memory': False,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'collate_fn': train_dataset.collate_fn\n",
    "}\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, **{'shuffle': True, **loader_params})\n",
    "dev_loader = data.DataLoader(dev_dataset, **{'shuffle': True, **loader_params})\n",
    "test_loader_seen = data.DataLoader(test_dataset_seen, **{'shuffle': False, **loader_params})\n",
    "test_loader_unseen = data.DataLoader(test_dataset_unseen, **{'shuffle': False, **loader_params})\n",
    "test_loader_desc = data.DataLoader(test_dataset_desc, **{'shuffle': False, **loader_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "lr = 2e-5\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "warmup_duration = 0.01 # portion of the first epoch spent on lr warmup\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=len(train_loader) * warmup_duration, \n",
    "                                            num_training_steps=len(train_loader) * epochs)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "# scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreverse-dict\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eternal-rain-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/reverse-dict/reverse-dictionary/runs/3p9wf9hp\" target=\"_blank\">https://wandb.ai/reverse-dict/reverse-dictionary/runs/3p9wf9hp</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/dl/11785-Reverse-Dictionary-Project/notebooks/wandb/run-20210505_075722-3p9wf9hp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7fb0a7ec24d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='reverse-dictionary', entity='reverse-dict')\n",
    "\n",
    "config = wandb.config\n",
    "config.learning_rate = lr\n",
    "config.epochs = epochs\n",
    "config.batch_size = batch_size\n",
    "config.optimizer = type(optim).__name__\n",
    "config.scheduler = type(scheduler).__name__\n",
    "config.warmup_duration = warmup_duration\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, gt, test=False):\n",
    "    acc1 = acc10 = acc100 = 0\n",
    "    n = len(pred)\n",
    "    pred_rank = []\n",
    "    for p, word in zip(pred, gt):\n",
    "        if test:\n",
    "            loc = (p == word).nonzero(as_tuple=True)\n",
    "            if len(loc) != 0:\n",
    "                pred_rank.append(min(loc[-1], 1000))\n",
    "            else:\n",
    "                pred_rank.append(1000)\n",
    "        if word in p[:100]:\n",
    "            acc100 += 1\n",
    "            if word in p[:10]:\n",
    "                acc10 += 1\n",
    "                if word == p[0]:\n",
    "                    acc1 += 1\n",
    "    if test:\n",
    "        pred_rank = torch.tensor(pred_rank, dtype=torch.float32)\n",
    "        return (acc1, acc10, acc100, pred_rank)\n",
    "    else:\n",
    "        return acc1/n, acc10/n, acc100/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, name):\n",
    "    inc = 3\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc1 = test_acc10 = test_acc100 = 0.0\n",
    "    total_seen = 0\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(loader)) as pbar:\n",
    "            for i, ((x, attention_mask), y) in enumerate(loader):\n",
    "                if i % inc == 0 and i != 0:\n",
    "                    display_loss = test_loss / i\n",
    "                    pbar.set_description(f'Test Loss: {display_loss}')\n",
    "\n",
    "                x = x.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "#                 with autocast():\n",
    "                loss, out = model(input_ids=x, attention_mask=attention_mask,\n",
    "                                  ground_truth=y)\n",
    "\n",
    "                test_loss += loss.detach()\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "                result, indices = torch.sort(out, descending=True)\n",
    "                \n",
    "                b = len(x)\n",
    "                acc1, acc10, acc100, pred_rank = evaluate(indices, y, test=True)\n",
    "                test_acc1 += acc1\n",
    "                test_acc10 += acc10\n",
    "                test_acc100 += acc100\n",
    "                total_seen += b\n",
    "                all_pred.extend(pred_rank)\n",
    "                \n",
    "                del x, y, out, loss\n",
    "                if i % 20 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "    test_loss /= len(loader)\n",
    "    test_acc1 /= total_seen\n",
    "    test_acc10 /= total_seen\n",
    "    test_acc100 /= total_seen\n",
    "    all_pred = torch.tensor(all_pred)\n",
    "    median = torch.median(all_pred)\n",
    "    var = torch.var(all_pred)**0.5\n",
    "    \n",
    "    print(f'{name}_test_loss:', test_loss)\n",
    "    print(f'{name}_test_acc1:', test_acc1)\n",
    "    print(f'{name}_test_acc10:', test_acc10)\n",
    "    print(f'{name}_test_acc100:', test_acc100)\n",
    "    print(f'{name}_test_rank_median:', median)\n",
    "    print(f'{name}_test_rank_variance', var)\n",
    "    \n",
    "    return ({\n",
    "        f'{name}_test_loss': test_loss,\n",
    "        f'{name}_test_acc1': test_acc1,\n",
    "        f'{name}_test_acc10': test_acc10,\n",
    "        f'{name}_test_acc100': test_acc100,\n",
    "        f'{name}_test_rank_median': median,\n",
    "        f'{name}_test_rank_variance': var\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b52bb3d0394cb0b27e6afb32044881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf7cb505d39455cabe9eb109f8770e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e49f52e85d44384b555644b1e68b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(9.3957, device='cuda:0')\n",
      "seen_test_acc1: 0.012\n",
      "seen_test_acc10: 0.074\n",
      "seen_test_acc100: 0.25\n",
      "seen_test_rank_median: tensor(852.)\n",
      "seen_test_rank_variance tensor(426.3570)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feccbe2f073472d9e6a1653bd773d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(13.0325, device='cuda:0')\n",
      "unseen_test_acc1: 0.0\n",
      "unseen_test_acc10: 0.002\n",
      "unseen_test_acc100: 0.004\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(67.4732)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5bc5908db24c4aa3192bbb9381e963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(6.2205, device='cuda:0')\n",
      "desc_test_acc1: 0.29\n",
      "desc_test_acc10: 0.555\n",
      "desc_test_acc100: 0.745\n",
      "desc_test_rank_median: tensor(7.)\n",
      "desc_test_rank_variance tensor(349.5893)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6578e05967445ed8236b6859be5d086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3462bcaada4801a978dc9e7ce0d926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268073053d674041aa871db5fdc3e7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(8.1269, device='cuda:0')\n",
      "seen_test_acc1: 0.06\n",
      "seen_test_acc10: 0.216\n",
      "seen_test_acc100: 0.468\n",
      "seen_test_rank_median: tensor(140.)\n",
      "seen_test_rank_variance tensor(419.7760)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808eb07e20d243ab99096445fd4d86b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(13.9106, device='cuda:0')\n",
      "unseen_test_acc1: 0.0\n",
      "unseen_test_acc10: 0.004\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(75.1580)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48315075f89e40bea0c32cc00c062374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.8081, device='cuda:0')\n",
      "desc_test_acc1: 0.375\n",
      "desc_test_acc10: 0.7\n",
      "desc_test_acc100: 0.82\n",
      "desc_test_rank_median: tensor(2.)\n",
      "desc_test_rank_variance tensor(299.2062)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e64ff1f4e4198bc2e9c83cb8c2e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993c3ab838ae4acca1b75d83653429c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cf6227bb734a92b8b1d6f9ec55d273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(7.0747, device='cuda:0')\n",
      "seen_test_acc1: 0.128\n",
      "seen_test_acc10: 0.366\n",
      "seen_test_acc100: 0.616\n",
      "seen_test_rank_median: tensor(36.)\n",
      "seen_test_rank_variance tensor(383.9724)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2f7fc0e3c44f6594d47ab7f83fce85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(14.1173, device='cuda:0')\n",
      "unseen_test_acc1: 0.002\n",
      "unseen_test_acc10: 0.004\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(76.6629)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ca7e0329e24ba69bb597d45b5f6466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.2866, device='cuda:0')\n",
      "desc_test_acc1: 0.375\n",
      "desc_test_acc10: 0.7\n",
      "desc_test_acc100: 0.845\n",
      "desc_test_rank_median: tensor(1.)\n",
      "desc_test_rank_variance tensor(245.0346)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eab481cc9544679fcd2baf878e367b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b73043a3634694b32f587823c568b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0534de51294c759f83d52501131119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(6.1792, device='cuda:0')\n",
      "seen_test_acc1: 0.206\n",
      "seen_test_acc10: 0.498\n",
      "seen_test_acc100: 0.718\n",
      "seen_test_rank_median: tensor(10.)\n",
      "seen_test_rank_variance tensor(358.8513)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b541751de0774fd787521b3737e38e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(14.3497, device='cuda:0')\n",
      "unseen_test_acc1: 0.002\n",
      "unseen_test_acc10: 0.006\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(77.2013)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca17acfefa4a93a0279fea0d7c38c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.1387, device='cuda:0')\n",
      "desc_test_acc1: 0.36\n",
      "desc_test_acc10: 0.695\n",
      "desc_test_acc100: 0.85\n",
      "desc_test_rank_median: tensor(2.)\n",
      "desc_test_rank_variance tensor(235.2277)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cbd9f9b0fd454bb5704c89d7df6577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a162dfb058544865b044c7cd5accbb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a32050b9bd47e8a75ed9cb6972a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(5.5666, device='cuda:0')\n",
      "seen_test_acc1: 0.292\n",
      "seen_test_acc10: 0.584\n",
      "seen_test_acc100: 0.768\n",
      "seen_test_rank_median: tensor(4.)\n",
      "seen_test_rank_variance tensor(355.4846)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee49a30b44f433b854179be83aa6df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(14.4899, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.006\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(81.6484)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67f82de2d024c0a945b114dd561f5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.0460, device='cuda:0')\n",
      "desc_test_acc1: 0.38\n",
      "desc_test_acc10: 0.675\n",
      "desc_test_acc100: 0.865\n",
      "desc_test_rank_median: tensor(2.)\n",
      "desc_test_rank_variance tensor(239.9710)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59be5a587a434ce081ddd6b1383fbde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad701e8c5b424427a03fa79f0cf94cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a1eca6f6ef46c8b3d6756d3c100579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(5.1292, device='cuda:0')\n",
      "seen_test_acc1: 0.33\n",
      "seen_test_acc10: 0.636\n",
      "seen_test_acc100: 0.798\n",
      "seen_test_rank_median: tensor(3.)\n",
      "seen_test_rank_variance tensor(349.5005)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2fb3bf8fbc46f488e55e7b402e7889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(14.6690, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.006\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(82.8029)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91678f692a1e461980f2adc5a64b907c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.0401, device='cuda:0')\n",
      "desc_test_acc1: 0.36\n",
      "desc_test_acc10: 0.675\n",
      "desc_test_acc100: 0.86\n",
      "desc_test_rank_median: tensor(2.)\n",
      "desc_test_rank_variance tensor(234.6072)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad52dfd4a7c4116bf0197840434342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ad80a5a1ad1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#             scaler.scale(loss).backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#             scaler.unscale_(optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inc = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epoch, epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    # Train on subset of training data to save time\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, ((x, attention_mask), y) in enumerate(train_loader):\n",
    "            if i % inc == 0 and i != 0:\n",
    "                display_loss = train_loss / i\n",
    "                pbar.set_description(f'Epoch {epoch+1}, Train Loss: {train_loss / i}')\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            loss, out = model(input_ids=x, attention_mask=attention_mask, \n",
    "                              ground_truth=y)\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "            loss.backward()\n",
    "            \n",
    "#             scaler.unscale_(optim)\n",
    "            nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "            \n",
    "#             scaler.step(optim)\n",
    "            optim.step()\n",
    "#             scaler.update()\n",
    "            \n",
    "            train_loss += loss.detach()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            del x, y, out, loss, attention_mask\n",
    "            \n",
    "    model_name = type(model).__name__\n",
    "    filename = f'../trained_models/{model_name} Epoch {epoch+1} at {datetime.datetime.now()}'.replace(' ', '_')\n",
    "    with open(filename, 'wb+') as f:\n",
    "        torch.save({'state_dict': model.state_dict()}, f)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc1, val_acc10, val_acc100 = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(dev_loader)) as pbar:\n",
    "            for i, ((x, attention_mask), y) in enumerate(dev_loader):\n",
    "                if i % inc == 0 and i != 0:\n",
    "                    display_loss = val_loss / i\n",
    "                    pbar.set_description(f'Epoch {epoch+1}, Val Loss: {val_loss / i}')\n",
    "\n",
    "                x = x.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "#                 with autocast():\n",
    "                loss, out = model(input_ids=x, attention_mask=attention_mask,\n",
    "                                  ground_truth=y)\n",
    "\n",
    "                val_loss += loss.detach()\n",
    "\n",
    "                pbar.update(1)                \n",
    "                \n",
    "                result, indices = torch.topk(out, k=100, dim=-1, largest=True, sorted=True)\n",
    "                \n",
    "                acc1, acc10, acc100 = evaluate(indices, y)\n",
    "                val_acc1 += acc1\n",
    "                val_acc10 += acc10\n",
    "                val_acc100 += acc100\n",
    "\n",
    "                del x, y, out, loss\n",
    "    \n",
    "    wandb.log({\n",
    "        'train_loss': train_loss / len(train_loader),\n",
    "        'val_loss': val_loss / len(dev_loader),\n",
    "        'val_acc1': val_acc1 / len(dev_loader),\n",
    "        'val_acc10': val_acc10 / len(dev_loader),\n",
    "        'val_acc100': val_acc100 / len(dev_loader),\n",
    "        **test(test_loader_seen, 'seen'),\n",
    "        **test(test_loader_unseen, 'unseen'),\n",
    "        **test(test_loader_desc, 'desc')\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredFromDesc(model, desc : str, top_n=10):\n",
    "    desc = T(desc, return_tensors='pt', padding=True)\n",
    "    x = desc['input_ids'].to(device)\n",
    "    attention_mask = desc['attention_mask'].to(device)\n",
    "    out = model(input_ids=x, attention_mask=attention_mask)\n",
    "    result, indices = torch.topk(out, k=top_n, dim=-1, largest=True, sorted=True)\n",
    "    \n",
    "    indices = indices[0]\n",
    "    return [idx2target[i] for i in indices], indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5acdde0e9fb4ae3ba304c673a7247af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen_test_loss: tensor(5.1246, device='cuda:0')\n",
      "seen_test_acc1: 0.326\n",
      "seen_test_acc10: 0.64\n",
      "seen_test_acc100: 0.804\n",
      "seen_test_rank_median: tensor(3.)\n",
      "seen_test_rank_variance tensor(347.5329)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seen_test_loss': tensor(5.1246, device='cuda:0'),\n",
       " 'seen_test_acc1': 0.326,\n",
       " 'seen_test_acc10': 0.64,\n",
       " 'seen_test_acc100': 0.804,\n",
       " 'seen_test_rank_median': tensor(3.),\n",
       " 'seen_test_rank_variance': tensor(347.5329)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_seen, 'seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a317254af5a846af8aebcc1cb19c847b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_test_loss: tensor(14.7876, device='cuda:0')\n",
      "unseen_test_acc1: 0.004\n",
      "unseen_test_acc10: 0.006\n",
      "unseen_test_acc100: 0.006\n",
      "unseen_test_rank_median: tensor(1000.)\n",
      "unseen_test_rank_variance tensor(82.8673)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unseen_test_loss': tensor(14.7876, device='cuda:0'),\n",
       " 'unseen_test_acc1': 0.004,\n",
       " 'unseen_test_acc10': 0.006,\n",
       " 'unseen_test_acc100': 0.006,\n",
       " 'unseen_test_rank_median': tensor(1000.),\n",
       " 'unseen_test_rank_variance': tensor(82.8673)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_unseen, 'unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fed77538ef540c5937c9df837aa325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc_test_loss: tensor(4.0884, device='cuda:0')\n",
      "desc_test_acc1: 0.365\n",
      "desc_test_acc10: 0.675\n",
      "desc_test_acc100: 0.86\n",
      "desc_test_rank_median: tensor(2.)\n",
      "desc_test_rank_variance tensor(234.0795)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'desc_test_loss': tensor(4.0884, device='cuda:0'),\n",
       " 'desc_test_acc1': 0.365,\n",
       " 'desc_test_acc10': 0.675,\n",
       " 'desc_test_acc100': 0.86,\n",
       " 'desc_test_rank_median': tensor(2.),\n",
       " 'desc_test_rank_variance': tensor(234.0795)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader_desc, 'desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['glacial',\n",
       "  'arctic',\n",
       "  'icy',\n",
       "  'iceman',\n",
       "  'frozen',\n",
       "  'winters',\n",
       "  'husky',\n",
       "  'nordic',\n",
       "  'boreal',\n",
       "  'barbarian',\n",
       "  'frigid',\n",
       "  'hun',\n",
       "  'mountaineer',\n",
       "  'winter',\n",
       "  'freezing',\n",
       "  'cooler',\n",
       "  'snowbird',\n",
       "  'cold',\n",
       "  'snowplow',\n",
       "  'thaw',\n",
       "  'malamute',\n",
       "  'coldly',\n",
       "  'renegade',\n",
       "  'frosty',\n",
       "  'afghan',\n",
       "  'bushman',\n",
       "  'barbarous',\n",
       "  'icehouse',\n",
       "  'tundra',\n",
       "  'taiga',\n",
       "  'tobogganing',\n",
       "  'nippy',\n",
       "  'chinook',\n",
       "  'coolie',\n",
       "  'rustic',\n",
       "  'mink',\n",
       "  'philistine',\n",
       "  'refrigerant',\n",
       "  'refrigerate',\n",
       "  'cynic',\n",
       "  'cool',\n",
       "  'frosted',\n",
       "  'glaciation',\n",
       "  'frost',\n",
       "  'snowy',\n",
       "  'glaciated',\n",
       "  'coolly',\n",
       "  'gypsy',\n",
       "  'frigidity',\n",
       "  'starve',\n",
       "  'landsman',\n",
       "  'thawing',\n",
       "  'troglodyte',\n",
       "  'refrigerating',\n",
       "  'chiller',\n",
       "  'nazi',\n",
       "  'nonnative',\n",
       "  'skater',\n",
       "  'foe',\n",
       "  'provincial',\n",
       "  'frostbite',\n",
       "  'neve',\n",
       "  'caribou',\n",
       "  'chills',\n",
       "  'peasant',\n",
       "  'cooling',\n",
       "  'clown',\n",
       "  'celsius',\n",
       "  'popsicle',\n",
       "  'agnostic',\n",
       "  'glade',\n",
       "  'snowboarding',\n",
       "  'slavic',\n",
       "  'overwinter',\n",
       "  'asia',\n",
       "  'weasel',\n",
       "  'polar',\n",
       "  'barbaric',\n",
       "  'countryman',\n",
       "  'growler',\n",
       "  'northerner',\n",
       "  'outlander',\n",
       "  'northerly',\n",
       "  'scandinavian',\n",
       "  'eurasian',\n",
       "  'chilliness',\n",
       "  'dutchman',\n",
       "  'foehn',\n",
       "  'sledding',\n",
       "  'forester',\n",
       "  'sundowner',\n",
       "  'lukewarm',\n",
       "  'refrigerated',\n",
       "  'poles',\n",
       "  'mogul',\n",
       "  'cir',\n",
       "  'indic',\n",
       "  'subalpine',\n",
       "  'antarctic',\n",
       "  'hibernate'],\n",
       " tensor([35415, 16367,  6566, 29936, 33742, 14179,  2778, 31187, 15576,  8324,\n",
       "         12858,  2569, 37223, 26260, 23980, 11401, 33383, 13156,   521, 21344,\n",
       "          6155, 21083, 23121, 42417, 42144,  5777,   807, 43769, 26016, 40805,\n",
       "         28146, 15832, 33112, 43267, 16493,  9303, 40268, 39099,  8385,   482,\n",
       "         17559, 39998, 21531, 16958, 28728,  8452, 44123, 15094, 12138, 35404,\n",
       "         40217, 17230,  9543, 11440, 31285, 41420, 19673, 27672, 31092, 29060,\n",
       "         18320, 37257, 16215, 17814,  8531, 33803, 40171, 13409, 10404, 24247,\n",
       "         27597, 20231, 22202, 41824, 40145, 44152, 15108, 35246, 26280, 19624,\n",
       "         27854, 19714, 41001, 23803, 32884, 30305, 23545, 44086, 27752, 33961,\n",
       "         32030, 28463, 32063, 16173, 17710, 29512,  4695, 38323, 18484,  5263],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'an inhabitant of a cold country', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['clown',\n",
       "  'butcher',\n",
       "  'circus',\n",
       "  'knackered',\n",
       "  'jobber',\n",
       "  'butchers',\n",
       "  'mummer',\n",
       "  'stag',\n",
       "  'monger',\n",
       "  'ham',\n",
       "  'gaffer',\n",
       "  'ringer',\n",
       "  'mie',\n",
       "  'cowherd',\n",
       "  'huntsman',\n",
       "  'knacker',\n",
       "  'demonstrator',\n",
       "  'juggler',\n",
       "  'masquerading',\n",
       "  'ranger',\n",
       "  'comedian',\n",
       "  'actor',\n",
       "  'picket',\n",
       "  'outlaw',\n",
       "  'strongman',\n",
       "  'buffo',\n",
       "  'stunting',\n",
       "  'carnival',\n",
       "  'jock',\n",
       "  'publican',\n",
       "  'bandsman',\n",
       "  'don',\n",
       "  'vamp',\n",
       "  'roustabout',\n",
       "  'valet',\n",
       "  'trooper',\n",
       "  'fagot',\n",
       "  'bullock',\n",
       "  'beadle',\n",
       "  'matador',\n",
       "  'garnishee',\n",
       "  'buffoon',\n",
       "  'man',\n",
       "  'ramrod',\n",
       "  'reeve',\n",
       "  'csd',\n",
       "  'usher',\n",
       "  'shifter',\n",
       "  'adventurer',\n",
       "  'larrikin',\n",
       "  'tinker',\n",
       "  'swagman',\n",
       "  'jeweler',\n",
       "  'roper',\n",
       "  'ape',\n",
       "  'gladiator',\n",
       "  'tenter',\n",
       "  'dof',\n",
       "  'lackey',\n",
       "  'rustler',\n",
       "  'player',\n",
       "  'teaser',\n",
       "  'knight',\n",
       "  'theatergoer',\n",
       "  'pedant',\n",
       "  'prostitute',\n",
       "  'knave',\n",
       "  'job',\n",
       "  'cad',\n",
       "  'flaunt',\n",
       "  'artist',\n",
       "  'pantomime',\n",
       "  'hams',\n",
       "  'mastering',\n",
       "  'cadet',\n",
       "  'handyman',\n",
       "  'apprentice',\n",
       "  'amateur',\n",
       "  'stockman',\n",
       "  'skinner',\n",
       "  'spectator',\n",
       "  'merchant',\n",
       "  'pioneer',\n",
       "  'kid',\n",
       "  'hackneyed',\n",
       "  'trouper',\n",
       "  'tailor',\n",
       "  'haberdasher',\n",
       "  'override',\n",
       "  'vaudevillian',\n",
       "  'jester',\n",
       "  'gig',\n",
       "  'brigand',\n",
       "  'performer',\n",
       "  'hatter',\n",
       "  'horner',\n",
       "  'provost',\n",
       "  'artisan',\n",
       "  'craftsman',\n",
       "  'beefeater'],\n",
       " tensor([40171, 31220, 27089,  9836, 34130, 22470, 30006,  1760, 23194, 16507,\n",
       "          9310, 33889, 32244,  1014, 21903, 27365, 15654, 24756, 10068, 36963,\n",
       "         27139, 34683, 42497, 38414,  6209, 33687, 18212, 30616, 29218, 27683,\n",
       "         21210, 15385, 41548, 29469, 10969, 35364,  6330, 20295, 17967, 33943,\n",
       "         30495, 41028, 14818, 44314, 16343,  4511, 26968, 30969, 42277, 44262,\n",
       "         25734, 39029,  9673, 33311, 15401, 24390, 18308, 18738, 10264,  4276,\n",
       "           697, 35516, 11496, 40052, 19001, 28349, 27741, 20043, 22897, 29347,\n",
       "         20681,  6147, 19098, 28376, 35593, 31477,  3653, 17103, 30094,  2885,\n",
       "         31770, 11331,  4900, 14277,   634, 30531, 44200, 12308,  3890, 22627,\n",
       "         22710, 36685, 42718,  2708, 20744, 31831,  5136, 29821, 43367, 33934],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'employee at a circus', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['riad',\n",
       "  'drive',\n",
       "  'speedway',\n",
       "  'railroad',\n",
       "  'railway',\n",
       "  'lanes',\n",
       "  'runway',\n",
       "  'bus',\n",
       "  'highway',\n",
       "  'race',\n",
       "  'rush',\n",
       "  'nus',\n",
       "  'driveway',\n",
       "  'fast',\n",
       "  'rushing',\n",
       "  'gating',\n",
       "  'bua',\n",
       "  'accelerator',\n",
       "  'freeway',\n",
       "  'tailgate',\n",
       "  'gate',\n",
       "  'road',\n",
       "  'car',\n",
       "  'scuttling',\n",
       "  'street',\n",
       "  'tracked',\n",
       "  'clearance',\n",
       "  'route',\n",
       "  'pad',\n",
       "  'clip',\n",
       "  'turnpike',\n",
       "  'hacking',\n",
       "  'trailer',\n",
       "  'psd',\n",
       "  'highball',\n",
       "  'track',\n",
       "  'rushes',\n",
       "  'blitzed',\n",
       "  'tracks',\n",
       "  'gangway',\n",
       "  'fasting',\n",
       "  'causeway',\n",
       "  'lock',\n",
       "  'swift',\n",
       "  'mileage',\n",
       "  'hack',\n",
       "  'fugitive',\n",
       "  'slipping',\n",
       "  'hitchhiking',\n",
       "  'backstop',\n",
       "  'routing',\n",
       "  'turnstile',\n",
       "  'highroad',\n",
       "  'flash',\n",
       "  'parking',\n",
       "  'shuttling',\n",
       "  'blockade',\n",
       "  'corridor',\n",
       "  'avenue',\n",
       "  'cab',\n",
       "  'trap',\n",
       "  'door',\n",
       "  'carpool',\n",
       "  'flight',\n",
       "  'shuttle',\n",
       "  'thoroughfare',\n",
       "  'bootlegging',\n",
       "  'career',\n",
       "  'taxi',\n",
       "  'jump',\n",
       "  'hijack',\n",
       "  'hurry',\n",
       "  'drove',\n",
       "  'gas',\n",
       "  'motor',\n",
       "  'convertible',\n",
       "  'steals',\n",
       "  'drift',\n",
       "  'expedited',\n",
       "  'fleet',\n",
       "  'trapped',\n",
       "  'guns',\n",
       "  'blitz',\n",
       "  'bolt',\n",
       "  'starter',\n",
       "  'taxiing',\n",
       "  'barricades',\n",
       "  'getaway',\n",
       "  'slick',\n",
       "  'escape',\n",
       "  'first',\n",
       "  'slip',\n",
       "  'motorcade',\n",
       "  'lead',\n",
       "  'impracticable',\n",
       "  'escaped',\n",
       "  'roadster',\n",
       "  'impasse',\n",
       "  'skid',\n",
       "  'fairway'],\n",
       " tensor([ 3873, 34151,  8640, 25796,  6535, 38393, 28832,   619, 14565,  1162,\n",
       "         24395, 14324, 17262,  4241, 22518,  9379,  6817,  4244, 19354, 26400,\n",
       "          1040, 18268, 37609, 24926, 12457, 31980, 27666, 15165, 17148, 29298,\n",
       "         13115, 25707, 38611, 43132, 17491, 34101,   795, 34268,   261, 40911,\n",
       "         29769, 25604, 37083, 32961, 22990,  5168, 39341, 20462,   364, 30850,\n",
       "         36561, 25766, 26199, 39649, 18677, 12901, 25805, 35146, 20113, 11404,\n",
       "         25155, 24309, 23846, 41677, 22355, 29589, 26740, 31341, 40953, 33402,\n",
       "         33503, 37618, 26193, 19330, 22759, 38280, 32053, 11066, 18903,  8168,\n",
       "         10465, 32639, 35032, 25004,  2785, 36608, 35777, 41689, 17171, 21101,\n",
       "          6481, 14689, 34224, 18058,  4424,  2678, 15250, 35119, 26597, 32478],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a road on which cars can go fast', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['thermometer',\n",
       "  'thermometry',\n",
       "  'isotherm',\n",
       "  'thermostat',\n",
       "  'calorimeter',\n",
       "  'pyrometer',\n",
       "  'fahrenheit',\n",
       "  'refrigerant',\n",
       "  'thermopile',\n",
       "  'cooler',\n",
       "  'centigrade',\n",
       "  'freezer',\n",
       "  'gasometer',\n",
       "  'celsius',\n",
       "  'chronograph',\n",
       "  'heating',\n",
       "  'superheating',\n",
       "  'dynamometer',\n",
       "  'temperance',\n",
       "  'meter',\n",
       "  'thermoregulation',\n",
       "  'manometer',\n",
       "  'calorific',\n",
       "  'mileage',\n",
       "  'barometer',\n",
       "  'percentile',\n",
       "  'heat',\n",
       "  'thermocouple',\n",
       "  'metering',\n",
       "  'endothermic',\n",
       "  'het',\n",
       "  'anemometer',\n",
       "  'ergometer',\n",
       "  'thermography',\n",
       "  'antarctica',\n",
       "  'refrigeration',\n",
       "  'comparator',\n",
       "  'ph',\n",
       "  'hygrometer',\n",
       "  'measurement',\n",
       "  'hotness',\n",
       "  'coldness',\n",
       "  'stp',\n",
       "  'calibration',\n",
       "  'joule',\n",
       "  'cryogenics',\n",
       "  'timepiece',\n",
       "  'heater',\n",
       "  'radiometer',\n",
       "  'climate',\n",
       "  'measurer',\n",
       "  'potentiometer',\n",
       "  'cryogenic',\n",
       "  'tonometry',\n",
       "  'calorie',\n",
       "  'coefficient',\n",
       "  'thermally',\n",
       "  'titer',\n",
       "  'gauge',\n",
       "  'conduction',\n",
       "  'seismometer',\n",
       "  'dosimeter',\n",
       "  'accelerometer',\n",
       "  'equidistant',\n",
       "  'thermotherapy',\n",
       "  'calibrated',\n",
       "  'boiling',\n",
       "  'stove',\n",
       "  'eutectic',\n",
       "  'ammeter',\n",
       "  'oscilloscope',\n",
       "  'thermal',\n",
       "  'cryogen',\n",
       "  'bodybuilding',\n",
       "  'thermistor',\n",
       "  'gage',\n",
       "  'acclimatize',\n",
       "  'albedo',\n",
       "  'caliper',\n",
       "  'bolometer',\n",
       "  'hydrometer',\n",
       "  'benchmark',\n",
       "  'dryer',\n",
       "  'measured',\n",
       "  'tonometer',\n",
       "  'pedometer',\n",
       "  'equalizer',\n",
       "  'sphygmomanometer',\n",
       "  'quantitatively',\n",
       "  'gravimetry',\n",
       "  'cook',\n",
       "  'inclinometer',\n",
       "  'hypothermia',\n",
       "  'climatology',\n",
       "  'biometry',\n",
       "  'suppurative',\n",
       "  'reading',\n",
       "  'baths',\n",
       "  'cryonics',\n",
       "  'hydrothermal'],\n",
       " tensor([21694,  2316, 35931, 27127, 43736, 39573, 23558, 39099, 16077, 11401,\n",
       "         43549,  8170, 43191, 13409, 31776, 33404,  4899, 27493, 23970, 33029,\n",
       "          1696, 22133, 44924, 22990, 21219, 12469, 25497, 33373, 15495, 12675,\n",
       "         14356,  8840, 12824,  6023, 16198, 15343, 42310,  9905,  2337,  8899,\n",
       "           804, 17867, 25870, 19570, 41046, 36983, 30895,  8653, 35187,  2795,\n",
       "         39895, 26594, 30879, 29938, 36670, 33376, 43570, 41727, 36591, 43812,\n",
       "         16710,  2775,  1680, 34299, 44463, 37950,  4530, 32534,  1095,  8054,\n",
       "         17702, 37815, 13886, 13918, 12069, 14722, 11599,  8554,  2519, 32107,\n",
       "         22783, 30138, 11912, 21881, 26743, 15261,  2530, 23567, 11816, 12598,\n",
       "         40531, 24097, 23107, 17499, 44146, 29546, 41191,   784,  4197, 32559],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'something you use to measure your temperature', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mansion',\n",
       "  'house',\n",
       "  'hall',\n",
       "  'villa',\n",
       "  'palace',\n",
       "  'stateroom',\n",
       "  'apartment',\n",
       "  'hotel',\n",
       "  'homestead',\n",
       "  'domiciled',\n",
       "  'tenement',\n",
       "  'lodge',\n",
       "  'roof',\n",
       "  'lofting',\n",
       "  'casa',\n",
       "  'housing',\n",
       "  'saloon',\n",
       "  'cottage',\n",
       "  'penthouse',\n",
       "  'residence',\n",
       "  'roofs',\n",
       "  'cabinet',\n",
       "  'householder',\n",
       "  'home',\n",
       "  'inn',\n",
       "  'castle',\n",
       "  'maisonette',\n",
       "  'condominium',\n",
       "  'manor',\n",
       "  'seraglio',\n",
       "  'summerhouse',\n",
       "  'nesting',\n",
       "  'placed',\n",
       "  'ibn',\n",
       "  'townhouse',\n",
       "  'parkour',\n",
       "  'cribbed',\n",
       "  'demesne',\n",
       "  'palatial',\n",
       "  'landlord',\n",
       "  'dwelling',\n",
       "  'divan',\n",
       "  'loge',\n",
       "  'parlor',\n",
       "  'court',\n",
       "  'stage',\n",
       "  'nested',\n",
       "  'lodging',\n",
       "  'cabin',\n",
       "  'chateau',\n",
       "  'building',\n",
       "  'nest',\n",
       "  'chamber',\n",
       "  'cloakroom',\n",
       "  'edifice',\n",
       "  'housemate',\n",
       "  'rooms',\n",
       "  'stacked',\n",
       "  'residency',\n",
       "  'buttery',\n",
       "  'guesthouse',\n",
       "  'studio',\n",
       "  'rotunda',\n",
       "  'pension',\n",
       "  'stack',\n",
       "  'floor',\n",
       "  'houseguest',\n",
       "  'treasury',\n",
       "  'kitty',\n",
       "  'hovel',\n",
       "  'lobbying',\n",
       "  'pavilion',\n",
       "  'household',\n",
       "  'condo',\n",
       "  'tenancy',\n",
       "  'roundhouse',\n",
       "  'stacks',\n",
       "  'feature',\n",
       "  'den',\n",
       "  'palazzo',\n",
       "  'hostelry',\n",
       "  'hostel',\n",
       "  'lodgment',\n",
       "  'boudoir',\n",
       "  'housekeeping',\n",
       "  'windsor',\n",
       "  'habitation',\n",
       "  'boardinghouse',\n",
       "  'mahal',\n",
       "  'auditorium',\n",
       "  'crib',\n",
       "  'suite',\n",
       "  'curtilage',\n",
       "  'tard',\n",
       "  'fireside',\n",
       "  'dollhouse',\n",
       "  'gazebo',\n",
       "  'roo',\n",
       "  'atrium',\n",
       "  'terracing'],\n",
       " tensor([22986,  7128,  8017, 44033, 32922, 21396, 31671,  3182, 23876, 39703,\n",
       "         39815, 19985, 22464, 15400, 36882, 23459,  3541, 19213, 28893, 31387,\n",
       "          3719, 27133, 22996, 19909, 39571, 26177, 40618, 30329, 37213, 41353,\n",
       "         17996, 36995, 40966, 17022, 19977, 16961, 31268, 31617, 32515, 27951,\n",
       "          6352, 35749, 34024, 38934, 29739, 39891, 30905, 19808, 39982,  8330,\n",
       "          9694, 10830, 18821, 21574, 11741, 43430,   473,  8358, 15256, 38575,\n",
       "         41475, 31925, 40116,  6013, 31239, 28095, 11411, 11268,  9528, 18040,\n",
       "         32757, 31078, 41851, 11387,   277,  3464, 14390, 12789,  5498,  3538,\n",
       "          3250,  5181, 27225,  5920, 27176, 30281, 36012,  6484,  4942, 28013,\n",
       "         13654, 17704, 13225, 22550, 27454, 23362,  1663, 16222, 29066, 24710],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a large house that a rich person lives in', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['unhappy',\n",
       "  'happiness',\n",
       "  'sadness',\n",
       "  'misery',\n",
       "  'vanity',\n",
       "  'misfortune',\n",
       "  'bashfulness',\n",
       "  'complacence',\n",
       "  'felicitate',\n",
       "  'evil',\n",
       "  'nothingness',\n",
       "  'depression',\n",
       "  'unhappiness',\n",
       "  'absurd',\n",
       "  'emptiness',\n",
       "  'disappointment',\n",
       "  'frailty',\n",
       "  'pessimism',\n",
       "  'felicity',\n",
       "  'diffidence',\n",
       "  'inconvenience',\n",
       "  'melancholic',\n",
       "  'egoism',\n",
       "  'indisposition',\n",
       "  'irrationality',\n",
       "  'penury',\n",
       "  'folly',\n",
       "  'mischief',\n",
       "  'languor',\n",
       "  'blithe',\n",
       "  'gravity',\n",
       "  'hopeless',\n",
       "  'unreality',\n",
       "  'atheism',\n",
       "  'joviality',\n",
       "  'unreasoning',\n",
       "  'luck',\n",
       "  'adversity',\n",
       "  'egotism',\n",
       "  'discontent',\n",
       "  'disconsolate',\n",
       "  'nihilism',\n",
       "  'insanity',\n",
       "  'pitiable',\n",
       "  'unkindly',\n",
       "  'spleen',\n",
       "  'transience',\n",
       "  'arrogance',\n",
       "  'magnanimity',\n",
       "  'affliction',\n",
       "  'gaiety',\n",
       "  'demerit',\n",
       "  'infatuation',\n",
       "  'modesty',\n",
       "  'ugliness',\n",
       "  'uneasiness',\n",
       "  'impotence',\n",
       "  'disinterest',\n",
       "  'disaffection',\n",
       "  'malevolence',\n",
       "  'sterility',\n",
       "  'flatness',\n",
       "  'envy',\n",
       "  'deficiency',\n",
       "  'goodness',\n",
       "  'deadness',\n",
       "  'regrets',\n",
       "  'leniency',\n",
       "  'joy',\n",
       "  'incontinence',\n",
       "  'happy',\n",
       "  'admiration',\n",
       "  'drought',\n",
       "  'lugubrious',\n",
       "  'humor',\n",
       "  'unfortunate',\n",
       "  'scarcity',\n",
       "  'desperation',\n",
       "  'megalomania',\n",
       "  'sorrowing',\n",
       "  'inertness',\n",
       "  'inanition',\n",
       "  'fatuity',\n",
       "  'closeness',\n",
       "  'nostalgia',\n",
       "  'unlikeliness',\n",
       "  'oll',\n",
       "  'thankless',\n",
       "  'narcissism',\n",
       "  'morbidity',\n",
       "  'distemper',\n",
       "  'want',\n",
       "  'sarcasm',\n",
       "  'disease',\n",
       "  'miracle',\n",
       "  'imperfection',\n",
       "  'photophobia',\n",
       "  'pathetic',\n",
       "  'preposterous',\n",
       "  'disappointing'],\n",
       " tensor([11144, 29088,   128, 40591,  9345, 35444,  1840,  2418, 23682, 39768,\n",
       "         34022, 11426, 31810, 30906, 25108, 34624, 27262, 33645, 24733,  8624,\n",
       "          5069, 13000, 38568, 41362, 38744, 36094,  3090, 25364, 10519,  2541,\n",
       "         16342,  2026, 10185, 20765, 26728, 30546, 34288,  5745, 11322,  3505,\n",
       "         33076, 36922, 23349, 33405, 28585,  8676, 16918,  5749, 22506, 21614,\n",
       "          2748, 16385,  8886, 37310,  8731, 43117, 36663, 32590, 37006, 17912,\n",
       "         17806,  4237, 38816, 32370,  8190,  3087,  2716, 39482, 25831, 31524,\n",
       "         33673, 23635, 30961, 25192, 16657, 39116,  8256, 32211, 27196, 14670,\n",
       "         30120,  8807, 35312,  8976, 20131, 23536, 34601,  4937,  5131, 26060,\n",
       "         40549, 34607, 11040, 21542, 15581, 18317,  5855, 11801,  1727, 23848],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'the opposite of being happy', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['amphibian',\n",
       "  'amphibious',\n",
       "  'swim',\n",
       "  'porpoise',\n",
       "  'plankton',\n",
       "  'aqueous',\n",
       "  'swimmer',\n",
       "  'subaquatic',\n",
       "  'cetacean',\n",
       "  'gill',\n",
       "  'puffer',\n",
       "  'dipper',\n",
       "  'swimming',\n",
       "  'benthos',\n",
       "  'sucker',\n",
       "  'monkfish',\n",
       "  'pelagic',\n",
       "  'underwater',\n",
       "  'hydrate',\n",
       "  'smelt',\n",
       "  'prawn',\n",
       "  'submersible',\n",
       "  'brine',\n",
       "  'salamander',\n",
       "  'ocean',\n",
       "  'limnology',\n",
       "  'beluga',\n",
       "  'leviathan',\n",
       "  'groundfish',\n",
       "  'laver',\n",
       "  'leeching',\n",
       "  'catfish',\n",
       "  'goby',\n",
       "  'porgy',\n",
       "  'neptune',\n",
       "  'pinniped',\n",
       "  'diver',\n",
       "  'hydraulic',\n",
       "  'lifeguard',\n",
       "  'hydrosphere',\n",
       "  'beaver',\n",
       "  'skater',\n",
       "  'drowned',\n",
       "  'bathe',\n",
       "  'sunfish',\n",
       "  'dowse',\n",
       "  'mermaid',\n",
       "  'mussel',\n",
       "  'tadpole',\n",
       "  'dogfish',\n",
       "  'awash',\n",
       "  'sheepshead',\n",
       "  'hardhead',\n",
       "  'grouper',\n",
       "  'planktonic',\n",
       "  'anglerfish',\n",
       "  'jellyfish',\n",
       "  'bloodsucker',\n",
       "  'afloat',\n",
       "  'vessel',\n",
       "  'paddling',\n",
       "  'moray',\n",
       "  'sea',\n",
       "  'darter',\n",
       "  'loach',\n",
       "  'cataract',\n",
       "  'shovelnose',\n",
       "  'mullet',\n",
       "  'swordfish',\n",
       "  'laker',\n",
       "  'butterfish',\n",
       "  'nautilus',\n",
       "  'steamer',\n",
       "  'lake',\n",
       "  'submarine',\n",
       "  'supernatant',\n",
       "  'fount',\n",
       "  'hydroplane',\n",
       "  'floater',\n",
       "  'siren',\n",
       "  'seagoing',\n",
       "  'grayling',\n",
       "  'water',\n",
       "  'hydrography',\n",
       "  'dabbling',\n",
       "  'oyster',\n",
       "  'remora',\n",
       "  'blower',\n",
       "  'marine',\n",
       "  'hydra',\n",
       "  'bream',\n",
       "  'preserver',\n",
       "  'kingfish',\n",
       "  'bonefish',\n",
       "  'ich',\n",
       "  'hydrotherapy',\n",
       "  'butterflyfish',\n",
       "  'hellbender',\n",
       "  'seine',\n",
       "  'reptile'],\n",
       " tensor([10461, 41026, 29554, 38462,   187,   713, 22475, 25763, 44034, 26546,\n",
       "         29289, 37968, 25233, 37034, 30817, 16134, 17623, 25340,  2975,  7530,\n",
       "         15919, 18791,  9003, 35798, 39557, 34223,   414, 17685,  1813, 10265,\n",
       "         16140, 26380, 11176, 33601, 24622, 30723, 20665, 42052, 37759, 18372,\n",
       "          9410, 27672, 35604, 38410,  4219,  8950, 11808,  2112, 14706, 13560,\n",
       "         30705, 36329, 22947, 13670,  7303, 14764, 21745, 26534, 36371, 36778,\n",
       "         18966, 31886, 24709,  3333,   413, 13603, 22962, 17127, 16624,  6358,\n",
       "          3550, 42974, 13395,  2935,  5413,  9973, 32088, 27698, 34064, 25441,\n",
       "         32752, 28062, 30158, 26556, 24021, 36700, 31382, 11628, 20569,  6245,\n",
       "         22889, 22731, 11848,   348,   620,  2200, 36231, 18810,  3533, 26876],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a mammal that lives in water', 100) # decent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['oceanic',\n",
       "  'ocean',\n",
       "  'pelagic',\n",
       "  'neptune',\n",
       "  'sea',\n",
       "  'benthos',\n",
       "  'oceanography',\n",
       "  'marine',\n",
       "  'leviathan',\n",
       "  'transoceanic',\n",
       "  'seagoing',\n",
       "  'nautilus',\n",
       "  'coaster',\n",
       "  'seabird',\n",
       "  'shearwater',\n",
       "  'beluga',\n",
       "  'beachcomber',\n",
       "  'gam',\n",
       "  'underwater',\n",
       "  'oceangoing',\n",
       "  'prawn',\n",
       "  'narwhal',\n",
       "  'monkfish',\n",
       "  'kingfish',\n",
       "  'bowhead',\n",
       "  'subaquatic',\n",
       "  'porpoise',\n",
       "  'transatlantic',\n",
       "  'shovelnose',\n",
       "  'seashell',\n",
       "  'plankton',\n",
       "  'halibut',\n",
       "  'kelp',\n",
       "  'seaweed',\n",
       "  'tsunami',\n",
       "  'cetacean',\n",
       "  'seahorse',\n",
       "  'hake',\n",
       "  'seaboard',\n",
       "  'mussel',\n",
       "  'archipelago',\n",
       "  'blackfish',\n",
       "  'gopher',\n",
       "  'brine',\n",
       "  'reefer',\n",
       "  'jason',\n",
       "  'iceberg',\n",
       "  'main',\n",
       "  'anchovy',\n",
       "  'buoy',\n",
       "  'submarine',\n",
       "  'seafaring',\n",
       "  'hardhead',\n",
       "  'brachiopod',\n",
       "  'manatee',\n",
       "  'atlantic',\n",
       "  'mermaid',\n",
       "  'baleen',\n",
       "  'groundfish',\n",
       "  'planktonic',\n",
       "  'orion',\n",
       "  'amphibian',\n",
       "  'seaward',\n",
       "  'offshore',\n",
       "  'oversea',\n",
       "  'cancer',\n",
       "  'beagle',\n",
       "  'chiton',\n",
       "  'tide',\n",
       "  'dogfish',\n",
       "  'serval',\n",
       "  'hydrosphere',\n",
       "  'moray',\n",
       "  'lobster',\n",
       "  'crustacean',\n",
       "  'cisco',\n",
       "  'porgy',\n",
       "  'shipwreck',\n",
       "  'barracuda',\n",
       "  'circumnavigation',\n",
       "  'submersible',\n",
       "  'hydra',\n",
       "  'marlin',\n",
       "  'afloat',\n",
       "  'amphibious',\n",
       "  'skinned',\n",
       "  'lithosphere',\n",
       "  'squid',\n",
       "  'plaice',\n",
       "  'butterflyfish',\n",
       "  'oyster',\n",
       "  'cooter',\n",
       "  'overseas',\n",
       "  'circumpolar',\n",
       "  'salter',\n",
       "  'gribble',\n",
       "  'bigfoot',\n",
       "  'asthenosphere',\n",
       "  'kraken',\n",
       "  'bobcat'],\n",
       " tensor([ 1858, 39557, 17623, 24622, 24709, 37034,  7241, 20569, 17685,  3277,\n",
       "         32752, 42974, 28224, 38632,   317,   414, 41624, 13067, 25340, 42401,\n",
       "         15919, 13176, 16134, 11848, 40689, 25763, 38462,  7196, 22962, 37590,\n",
       "           187, 39673, 21816, 14017, 35580, 44034, 39346,  3917,   245,  2112,\n",
       "          4600, 21931,  8370,  9003, 26414,   282, 32334, 24005,   747, 16556,\n",
       "          5413, 19017, 22947,  1986,  8678,  3484, 11808, 14418,  1813,  7303,\n",
       "         41885, 10461, 36501, 30314, 34020, 21541, 36393, 16084, 19842, 13560,\n",
       "         23479, 18372, 31886,  2585, 11170,  9089, 33601, 40640, 39538,  1585,\n",
       "         18791,  6245, 17490, 36371, 41026, 34975,  8550,  8177,  4691, 36231,\n",
       "         36700, 42343, 32456, 15673, 20869, 13305, 27717, 31945, 36578, 34105],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a mammal that lives in ocean', 100) # bad results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['scholar',\n",
       "  'pedant',\n",
       "  'student',\n",
       "  'expert',\n",
       "  'professor',\n",
       "  'intellectual',\n",
       "  'literate',\n",
       "  'adept',\n",
       "  'polyglot',\n",
       "  'bookworm',\n",
       "  'lector',\n",
       "  'educator',\n",
       "  'thinker',\n",
       "  'monitor',\n",
       "  'teacher',\n",
       "  'master',\n",
       "  'virtuoso',\n",
       "  'highbrow',\n",
       "  'reader',\n",
       "  'proficient',\n",
       "  'mastering',\n",
       "  'doctoring',\n",
       "  'knowledgeable',\n",
       "  'skeptic',\n",
       "  'amateur',\n",
       "  'connoisseur',\n",
       "  'pedagogue',\n",
       "  'technocrat',\n",
       "  'doctored',\n",
       "  'savant',\n",
       "  'scientist',\n",
       "  'bookman',\n",
       "  'philosopher',\n",
       "  'erudition',\n",
       "  'conversant',\n",
       "  'doctor',\n",
       "  'gnostic',\n",
       "  'cpa',\n",
       "  'appreciator',\n",
       "  'humanist',\n",
       "  'collector',\n",
       "  'pundit',\n",
       "  'learning',\n",
       "  'lettered',\n",
       "  'mandarin',\n",
       "  'science',\n",
       "  'informant',\n",
       "  'generalist',\n",
       "  'artist',\n",
       "  'scholastic',\n",
       "  'teller',\n",
       "  'learner',\n",
       "  'informer',\n",
       "  'tea',\n",
       "  'technologist',\n",
       "  'inquisitor',\n",
       "  'educated',\n",
       "  'lore',\n",
       "  'fellow',\n",
       "  'orator',\n",
       "  'university',\n",
       "  'specialist',\n",
       "  'technician',\n",
       "  'sage',\n",
       "  'brains',\n",
       "  'stargazer',\n",
       "  'scholarship',\n",
       "  'intellect',\n",
       "  'study',\n",
       "  'exegete',\n",
       "  'empiric',\n",
       "  'observer',\n",
       "  'mistress',\n",
       "  'prophet',\n",
       "  'studied',\n",
       "  'herbalist',\n",
       "  'faculty',\n",
       "  'experienced',\n",
       "  'instructor',\n",
       "  'textbook',\n",
       "  'monitoring',\n",
       "  'ace',\n",
       "  'crammer',\n",
       "  'speller',\n",
       "  'reckoner',\n",
       "  'bookish',\n",
       "  'literacy',\n",
       "  'viewer',\n",
       "  'server',\n",
       "  'teachable',\n",
       "  'mathematician',\n",
       "  'logician',\n",
       "  'autodidact',\n",
       "  'analyst',\n",
       "  'boffin',\n",
       "  'exponent',\n",
       "  'skilled',\n",
       "  'computer',\n",
       "  'virtuosity',\n",
       "  'bibliophile'],\n",
       " tensor([ 1930, 19001, 19574, 38183,  2972, 33895, 34372, 38577, 19298, 43513,\n",
       "         43688, 29485, 42798, 10077,  5177, 40203, 37772, 29362, 20318, 26913,\n",
       "         28376, 17576, 21099, 44361, 17103, 24627,  1058, 31246, 34487, 37158,\n",
       "          4512, 28258,  4896, 14530, 40952, 30313, 44251,  8572, 24940, 32069,\n",
       "         30549, 26022, 29078, 23132,  1371, 32959, 12180, 19029, 20681,  2525,\n",
       "         19586,  8131, 13268, 22703, 44018, 38133, 38902,  3138, 38040, 35338,\n",
       "         37240, 10381, 14720, 12819, 25579, 31849, 35224, 22791,  3500, 31618,\n",
       "          2686,   123,  9629, 22396, 30520, 31327, 21082,  2832, 19176,  6775,\n",
       "          6213, 13970, 27976,   652,   370, 30582, 13532,  9698,  6449,    75,\n",
       "         11580,  4441, 21010,  6487, 44174, 44503, 16329, 15344, 27644,   860],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPredFromDesc(model, 'a person who is very knowledgeable about many subjects', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = type(model).__name__\n",
    "filename = f'../trained_models/{model_name} Epoch {epoch+1} at {datetime.datetime.now()}'.replace(' ', '_')\n",
    "with open(filename, 'wb+') as f:\n",
    "    torch.save({'state_dict': model.state_dict()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2017,  2024,  2025, 13346,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(\"you are not helpless\", return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = {train_dataset[i][1] for i in range(len(train_dataset))}\n",
    "dev_words = {dev_dataset[i][1] for i in range(len(dev_dataset))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 44996)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_words), len(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(path):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_data = read_json('../data/wn_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synonyms': ['distressed', 'dysphoric'],\n",
       " 'antonyms': ['euphoric', 'happy'],\n",
       " 'related_forms': ['unhappiness', 'dysphoria'],\n",
       " 'hyponyms': [],\n",
       " 'hypernyms': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_data['unhappy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceBERTForRD('distilbert-base-nli-stsb-mean-tokens', \n",
    "                          len(target2idx), freeze_sbert=False, criterion=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../trained_models/SentenceBERTForRD_Epoch_3_at_2021-05-05_19:58:01.613062')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'a type of tree',\n",
    "    'the opposite of being happy',\n",
    "    'employee at a circus',\n",
    "    'a road on which cars can go quickly without stopping',\n",
    "    'a very intelligent person',\n",
    "    'a very smart person',\n",
    "    'something you use to measure your temperature',\n",
    "    'a dark time of day',\n",
    "    'medieval social hierarchy where peasants and vassals served lords',\n",
    "    'to help someone else learn',\n",
    "    'when someone you trust does something that breaks your trust',\n",
    "    'deep learning'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a type of tree\n",
      "(['tree',\n",
      "  'treed',\n",
      "  'eucalypt',\n",
      "  'arboreal',\n",
      "  'barking',\n",
      "  'birch',\n",
      "  'fir',\n",
      "  'hemlock',\n",
      "  'leatherwood',\n",
      "  'butternut',\n",
      "  'stocks',\n",
      "  'aspen',\n",
      "  'softwood',\n",
      "  'brushwood',\n",
      "  'durian',\n",
      "  'sapling',\n",
      "  'forester',\n",
      "  'sylvan',\n",
      "  'broadleaf',\n",
      "  'oak',\n",
      "  'redwood',\n",
      "  'tope',\n",
      "  'nutmeg',\n",
      "  'carambola',\n",
      "  'deodar',\n",
      "  'balsa',\n",
      "  'logwood',\n",
      "  'longan',\n",
      "  'bole',\n",
      "  'swede',\n",
      "  'rambutan',\n",
      "  'trunked',\n",
      "  'burl',\n",
      "  'blackwood',\n",
      "  'loquat',\n",
      "  'trunks',\n",
      "  'coppice',\n",
      "  'oaken',\n",
      "  'toon',\n",
      "  'sugarbush',\n",
      "  'stocked',\n",
      "  'haw',\n",
      "  'nox',\n",
      "  'forest',\n",
      "  'palm',\n",
      "  'dudgeon',\n",
      "  'chinquapin',\n",
      "  'pecker',\n",
      "  'roe',\n",
      "  'timberland',\n",
      "  'brand',\n",
      "  'mast',\n",
      "  'gumming',\n",
      "  'knot',\n",
      "  'flag',\n",
      "  'stick',\n",
      "  'sticks',\n",
      "  'sycamore',\n",
      "  'dogwood',\n",
      "  'cedar',\n",
      "  'pollard',\n",
      "  'twiggy',\n",
      "  'bau',\n",
      "  'catalpa',\n",
      "  'liana',\n",
      "  'hazel',\n",
      "  'kauri',\n",
      "  'twig',\n",
      "  'limb',\n",
      "  'sapodilla',\n",
      "  'bough',\n",
      "  'locust',\n",
      "  'fig',\n",
      "  'teak',\n",
      "  'cypress',\n",
      "  'mahogany',\n",
      "  'spurring',\n",
      "  'atm',\n",
      "  'pawpaw',\n",
      "  'superior',\n",
      "  'baying',\n",
      "  'preen',\n",
      "  'crown',\n",
      "  'casuarina',\n",
      "  'hickory',\n",
      "  'poplar',\n",
      "  'stoned',\n",
      "  'kaki',\n",
      "  'maple',\n",
      "  'persimmon',\n",
      "  'chestnut',\n",
      "  'holm',\n",
      "  'laburnum',\n",
      "  'winter',\n",
      "  'pipal',\n",
      "  'crabs',\n",
      "  'pear',\n",
      "  'sassafras',\n",
      "  'corking',\n",
      "  'calabash'],\n",
      " tensor([19190,  6880,  9430,  2228, 30198, 20870,  1662, 21499, 25615, 44158,\n",
      "        18537, 27755,  8544,  2813,  5616, 12471, 33961, 36353,  9957, 21233,\n",
      "        11847,   264, 16892,  6885, 27744,  9950, 44267,   248,  6456,  4538,\n",
      "        40636, 24040,  1669, 18350, 24402, 27436, 37549, 30638,  7118, 15368,\n",
      "         2918, 30278,  8251, 29880,  3487, 30450,  4301, 41109,  3757, 30136,\n",
      "        23162, 20496, 33291, 11997,  9448, 43245, 17917, 15302, 41880, 38054,\n",
      "        36534, 36790, 21862, 31106, 19063, 33988, 30083, 16656,   579, 17091,\n",
      "        41412, 21164, 43825, 12255, 11498, 36541, 38703, 22353,  9470, 20417,\n",
      "        40501, 23122, 35812, 32920, 39430,  6516, 13216, 27927,  4171, 30578,\n",
      "        35239,  4056, 37233, 26260,  5382,  2297, 39679, 37463,  6063, 42066],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for the opposite of being happy\n",
      "(['cynic',\n",
      "  'sport',\n",
      "  'romantic',\n",
      "  'romanticism',\n",
      "  'egoism',\n",
      "  'egotism',\n",
      "  'cynical',\n",
      "  'ungrateful',\n",
      "  'adverse',\n",
      "  'indecent',\n",
      "  'dovish',\n",
      "  'unbecoming',\n",
      "  'sadness',\n",
      "  'sports',\n",
      "  'optimist',\n",
      "  'negative',\n",
      "  'felicity',\n",
      "  'cool',\n",
      "  'off',\n",
      "  'optimism',\n",
      "  'backward',\n",
      "  'good',\n",
      "  'laugh',\n",
      "  'lee',\n",
      "  'unrewarding',\n",
      "  'disinterest',\n",
      "  'fooling',\n",
      "  'evil',\n",
      "  'lovely',\n",
      "  'dished',\n",
      "  'unpromising',\n",
      "  'oll',\n",
      "  'prettiness',\n",
      "  'antipodes',\n",
      "  'junket',\n",
      "  'behavior',\n",
      "  'barrenness',\n",
      "  'laughter',\n",
      "  'disadvantageous',\n",
      "  'happiness',\n",
      "  'iff',\n",
      "  'demerit',\n",
      "  'aversion',\n",
      "  'gaiety',\n",
      "  'ues',\n",
      "  'pff',\n",
      "  'tropism',\n",
      "  'reverse',\n",
      "  'gainful',\n",
      "  'propensity',\n",
      "  'alienation',\n",
      "  'anima',\n",
      "  'spoilsport',\n",
      "  'handedness',\n",
      "  'base',\n",
      "  'unpatriotic',\n",
      "  'sympathy',\n",
      "  'transexual',\n",
      "  'irony',\n",
      "  'retrograde',\n",
      "  'flip',\n",
      "  'churl',\n",
      "  'pleasant',\n",
      "  'genial',\n",
      "  'contrariwise',\n",
      "  'glad',\n",
      "  'deflation',\n",
      "  'drawback',\n",
      "  'platonic',\n",
      "  'euphoric',\n",
      "  'toy',\n",
      "  'alien',\n",
      "  'ambition',\n",
      "  'straightness',\n",
      "  'vad',\n",
      "  'uncharitable',\n",
      "  'secularism',\n",
      "  'love',\n",
      "  'jokes',\n",
      "  'contrasting',\n",
      "  'fool',\n",
      "  'expedience',\n",
      "  'turn',\n",
      "  'barren',\n",
      "  'misconduct',\n",
      "  'reciprocal',\n",
      "  'friction',\n",
      "  'jaundice',\n",
      "  'advantageous',\n",
      "  'deviance',\n",
      "  'undesirable',\n",
      "  'jejune',\n",
      "  'neutral',\n",
      "  'fondness',\n",
      "  'pride',\n",
      "  'unhappy',\n",
      "  'reins',\n",
      "  'antagonistic',\n",
      "  'opposition',\n",
      "  'inclination'],\n",
      " tensor([  482, 11265, 16312, 41452, 38568, 11322, 13565, 25205, 20373, 34957,\n",
      "         2273, 42662,   128, 41011, 42402, 16643, 24733, 17559, 41309, 11295,\n",
      "         3998,  1465,   159,  5406, 40746, 32590, 14092, 39768, 12638,  7544,\n",
      "        13397, 34601, 41460, 38154, 34266,   146, 43533, 44817,  9996, 29088,\n",
      "        28697, 16385, 20138,  2748,  8989,  6313, 32801,  4043,  7686, 17377,\n",
      "        24867, 36122,  2161, 34855, 12282, 11849,   927, 39173, 31131, 21321,\n",
      "        36402,  8837, 42278,  3511, 40475, 31800, 17579, 19266, 37784, 38038,\n",
      "        22582, 34554,  4101, 16254,  1666, 28707,  7866, 11183, 26920, 17580,\n",
      "        17206, 35007, 31034,  5233, 35327, 16137, 22533, 44599,  4364, 27434,\n",
      "        32997, 19956, 29639, 26725, 20031, 11144, 35500,  6462,  6471,  6903],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for employee at a circus\n",
      "(['bughouse',\n",
      "  'sideshow',\n",
      "  'museology',\n",
      "  'clown',\n",
      "  'mountebank',\n",
      "  'impresario',\n",
      "  'butchers',\n",
      "  'fairground',\n",
      "  'loge',\n",
      "  'pageant',\n",
      "  'shew',\n",
      "  'shop',\n",
      "  'canteen',\n",
      "  'shopping',\n",
      "  'panopticon',\n",
      "  'cad',\n",
      "  'trapeze',\n",
      "  'butcher',\n",
      "  'professor',\n",
      "  'dpa',\n",
      "  'gypsy',\n",
      "  'carnival',\n",
      "  'exhibition',\n",
      "  'stunt',\n",
      "  'circus',\n",
      "  'bazaar',\n",
      "  'stalls',\n",
      "  'hostel',\n",
      "  'stunting',\n",
      "  'snark',\n",
      "  'museum',\n",
      "  'usher',\n",
      "  'nox',\n",
      "  'garter',\n",
      "  'sport',\n",
      "  'parquet',\n",
      "  'company',\n",
      "  'pavillion',\n",
      "  'pavilion',\n",
      "  'upstage',\n",
      "  'goat',\n",
      "  'serai',\n",
      "  'barnstorm',\n",
      "  'hosiery',\n",
      "  'roustabout',\n",
      "  'situation',\n",
      "  'bellboy',\n",
      "  'troupe',\n",
      "  'gripping',\n",
      "  'carrousel',\n",
      "  'fooling',\n",
      "  'laboratory',\n",
      "  'commissary',\n",
      "  'barrack',\n",
      "  'conservatory',\n",
      "  'publican',\n",
      "  'illusionist',\n",
      "  'circle',\n",
      "  'spectator',\n",
      "  'mansfield',\n",
      "  'expo',\n",
      "  'staged',\n",
      "  'showgrounds',\n",
      "  'town',\n",
      "  'amphitheater',\n",
      "  'acy',\n",
      "  'buffalo',\n",
      "  'spectacular',\n",
      "  'edmonton',\n",
      "  'theater',\n",
      "  'trapped',\n",
      "  'theatergoer',\n",
      "  'school',\n",
      "  'vault',\n",
      "  'lamasery',\n",
      "  'gymnasium',\n",
      "  'salesclerk',\n",
      "  'showroom',\n",
      "  'ostentation',\n",
      "  'harbor',\n",
      "  'loggia',\n",
      "  'job',\n",
      "  'miraculous',\n",
      "  'cribbed',\n",
      "  'gyp',\n",
      "  'balcony',\n",
      "  'pen',\n",
      "  'amazed',\n",
      "  'cody',\n",
      "  'entertainment',\n",
      "  'foyer',\n",
      "  'restaurateur',\n",
      "  'posing',\n",
      "  'insane',\n",
      "  'conservator',\n",
      "  'actor',\n",
      "  'institutionalize',\n",
      "  'gig',\n",
      "  'novelist',\n",
      "  'verger'],\n",
      " tensor([ 8533,  8174,   269, 40171,  7183, 21478, 22470,  9960, 34024, 34578,\n",
      "        29730, 15203, 27730, 16284,  6376, 22897,  4733, 31220,  2972,  2867,\n",
      "        15094, 30616, 20184, 21695, 27089, 31844, 37835,  5181, 18212, 43327,\n",
      "         9081, 26968,  8251, 32887, 11265,  1229, 27510, 10788, 31078, 14004,\n",
      "        33493, 40060, 39957, 23687, 29469, 13593,  6437, 24038,   757, 15999,\n",
      "        14092, 31803, 11735, 22359,  2901, 27683, 21687, 24459, 31770,  3173,\n",
      "        19875, 16817, 27398, 22613, 16475, 43651, 12620,  1408, 28167,  5493,\n",
      "        10465, 40052, 17639, 17266, 15634, 36786, 25085, 19040, 25323, 23090,\n",
      "        25128, 20043, 34539, 31268, 32252, 10957,  1702,  2269,  5803,  1619,\n",
      "        44286, 40822, 28741, 35847, 31787, 34683,  7926, 36685,  4808, 17123],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a road on which cars can go quickly without stopping\n",
      "(['hitchhiking',\n",
      "  'mobile',\n",
      "  'fasting',\n",
      "  'runs',\n",
      "  'tailgate',\n",
      "  'crash',\n",
      "  'shuttle',\n",
      "  'run',\n",
      "  'rolled',\n",
      "  'roll',\n",
      "  'csr',\n",
      "  'nus',\n",
      "  'fast',\n",
      "  'drive',\n",
      "  'slide',\n",
      "  'fleet',\n",
      "  'door',\n",
      "  'hijack',\n",
      "  'tracks',\n",
      "  'skid',\n",
      "  'through',\n",
      "  'taxiing',\n",
      "  'clear',\n",
      "  'go',\n",
      "  'shuttling',\n",
      "  'hop',\n",
      "  'gridlock',\n",
      "  'passed',\n",
      "  'lurch',\n",
      "  'street',\n",
      "  'cab',\n",
      "  'hops',\n",
      "  'tipple',\n",
      "  'rushes',\n",
      "  'cruising',\n",
      "  'chase',\n",
      "  'thoroughfare',\n",
      "  'cleared',\n",
      "  'riad',\n",
      "  'slipped',\n",
      "  'slick',\n",
      "  'detroit',\n",
      "  'rushing',\n",
      "  'roadster',\n",
      "  'circumnavigate',\n",
      "  'bua',\n",
      "  'streamed',\n",
      "  'strand',\n",
      "  'trapping',\n",
      "  'quickstep',\n",
      "  'swarming',\n",
      "  'rop',\n",
      "  'surrounded',\n",
      "  'rummaging',\n",
      "  'hijacking',\n",
      "  'trucks',\n",
      "  'cruiser',\n",
      "  'dribble',\n",
      "  'fly',\n",
      "  'motorcade',\n",
      "  'clearance',\n",
      "  'wau',\n",
      "  'corner',\n",
      "  'close',\n",
      "  'ferrying',\n",
      "  'fording',\n",
      "  'concourse',\n",
      "  'hacking',\n",
      "  'film',\n",
      "  'flash',\n",
      "  'car',\n",
      "  'driveway',\n",
      "  'trotting',\n",
      "  'carpool',\n",
      "  'crawl',\n",
      "  'quicksand',\n",
      "  'skipping',\n",
      "  'travel',\n",
      "  'coast',\n",
      "  'rally',\n",
      "  'lock',\n",
      "  'bus',\n",
      "  'float',\n",
      "  'getaway',\n",
      "  'stranded',\n",
      "  'inbound',\n",
      "  'flight',\n",
      "  'ramble',\n",
      "  'sail',\n",
      "  'wash',\n",
      "  'rattling',\n",
      "  'pass',\n",
      "  'interchange',\n",
      "  'locks',\n",
      "  'romp',\n",
      "  'boxcar',\n",
      "  'railroad',\n",
      "  'jeep',\n",
      "  'carjacking',\n",
      "  'rush'],\n",
      " tensor([  364, 43703, 29769, 43700, 26400, 10968, 22355, 37921, 32914,  2701,\n",
      "        36911, 14324,  4241, 34151, 31065,  8168, 24309, 33503,   261, 26597,\n",
      "        25517, 36608, 34941, 15331, 12901, 43217, 31649, 32656,  3244, 12457,\n",
      "        11404, 28141,  6932,   795, 21129, 19823, 29589, 17264,  3873,  5160,\n",
      "        17171, 23994, 22518, 15250, 20600,  6817,  4080, 36860,  8537, 13450,\n",
      "        16333, 33348, 25687, 20086, 35133, 16884,   971,  8042,  7038, 34224,\n",
      "        27666, 26989, 31347,  9786, 28309,  1105, 22094, 25707, 34354, 39649,\n",
      "        37609, 17262, 19737, 23846,  3121, 10667, 31802, 31950, 17536, 18694,\n",
      "        37083,   619, 23063, 41689,  7270, 24966, 41677, 31337,  6392,  9840,\n",
      "        19991, 24348, 21922, 32935, 13034,  7121, 25796,  5187, 33339, 24395],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a very intelligent person\n",
      "(['brain',\n",
      "  'brightly',\n",
      "  'intelligently',\n",
      "  'powerful',\n",
      "  'brains',\n",
      "  'genius',\n",
      "  'sapient',\n",
      "  'smarting',\n",
      "  'strong',\n",
      "  'sagacious',\n",
      "  'smart',\n",
      "  'proficient',\n",
      "  'smarts',\n",
      "  'resourceful',\n",
      "  'knowledgeable',\n",
      "  'belter',\n",
      "  'sensitive',\n",
      "  'golden',\n",
      "  'cutely',\n",
      "  'cleverness',\n",
      "  'brilliantly',\n",
      "  'bright',\n",
      "  'knowing',\n",
      "  'mandarin',\n",
      "  'grat',\n",
      "  'adept',\n",
      "  'knockout',\n",
      "  'intelligent',\n",
      "  'giant',\n",
      "  'favorable',\n",
      "  'beauteous',\n",
      "  'ace',\n",
      "  'connoisseur',\n",
      "  'splendid',\n",
      "  'dear',\n",
      "  'delicious',\n",
      "  'visionary',\n",
      "  'daisy',\n",
      "  'brainy',\n",
      "  'perspicacity',\n",
      "  'divinity',\n",
      "  'perspicacious',\n",
      "  'crackerjack',\n",
      "  'clever',\n",
      "  'adeptness',\n",
      "  'aristocracy',\n",
      "  'great',\n",
      "  'perfected',\n",
      "  'lass',\n",
      "  'brilliant',\n",
      "  'brightness',\n",
      "  'rich',\n",
      "  'smartly',\n",
      "  'lovely',\n",
      "  'brainiac',\n",
      "  'analyst',\n",
      "  'belles',\n",
      "  'good',\n",
      "  'understanding',\n",
      "  'mastering',\n",
      "  'stong',\n",
      "  'sagacity',\n",
      "  'selectively',\n",
      "  'goodly',\n",
      "  'slick',\n",
      "  'farseeing',\n",
      "  'iphone',\n",
      "  'fines',\n",
      "  'logician',\n",
      "  'decoder',\n",
      "  'bombshell',\n",
      "  'efficiency',\n",
      "  'smartness',\n",
      "  'taking',\n",
      "  'oligarch',\n",
      "  'efficiently',\n",
      "  'felicity',\n",
      "  'productive',\n",
      "  'stunning',\n",
      "  'goldmine',\n",
      "  'highbrow',\n",
      "  'big',\n",
      "  'cute',\n",
      "  'android',\n",
      "  'czar',\n",
      "  'toothsome',\n",
      "  'mogul',\n",
      "  'kindly',\n",
      "  'sweetheart',\n",
      "  'apparent',\n",
      "  'respectability',\n",
      "  'trojan',\n",
      "  'capable',\n",
      "  'stunner',\n",
      "  'superb',\n",
      "  'sensible',\n",
      "  'breakthrough',\n",
      "  'fortunately',\n",
      "  'tomato',\n",
      "  'angel'],\n",
      " tensor([38338, 42590, 27477, 31891, 25579, 27923, 29465,  5311, 19269, 27935,\n",
      "        31720, 26913, 33125, 15773, 21099, 23095, 35386, 17270, 22249, 19335,\n",
      "        32739, 15624, 21410,  1371,  6402, 38577, 12220, 12896, 29538,    46,\n",
      "        34028, 13970, 24627, 29300, 37646, 15071, 26837, 39576, 22053,    99,\n",
      "          598, 30937, 13641, 22441, 18361, 41717, 37744, 42353,  2891,  9645,\n",
      "         7408, 17253, 19243, 12638, 15336,  6487, 42833,  1465, 42157, 28376,\n",
      "        27669,  4953, 22050, 22953, 17171, 26172, 18451, 30088,  4441, 12157,\n",
      "        44579, 42088, 38157, 25336,  3820, 33360, 24733, 42007, 38475, 22483,\n",
      "        29362,  4344, 31375, 23945, 19321, 31553, 17710,  6869,  6926, 31556,\n",
      "        39439,  7418, 11407, 23111, 27767, 16946, 14892, 42427, 27795, 31850],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a very smart person\n",
      "(['smarts',\n",
      "  'smarting',\n",
      "  'smart',\n",
      "  'belter',\n",
      "  'brightly',\n",
      "  'brain',\n",
      "  'proficient',\n",
      "  'dear',\n",
      "  'strong',\n",
      "  'sagacious',\n",
      "  'clever',\n",
      "  'sapient',\n",
      "  'favorable',\n",
      "  'smartly',\n",
      "  'cutely',\n",
      "  'sensitive',\n",
      "  'brains',\n",
      "  'bright',\n",
      "  'knowledgeable',\n",
      "  'adept',\n",
      "  'cleverness',\n",
      "  'selectively',\n",
      "  'genius',\n",
      "  'kindly',\n",
      "  'lass',\n",
      "  'golden',\n",
      "  'daisy',\n",
      "  'good',\n",
      "  'crackerjack',\n",
      "  'lovely',\n",
      "  'sweet',\n",
      "  'knowing',\n",
      "  'ace',\n",
      "  'brilliant',\n",
      "  'grat',\n",
      "  'mandarin',\n",
      "  'sweetheart',\n",
      "  'mastering',\n",
      "  'delicious',\n",
      "  'intelligently',\n",
      "  'resourceful',\n",
      "  'smartness',\n",
      "  'felicity',\n",
      "  'beauteous',\n",
      "  'adeptness',\n",
      "  'handy',\n",
      "  'perspicacious',\n",
      "  'felicitous',\n",
      "  'great',\n",
      "  'brilliantly',\n",
      "  'powerful',\n",
      "  'sharpie',\n",
      "  'tactician',\n",
      "  'slick',\n",
      "  'brightness',\n",
      "  'accurate',\n",
      "  'intelligent',\n",
      "  'trojan',\n",
      "  'perfected',\n",
      "  'belles',\n",
      "  'alert',\n",
      "  'fines',\n",
      "  'visionary',\n",
      "  'trusty',\n",
      "  'rich',\n",
      "  'faithful',\n",
      "  'big',\n",
      "  'nut',\n",
      "  'superb',\n",
      "  'cute',\n",
      "  'stunning',\n",
      "  'cropper',\n",
      "  'splendid',\n",
      "  'vig',\n",
      "  'goodly',\n",
      "  'taking',\n",
      "  'brainy',\n",
      "  'connoisseur',\n",
      "  'pick',\n",
      "  'toothsome',\n",
      "  'productive',\n",
      "  'smug',\n",
      "  'filly',\n",
      "  'angel',\n",
      "  'thoroughbred',\n",
      "  'ducky',\n",
      "  'sensible',\n",
      "  'knockout',\n",
      "  'choice',\n",
      "  'aristocracy',\n",
      "  'manager',\n",
      "  'sharp',\n",
      "  'forte',\n",
      "  'bombshell',\n",
      "  'understanding',\n",
      "  'divinity',\n",
      "  'dewey',\n",
      "  'beloved',\n",
      "  'goldmine',\n",
      "  'dvd'],\n",
      " tensor([33125,  5311, 31720, 23095, 42590, 38338, 26913, 37646, 19269, 27935,\n",
      "        22441, 29465,    46, 19243, 22249, 35386, 25579, 15624, 21099, 38577,\n",
      "        19335, 22050, 27923,  6869,  2891, 17270, 39576,  1465, 13641, 12638,\n",
      "        30619, 21410, 13970,  9645,  6402,  1371,  6926, 28376, 15071, 27477,\n",
      "        15773, 38157, 24733, 34028, 18361,  6026, 30937, 28302, 37744, 32739,\n",
      "        31891, 25437, 10682, 17171,  7408, 31336, 12896,  7418, 42353, 42833,\n",
      "        38194, 30088, 26837,  2512, 17253, 40829,  4344, 32421, 27767, 31375,\n",
      "        38475,  3715, 29300,  7881, 22953, 25336, 22053, 24627, 23466, 31553,\n",
      "        42007, 34317, 28717, 31850,  4220, 37629, 16946, 12220, 40697, 41717,\n",
      "        20614, 22269,  6944, 44579, 42157,   598, 15351, 31390, 22483, 15069],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for something you use to measure your temperature\n",
      "(['thermometer',\n",
      "  'heat',\n",
      "  'isotherm',\n",
      "  'pyrometer',\n",
      "  'sets',\n",
      "  'thermometry',\n",
      "  'thermostat',\n",
      "  'reading',\n",
      "  'fahrenheit',\n",
      "  'calorimeter',\n",
      "  'acclimatization',\n",
      "  'het',\n",
      "  'thermocouple',\n",
      "  'frost',\n",
      "  'fanned',\n",
      "  'dew',\n",
      "  'climate',\n",
      "  'set',\n",
      "  'tipped',\n",
      "  'strike',\n",
      "  'fan',\n",
      "  'refrigerant',\n",
      "  'sunset',\n",
      "  'meter',\n",
      "  'chills',\n",
      "  'anemometer',\n",
      "  'cool',\n",
      "  'cook',\n",
      "  'dips',\n",
      "  'celsius',\n",
      "  'sweat',\n",
      "  'ice',\n",
      "  'refrigerating',\n",
      "  'metering',\n",
      "  'calibrated',\n",
      "  'bask',\n",
      "  'centigrade',\n",
      "  'jiffy',\n",
      "  'clime',\n",
      "  'dosimeter',\n",
      "  'climatology',\n",
      "  'dip',\n",
      "  'cooler',\n",
      "  'rated',\n",
      "  'cold',\n",
      "  'glass',\n",
      "  'feel',\n",
      "  'dio',\n",
      "  'thaw',\n",
      "  'beats',\n",
      "  'scout',\n",
      "  'thermopile',\n",
      "  'airs',\n",
      "  'heater',\n",
      "  'melted',\n",
      "  'exothermic',\n",
      "  'calorie',\n",
      "  'lap',\n",
      "  'inclination',\n",
      "  'scale',\n",
      "  'cooked',\n",
      "  'thawing',\n",
      "  'refrigeration',\n",
      "  'calendar',\n",
      "  'heating',\n",
      "  'chronograph',\n",
      "  'spaced',\n",
      "  'hot',\n",
      "  'temper',\n",
      "  'fin',\n",
      "  'tachograph',\n",
      "  'smoke',\n",
      "  'boil',\n",
      "  'tryst',\n",
      "  'graduate',\n",
      "  'melt',\n",
      "  'touched',\n",
      "  'photometer',\n",
      "  'calm',\n",
      "  'form',\n",
      "  'on',\n",
      "  'parch',\n",
      "  'hiss',\n",
      "  'hypothermia',\n",
      "  'beat',\n",
      "  'touch',\n",
      "  'biometrics',\n",
      "  'fever',\n",
      "  'breathe',\n",
      "  'tans',\n",
      "  'stroked',\n",
      "  'atmosphere',\n",
      "  'ergometer',\n",
      "  'prick',\n",
      "  'thermography',\n",
      "  'steam',\n",
      "  'scores',\n",
      "  'compensator',\n",
      "  'go',\n",
      "  'styling'],\n",
      " tensor([21694, 25497, 35931, 39573, 41539,  2316, 27127, 41191, 23558, 43736,\n",
      "        16542, 14356, 33373, 16958,  5752,  8482,  2795,  2086,  8643,  6738,\n",
      "        28874, 39099,  2201, 33029, 17814,  8840, 17559, 40531,  3849, 13409,\n",
      "        10893,    24, 11440, 15495, 37950,   145, 43549, 22740,  1027,  2775,\n",
      "        17499, 24500, 11401, 43528, 13156, 39183, 35696, 40726, 21344, 16489,\n",
      "        23530, 16077, 38784,  8653, 12488, 32944, 36670, 14256,  6903, 29721,\n",
      "        28764, 17230, 15343, 32769, 33404, 31776, 36597,  9961, 12738, 30573,\n",
      "        17827, 13751,  8332,  4518, 17675,  8773, 33804,  7510, 14895, 17618,\n",
      "        26691,  4258, 18606, 23107, 30799,  7490, 17941, 12720,  2658, 20889,\n",
      "         2093, 17420, 12824, 28997,  6023, 37781, 19999, 30390, 15331, 11055],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a dark time of day\n",
      "(['night',\n",
      "  'dau',\n",
      "  'fark',\n",
      "  'day',\n",
      "  'gloom',\n",
      "  'darkness',\n",
      "  'dusky',\n",
      "  'darkling',\n",
      "  'shades',\n",
      "  'shade',\n",
      "  'darkly',\n",
      "  'late',\n",
      "  'daytime',\n",
      "  'gloaming',\n",
      "  'sunset',\n",
      "  'hour',\n",
      "  'tenebrous',\n",
      "  'diurnal',\n",
      "  'nimbus',\n",
      "  'grays',\n",
      "  'noon',\n",
      "  'blue',\n",
      "  'evening',\n",
      "  'black',\n",
      "  'dun',\n",
      "  'deep',\n",
      "  'dusk',\n",
      "  'tans',\n",
      "  'eos',\n",
      "  'bivouac',\n",
      "  'shadowed',\n",
      "  'eventide',\n",
      "  'earth',\n",
      "  'dimmed',\n",
      "  'midnight',\n",
      "  'climate',\n",
      "  'morning',\n",
      "  'darkish',\n",
      "  'earthed',\n",
      "  'quarters',\n",
      "  'moonlight',\n",
      "  'nights',\n",
      "  'setting',\n",
      "  'nightdress',\n",
      "  'kook',\n",
      "  'eve',\n",
      "  'forenoon',\n",
      "  'opaque',\n",
      "  'sombre',\n",
      "  'winters',\n",
      "  'reflectivity',\n",
      "  'journal',\n",
      "  'daylight',\n",
      "  'today',\n",
      "  'owl',\n",
      "  'twilight',\n",
      "  'heliotrope',\n",
      "  'greyed',\n",
      "  'sunglasses',\n",
      "  'l',\n",
      "  'donner',\n",
      "  'calendar',\n",
      "  'shadowy',\n",
      "  'journey',\n",
      "  'eyes',\n",
      "  'month',\n",
      "  'illumination',\n",
      "  'pm',\n",
      "  'against',\n",
      "  'saturday',\n",
      "  'azure',\n",
      "  'gypsy',\n",
      "  'time',\n",
      "  'secretiveness',\n",
      "  'somberness',\n",
      "  'squint',\n",
      "  'house',\n",
      "  'eye',\n",
      "  'career',\n",
      "  'src',\n",
      "  'mansion',\n",
      "  'serene',\n",
      "  'clime',\n",
      "  'moonlit',\n",
      "  'darken',\n",
      "  'cloudy',\n",
      "  'diamond',\n",
      "  'blindfold',\n",
      "  'kakapo',\n",
      "  'brunet',\n",
      "  'looks',\n",
      "  'tan',\n",
      "  'dial',\n",
      "  'orb',\n",
      "  'shadow',\n",
      "  'sleep',\n",
      "  'dating',\n",
      "  'timed',\n",
      "  'ramadan',\n",
      "  'christianity'],\n",
      " tensor([30711, 32386, 38058, 32315, 36896, 10330, 18941, 17315, 31799, 31443,\n",
      "        21620, 38339, 37962,  2067,  2201, 28253,  1886, 31894,  3033, 34442,\n",
      "         7127, 27185, 32790, 34961, 18814, 16815, 23883, 20889, 42745, 25167,\n",
      "        44104,  3050, 15313, 23961,  5123,  2795, 20406,  8159, 35522, 43315,\n",
      "        26205, 19595, 29595, 39101, 38243, 18649,  9972, 39594,  4304, 14179,\n",
      "        42821, 40969, 11277, 38705, 36215, 18812,  9437, 32289, 13297, 24904,\n",
      "        26011, 32769,  9632, 33915, 43622,  6200, 43991, 29074, 24671, 36637,\n",
      "         4554, 15094, 28884, 35465,  8888, 13507,  7128, 11231, 31341,  2863,\n",
      "        22986, 18015,  1027, 15303, 42095, 16655, 18021, 22136, 28368, 27911,\n",
      "         2133, 12683, 17869, 27805, 37961, 43188, 25534,  9326, 11012, 35342],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for medieval social hierarchy where peasants and vassals served lords\n",
      "(['serf',\n",
      "  'lord',\n",
      "  'thane',\n",
      "  'feud',\n",
      "  'family',\n",
      "  'lords',\n",
      "  'fiefdom',\n",
      "  'nobility',\n",
      "  'vassal',\n",
      "  'honoring',\n",
      "  'knight',\n",
      "  'patriarchate',\n",
      "  'gentry',\n",
      "  'dynasty',\n",
      "  'aristocracy',\n",
      "  'presbytery',\n",
      "  'manor',\n",
      "  'blackguard',\n",
      "  'gens',\n",
      "  'terrier',\n",
      "  'meritocracy',\n",
      "  'chivalry',\n",
      "  'feudal',\n",
      "  'nomenklatura',\n",
      "  'castle',\n",
      "  'commune',\n",
      "  'suzerain',\n",
      "  'caste',\n",
      "  'noble',\n",
      "  'peerage',\n",
      "  'labor',\n",
      "  'servitude',\n",
      "  'reeve',\n",
      "  'marquis',\n",
      "  'medievalism',\n",
      "  'butler',\n",
      "  'cossack',\n",
      "  'aristocratic',\n",
      "  'bourgeoisie',\n",
      "  'lumpenproletariat',\n",
      "  'solon',\n",
      "  'people',\n",
      "  'council',\n",
      "  'peoples',\n",
      "  'patrician',\n",
      "  'majordomo',\n",
      "  'baron',\n",
      "  'bushido',\n",
      "  'constable',\n",
      "  'roundhouse',\n",
      "  'familly',\n",
      "  'bourgeois',\n",
      "  'henchman',\n",
      "  'bailiff',\n",
      "  'duke',\n",
      "  'mankind',\n",
      "  'matriarchy',\n",
      "  'senate',\n",
      "  'clientele',\n",
      "  'roundtable',\n",
      "  'court',\n",
      "  'oligarchy',\n",
      "  'peering',\n",
      "  'gendarmerie',\n",
      "  'tenure',\n",
      "  'khan',\n",
      "  'oligarch',\n",
      "  'marxism',\n",
      "  'ranking',\n",
      "  'crew',\n",
      "  'rancho',\n",
      "  'palatine',\n",
      "  'pharaoh',\n",
      "  'aif',\n",
      "  'livery',\n",
      "  'gang',\n",
      "  'grange',\n",
      "  'rector',\n",
      "  'master',\n",
      "  'downward',\n",
      "  'descent',\n",
      "  'stocks',\n",
      "  'tabard',\n",
      "  'ascendant',\n",
      "  'mastering',\n",
      "  'cacique',\n",
      "  'page',\n",
      "  'phylum',\n",
      "  'gregarious',\n",
      "  'verge',\n",
      "  'bulldozer',\n",
      "  'steward',\n",
      "  'gentleman',\n",
      "  'rectory',\n",
      "  'tenement',\n",
      "  'peer',\n",
      "  'socal',\n",
      "  'brothers',\n",
      "  'bloods',\n",
      "  'knighthood'],\n",
      " tensor([ 8320, 24469, 18300, 18471, 27443, 18960, 43377, 22184, 13253,  3706,\n",
      "        11496,  3283, 42087, 17503, 41717, 10348, 37213, 15451, 10144, 38612,\n",
      "        18843, 25317, 15563, 17815, 26177,  4431,  6337, 11967, 26478, 12372,\n",
      "         8216,  4777, 16343, 17962, 27831, 42655, 22684, 28229,  7867, 20635,\n",
      "         3300, 27123, 29042, 23645, 14437, 42306, 32815,  9329, 34240,  3464,\n",
      "         7422, 36893,  9915, 22049, 22839, 42987, 30679, 37728, 35646, 29200,\n",
      "        29739,  1054, 19822,  1332, 38826, 20375,  3820,  8720, 27530, 16887,\n",
      "        12651, 40556,  9675, 15332, 38399,  8532, 35014,  5680, 40203,  5800,\n",
      "        17611, 18537,  4889,  7467, 28376,  7631, 30952,  1405,   575, 20688,\n",
      "        41277, 30594, 44808, 15058, 39815, 25372, 32131, 28687, 12674,  2796],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for to help someone else learn\n",
      "(['learn',\n",
      "  'tutoring',\n",
      "  'help',\n",
      "  'shift',\n",
      "  'understand',\n",
      "  'disciple',\n",
      "  'edified',\n",
      "  'caring',\n",
      "  'add',\n",
      "  'substitute',\n",
      "  'study',\n",
      "  'relaxed',\n",
      "  'improve',\n",
      "  'shop',\n",
      "  'translate',\n",
      "  'develop',\n",
      "  'tutor',\n",
      "  'student',\n",
      "  'socialized',\n",
      "  'sophisticated',\n",
      "  'fah',\n",
      "  'school',\n",
      "  'touch',\n",
      "  'confuse',\n",
      "  'guide',\n",
      "  'discover',\n",
      "  'lower',\n",
      "  'sweeten',\n",
      "  'subject',\n",
      "  'fellow',\n",
      "  'better',\n",
      "  'apprentice',\n",
      "  'con',\n",
      "  'facilitate',\n",
      "  'cover',\n",
      "  'seconds',\n",
      "  'educate',\n",
      "  'misses',\n",
      "  'do',\n",
      "  'unlearn',\n",
      "  'substituting',\n",
      "  'friends',\n",
      "  'doctor',\n",
      "  'guided',\n",
      "  'commute',\n",
      "  'assimilate',\n",
      "  'simplify',\n",
      "  'introduced',\n",
      "  'avail',\n",
      "  'subbing',\n",
      "  'solo',\n",
      "  'mate',\n",
      "  'care',\n",
      "  'lose',\n",
      "  'dig',\n",
      "  'friend',\n",
      "  'illuminate',\n",
      "  'vetter',\n",
      "  'shopping',\n",
      "  'cultivate',\n",
      "  'force',\n",
      "  'covers',\n",
      "  'convey',\n",
      "  'paraphrase',\n",
      "  'relaxing',\n",
      "  'fixate',\n",
      "  'applying',\n",
      "  'assigned',\n",
      "  'untaught',\n",
      "  'skill',\n",
      "  'elsewhere',\n",
      "  'lear',\n",
      "  'spell',\n",
      "  'shepherd',\n",
      "  'assign',\n",
      "  'doctored',\n",
      "  'master',\n",
      "  'experimenting',\n",
      "  'amuse',\n",
      "  'cipher',\n",
      "  'enrich',\n",
      "  'traduce',\n",
      "  'read',\n",
      "  'talk',\n",
      "  'understudied',\n",
      "  'sub',\n",
      "  'scotch',\n",
      "  'tending',\n",
      "  'monitor',\n",
      "  'alter',\n",
      "  'asd',\n",
      "  'sophisticate',\n",
      "  'upgraded',\n",
      "  'kid',\n",
      "  'project',\n",
      "  'cans',\n",
      "  'soothe',\n",
      "  'rest',\n",
      "  'demote',\n",
      "  'intellectual'],\n",
      " tensor([33880,  7857, 10643, 17094, 30761, 42699, 44195, 25025,  5742, 20426,\n",
      "         3500,  5179, 16486, 15203, 35766, 19297, 20819, 19574, 15125, 26775,\n",
      "        37548, 17639,  7490, 38546, 23541,  9353,  6867, 17213,  5231, 38040,\n",
      "        17117,  3653, 17877, 13531, 29635,  2968, 38938,  8176, 25183, 26219,\n",
      "         8373, 16369, 30313, 18985, 33552, 32913,  1769,  9136, 39776, 27885,\n",
      "        37237,  9595, 31874, 28427, 31675, 29828, 26637, 38060, 16284,   644,\n",
      "        19367, 43230, 36138, 11897, 23507, 21262,  6994, 20712, 44241, 11419,\n",
      "        14938, 13140, 36846, 34398, 15111, 34487, 40203,  4035, 35900, 15909,\n",
      "        37693, 35521, 11669,  3037, 29319, 23345, 20177, 38262, 10077, 36297,\n",
      "        44542, 31541, 27411, 14277, 11416, 41295, 42318, 15678,  1768, 33895],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for when someone you trust does something that breaks your trust\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['bribing',\n",
      "  'traitor',\n",
      "  'betray',\n",
      "  'credits',\n",
      "  'surety',\n",
      "  'confide',\n",
      "  'hedge',\n",
      "  'perfidy',\n",
      "  'trust',\n",
      "  'trusty',\n",
      "  'cheated',\n",
      "  'entrust',\n",
      "  'judas',\n",
      "  'credited',\n",
      "  'treason',\n",
      "  'cheat',\n",
      "  'embezzling',\n",
      "  'fiduciary',\n",
      "  'confidant',\n",
      "  'venturing',\n",
      "  'frailty',\n",
      "  'compromising',\n",
      "  'bet',\n",
      "  'bribe',\n",
      "  'depositing',\n",
      "  'misplaced',\n",
      "  'trusting',\n",
      "  'subscribe',\n",
      "  'mistrust',\n",
      "  'compromise',\n",
      "  'confusion',\n",
      "  'jinx',\n",
      "  'fraud',\n",
      "  'treachery',\n",
      "  'unfaithful',\n",
      "  'pawning',\n",
      "  'credit',\n",
      "  'confessor',\n",
      "  'mislead',\n",
      "  'selling',\n",
      "  'friend',\n",
      "  'mate',\n",
      "  'confidence',\n",
      "  'infidelity',\n",
      "  'confidential',\n",
      "  'pawn',\n",
      "  'lose',\n",
      "  'guard',\n",
      "  'suicide',\n",
      "  'depositional',\n",
      "  'distrust',\n",
      "  'fear',\n",
      "  'reliance',\n",
      "  'accredit',\n",
      "  'biter',\n",
      "  'hazardous',\n",
      "  'venture',\n",
      "  'flaw',\n",
      "  'responsible',\n",
      "  'jilt',\n",
      "  'fob',\n",
      "  'betrayer',\n",
      "  'credibility',\n",
      "  'pledge',\n",
      "  'trespassing',\n",
      "  'bets',\n",
      "  'margin',\n",
      "  'fooling',\n",
      "  'betting',\n",
      "  'stakeholder',\n",
      "  'treacherous',\n",
      "  'informant',\n",
      "  'hedger',\n",
      "  'heartbreaker',\n",
      "  'comforter',\n",
      "  'friends',\n",
      "  'security',\n",
      "  'sell',\n",
      "  'acquaintance',\n",
      "  'check',\n",
      "  'confident',\n",
      "  'bailor',\n",
      "  'pledging',\n",
      "  'commissioning',\n",
      "  'spell',\n",
      "  'breaching',\n",
      "  'imposition',\n",
      "  'scapegoat',\n",
      "  'pledged',\n",
      "  'cover',\n",
      "  'collusion',\n",
      "  'endanger',\n",
      "  'jobber',\n",
      "  'conditions',\n",
      "  'stranger',\n",
      "  'falls',\n",
      "  'fibber',\n",
      "  'shelter',\n",
      "  'borrow',\n",
      "  'convert'],\n",
      " tensor([38603, 31755, 17674, 28446,  8063,  8244, 14940, 41753, 20311,  2512,\n",
      "        34030, 33762, 30372,  2909,  5002, 13001,  3232, 20516, 31821,  1374,\n",
      "        27262, 43112, 12423, 28370, 26179, 18829,  5133,  2150, 11633, 30919,\n",
      "        44430, 17629,  4721, 35634, 38641, 44747, 42735, 21558, 18708, 20440,\n",
      "        29828,  9595, 26847,  3262, 36153, 36288, 28427, 28935, 31876, 35966,\n",
      "        38624,  1884, 33890, 29252, 15436, 25405, 36813, 17784,  3169, 27743,\n",
      "        43686, 23663,  4299, 41945, 20205, 11641,  6399, 14092, 22670, 15352,\n",
      "         3091, 12180, 37318, 39575,  6996, 16369, 44038, 27317, 19449, 22818,\n",
      "        43184, 23509, 18409, 19784, 36846, 10837, 25430, 32594, 42774, 29635,\n",
      "         2945, 12535, 34130, 34308, 25676, 30381, 16543, 12671, 24852,  2713],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for deep learning\n",
      "(['profundity',\n",
      "  'study',\n",
      "  'recondite',\n",
      "  'profoundness',\n",
      "  'profound',\n",
      "  'studied',\n",
      "  'ingrain',\n",
      "  'deep',\n",
      "  'conversant',\n",
      "  'learning',\n",
      "  'deepness',\n",
      "  'profoundly',\n",
      "  'knowledgeable',\n",
      "  'open',\n",
      "  'highbrow',\n",
      "  'depth',\n",
      "  'gifted',\n",
      "  'keen',\n",
      "  'immerse',\n",
      "  'learn',\n",
      "  'searching',\n",
      "  'cram',\n",
      "  'catch',\n",
      "  'grasp',\n",
      "  'hard',\n",
      "  'curious',\n",
      "  'core',\n",
      "  'student',\n",
      "  'cet',\n",
      "  'apprehension',\n",
      "  'strep',\n",
      "  'lear',\n",
      "  'instruction',\n",
      "  'gutted',\n",
      "  'harmony',\n",
      "  'tract',\n",
      "  'penetrate',\n",
      "  'pith',\n",
      "  'meditation',\n",
      "  'education',\n",
      "  'acquisitive',\n",
      "  'diligent',\n",
      "  'dilatation',\n",
      "  'academy',\n",
      "  'pick',\n",
      "  'explore',\n",
      "  'gash',\n",
      "  'evangelical',\n",
      "  'elaborate',\n",
      "  'knowing',\n",
      "  'crack',\n",
      "  'grounding',\n",
      "  'sonorous',\n",
      "  'dense',\n",
      "  'afghanistan',\n",
      "  'enter',\n",
      "  'unlocking',\n",
      "  'awareness',\n",
      "  'culture',\n",
      "  'intelligence',\n",
      "  'catholicism',\n",
      "  'examination',\n",
      "  'adept',\n",
      "  'exhaustively',\n",
      "  'breakthrough',\n",
      "  'tich',\n",
      "  'astute',\n",
      "  'tested',\n",
      "  'lesson',\n",
      "  'penetration',\n",
      "  'inward',\n",
      "  'explication',\n",
      "  'dig',\n",
      "  'ingenuity',\n",
      "  'tracks',\n",
      "  'gaping',\n",
      "  'know',\n",
      "  'curriculum',\n",
      "  'mainstream',\n",
      "  'invention',\n",
      "  'babble',\n",
      "  'ingrained',\n",
      "  'rout',\n",
      "  'absorb',\n",
      "  'knotty',\n",
      "  'interrogatory',\n",
      "  'discover',\n",
      "  'test',\n",
      "  'dive',\n",
      "  'elaborated',\n",
      "  'race',\n",
      "  'sound',\n",
      "  'receptivity',\n",
      "  'seminary',\n",
      "  'indigo',\n",
      "  'fissure',\n",
      "  'blase',\n",
      "  'fathom',\n",
      "  'spy',\n",
      "  'innate'],\n",
      " tensor([13896,  3500,  9848, 15622, 17267, 30520,  2956, 16815, 40952, 29078,\n",
      "        23523, 15505, 21099, 38284, 29362, 14528, 40505, 21679, 22751, 33880,\n",
      "        10658, 11049, 34057,  7734,  9256, 35978, 37852, 19574, 32682, 15391,\n",
      "          527, 13140, 30971,  2462, 14523, 43711,  3686, 16906, 24988, 36247,\n",
      "        37434, 17870, 29646, 25031, 23466, 44008, 19555, 44073, 42332, 21410,\n",
      "         8092, 36611,  6052, 10134, 29820, 26964,  9628, 16528, 24577, 18976,\n",
      "         7488, 41461, 38577, 15855, 14892, 16841, 14074, 27122,  2181, 19092,\n",
      "        19143, 36495, 31675, 43140,   261, 17410,  5506, 20995,  4598,   563,\n",
      "         2793, 39862, 18008,  2773,  4368, 38906,  9353, 10502, 18352, 28822,\n",
      "         1162,   486, 10135,  7595,  3219, 41392, 42287, 42051, 21533, 41502],\n",
      "       device='cuda:0'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for q in queries:\n",
    "    print(f'Results for {q}')\n",
    "    pprint(getPredFromDesc(model, q, 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a type of tree\n",
      "(['tree',\n",
      "  'treed',\n",
      "  'nox',\n",
      "  'canes',\n",
      "  'pine',\n",
      "  'fir',\n",
      "  'maple',\n",
      "  'arboreal',\n",
      "  'ironwood',\n",
      "  'mahogany',\n",
      "  'hardwood',\n",
      "  'spruce',\n",
      "  'apple',\n",
      "  'oak',\n",
      "  'hickory',\n",
      "  'forest',\n",
      "  'cedar',\n",
      "  'larch',\n",
      "  'grove',\n",
      "  'log',\n",
      "  'eucalyptus',\n",
      "  'sandalwood',\n",
      "  'plu',\n",
      "  'bamboo',\n",
      "  'redwood',\n",
      "  'cypress',\n",
      "  'birch',\n",
      "  'stocks',\n",
      "  'sycamore',\n",
      "  'bush',\n",
      "  'locust',\n",
      "  'stocked',\n",
      "  'knotting',\n",
      "  'limes',\n",
      "  'barking',\n",
      "  'toon',\n",
      "  'evergreen',\n",
      "  'stick',\n",
      "  'acacia',\n",
      "  'chestnut',\n",
      "  'basil',\n",
      "  'knot',\n",
      "  'nutmeg',\n",
      "  'mallee',\n",
      "  'cottonwood',\n",
      "  'liming',\n",
      "  'lime',\n",
      "  'clove',\n",
      "  'hemlock',\n",
      "  'mulberry',\n",
      "  'leatherwood',\n",
      "  'hazel',\n",
      "  'box',\n",
      "  'mangrove',\n",
      "  'timbered',\n",
      "  'lumber',\n",
      "  'dock',\n",
      "  'baying',\n",
      "  'leaf',\n",
      "  'sylvan',\n",
      "  'crip',\n",
      "  'linden',\n",
      "  'pollard',\n",
      "  'butternut',\n",
      "  'dogwood',\n",
      "  'brushwood',\n",
      "  'papaw',\n",
      "  'standard',\n",
      "  'fig',\n",
      "  'bau',\n",
      "  'ebony',\n",
      "  'sticks',\n",
      "  'forester',\n",
      "  'reed',\n",
      "  'shrub',\n",
      "  'straw',\n",
      "  'foliate',\n",
      "  'grass',\n",
      "  'softwood',\n",
      "  'plum',\n",
      "  'trunks',\n",
      "  'poplar',\n",
      "  'stumping',\n",
      "  'logwood',\n",
      "  'tard',\n",
      "  'inflorescence',\n",
      "  'bushwhack',\n",
      "  'juniper',\n",
      "  'rattan',\n",
      "  'sage',\n",
      "  'gimp',\n",
      "  'rosewood',\n",
      "  'twig',\n",
      "  'gooseberry',\n",
      "  'sorb',\n",
      "  'satinwood',\n",
      "  'nog',\n",
      "  'hornbeam',\n",
      "  'vibe',\n",
      "  'ssh'],\n",
      " tensor([19190,  6880,  8251, 23231, 40429,  1662,  4171,  2228,  4146, 36541,\n",
      "        23065, 30887, 21889, 21233, 39430, 29880, 38054, 44367,  6258, 42145,\n",
      "        25893, 35214, 39206,  3293, 11847, 11498, 20870, 18537, 15302, 29632,\n",
      "        21164,  2918, 27883, 12889, 30198,  7118, 14757, 43245, 29230, 35239,\n",
      "         8322, 11997, 16892, 12696,  6686, 23317,  1751,  3083, 21499, 42372,\n",
      "        25615, 33988, 41807, 34668, 31568, 39458, 31817, 40501, 39741, 36353,\n",
      "         2123, 11683, 36534, 44158, 41880,  2813,  5297, 33316, 43825, 21862,\n",
      "        35378, 17917, 33961, 44800, 43236, 38120, 33063, 35043,  8544, 12925,\n",
      "        27436,  6516,   646, 44267, 22550, 42184, 18219, 34092,  8481, 12819,\n",
      "        29463, 22808, 16656,  9607,  3559, 10638, 23486, 41227, 37393, 16506],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for the opposite of being happy\n",
      "(['happiness',\n",
      "  'languor',\n",
      "  'unhappy',\n",
      "  'negligence',\n",
      "  'dislike',\n",
      "  'emptiness',\n",
      "  'bashfulness',\n",
      "  'diffidence',\n",
      "  'blithe',\n",
      "  'complacence',\n",
      "  'melancholic',\n",
      "  'suavity',\n",
      "  'pitiable',\n",
      "  'meanness',\n",
      "  'nihilism',\n",
      "  'felicitate',\n",
      "  'discontent',\n",
      "  'impotence',\n",
      "  'innocence',\n",
      "  'felicity',\n",
      "  'vanity',\n",
      "  'absurd',\n",
      "  'irrationality',\n",
      "  'arrogance',\n",
      "  'ignorance',\n",
      "  'egoism',\n",
      "  'misery',\n",
      "  'sadness',\n",
      "  'indisposition',\n",
      "  'unkindly',\n",
      "  'nothingness',\n",
      "  'magnanimity',\n",
      "  'penury',\n",
      "  'disinterest',\n",
      "  'neglect',\n",
      "  'sterility',\n",
      "  'modesty',\n",
      "  'antipathy',\n",
      "  'egotism',\n",
      "  'inertness',\n",
      "  'joviality',\n",
      "  'sobriety',\n",
      "  'joy',\n",
      "  'inanition',\n",
      "  'unreality',\n",
      "  'atheism',\n",
      "  'mischief',\n",
      "  'unconformity',\n",
      "  'inefficacy',\n",
      "  'solitude',\n",
      "  'inconvenience',\n",
      "  'rejoice',\n",
      "  'impertinence',\n",
      "  'commiserate',\n",
      "  'indolence',\n",
      "  'unlucky',\n",
      "  'vacation',\n",
      "  'inattention',\n",
      "  'irreverence',\n",
      "  'regrets',\n",
      "  'nostalgia',\n",
      "  'inadvertence',\n",
      "  'disquiet',\n",
      "  'admiration',\n",
      "  'hopeless',\n",
      "  'misfortune',\n",
      "  'subjectivism',\n",
      "  'loneliness',\n",
      "  'disregarding',\n",
      "  'leniency',\n",
      "  'impropriety',\n",
      "  'philanthropy',\n",
      "  'avarice',\n",
      "  'effrontery',\n",
      "  'loving',\n",
      "  'lugubrious',\n",
      "  'disconsolate',\n",
      "  'demerit',\n",
      "  'lethargy',\n",
      "  'shameless',\n",
      "  'impudence',\n",
      "  'sophistication',\n",
      "  'misgovernment',\n",
      "  'annoyance',\n",
      "  'avidity',\n",
      "  'contempt',\n",
      "  'antisocial',\n",
      "  'indulgence',\n",
      "  'displeasure',\n",
      "  'amuse',\n",
      "  'delight',\n",
      "  'fatness',\n",
      "  'poignancy',\n",
      "  'inability',\n",
      "  'distressed',\n",
      "  'envy',\n",
      "  'immorality',\n",
      "  'distaste',\n",
      "  'hilarity',\n",
      "  'ungrateful'],\n",
      " tensor([29088, 10519, 11144, 14458, 36333, 25108,  1840,  8624,  2541,  2418,\n",
      "        13000,  6791, 33405,  2270, 36922, 23682,  3505, 36663, 14350, 24733,\n",
      "         9345, 30906, 38744,  5749, 17583, 38568, 40591,   128, 41362, 28585,\n",
      "        34022, 22506, 36094, 32590, 20009, 17806, 37310, 20883, 11322, 30120,\n",
      "        26728, 32536, 25831,  8807, 10185, 20765, 25364, 24488, 32250, 13184,\n",
      "         5069, 23718, 18487,   776, 38567,  5411, 13063, 15176, 35138,  2716,\n",
      "        20131, 41396, 15052, 23635,  2026, 35444, 22913, 42715, 34889, 39482,\n",
      "        21642, 14609, 38676, 10507, 27709, 25192, 33076, 16385, 38978, 28836,\n",
      "        38605, 26306, 27062,  6637, 33815, 43934, 41779, 10598, 28292, 35900,\n",
      "        28112, 14573,  3613, 41736, 28809, 38816,  7500,  7136,  8224, 25205],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for employee at a circus\n",
      "(['clown',\n",
      "  'butcher',\n",
      "  'mie',\n",
      "  'circus',\n",
      "  'ringer',\n",
      "  'jobber',\n",
      "  'ham',\n",
      "  'ranger',\n",
      "  'ape',\n",
      "  'buffoon',\n",
      "  'fooling',\n",
      "  'comedian',\n",
      "  'picket',\n",
      "  'butchers',\n",
      "  'jock',\n",
      "  'masquerading',\n",
      "  'player',\n",
      "  'knackered',\n",
      "  'mastering',\n",
      "  'merchant',\n",
      "  'monger',\n",
      "  'stag',\n",
      "  'beast',\n",
      "  'studded',\n",
      "  'stunting',\n",
      "  'buffalo',\n",
      "  'jester',\n",
      "  'fool',\n",
      "  'pantomime',\n",
      "  'carnival',\n",
      "  'thespian',\n",
      "  'knight',\n",
      "  'dof',\n",
      "  'actor',\n",
      "  'craftsman',\n",
      "  'sport',\n",
      "  'mummer',\n",
      "  'jockey',\n",
      "  'bullock',\n",
      "  'mountebank',\n",
      "  'outlaw',\n",
      "  'mime',\n",
      "  'juggler',\n",
      "  'antic',\n",
      "  'haberdasher',\n",
      "  'gaffer',\n",
      "  'knave',\n",
      "  'artist',\n",
      "  'huntsman',\n",
      "  'hunter',\n",
      "  'kid',\n",
      "  'trooper',\n",
      "  'hackneyed',\n",
      "  'domino',\n",
      "  'flaunt',\n",
      "  'tinker',\n",
      "  'fagot',\n",
      "  'joker',\n",
      "  'amateur',\n",
      "  'goat',\n",
      "  'dog',\n",
      "  'cad',\n",
      "  'gladiator',\n",
      "  'marx',\n",
      "  'strongman',\n",
      "  'minstrel',\n",
      "  'usher',\n",
      "  'knacker',\n",
      "  'farmer',\n",
      "  'stall',\n",
      "  'company',\n",
      "  'guys',\n",
      "  'pavillion',\n",
      "  'vamp',\n",
      "  'skinner',\n",
      "  'fop',\n",
      "  'knighting',\n",
      "  'scout',\n",
      "  'garrison',\n",
      "  'barrack',\n",
      "  'publican',\n",
      "  'tenanted',\n",
      "  'horseman',\n",
      "  'cat',\n",
      "  'demonstrator',\n",
      "  'prostitute',\n",
      "  'tailor',\n",
      "  'calf',\n",
      "  'provost',\n",
      "  'crew',\n",
      "  'tyrant',\n",
      "  'master',\n",
      "  'hams',\n",
      "  'adventurer',\n",
      "  'seller',\n",
      "  'gammon',\n",
      "  'sullivan',\n",
      "  'shop',\n",
      "  'hatter',\n",
      "  'barbecue'],\n",
      " tensor([40171, 31220, 32244, 27089, 33889, 34130, 16507, 36963, 15401, 41028,\n",
      "        14092, 27139, 42497, 22470, 29218, 10068,   697,  9836, 28376, 11331,\n",
      "        23194,  1760, 35026, 30601, 18212, 12620, 22710, 17206,  6147, 30616,\n",
      "         4453, 11496, 18738, 34683, 43367, 11265, 30006, 17115, 20295,  7183,\n",
      "        38414,  5150, 24756, 10204, 12308,  9310, 27741, 20681, 21903,  5961,\n",
      "        14277, 35364,   634, 17761, 29347, 25734,  6330, 38872, 17103, 33493,\n",
      "         4018, 22897, 24390, 22000,  6209,  7903, 26968, 27365, 26258, 41516,\n",
      "        27510, 39702, 10788, 41548,  2885, 16654, 35983, 23530, 27798, 22359,\n",
      "        27683, 37226, 31271, 37754, 15654, 28349, 44200, 11211,  5136, 16887,\n",
      "        27503, 40203, 19098, 42277,  5656, 38856,  9484, 15203, 20744, 35163],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a road on which cars can go quickly without stopping\n",
      "(['rush',\n",
      "  'drive',\n",
      "  'rushing',\n",
      "  'rushes',\n",
      "  'flight',\n",
      "  'race',\n",
      "  'hacking',\n",
      "  'hurry',\n",
      "  'riad',\n",
      "  'hack',\n",
      "  'railroad',\n",
      "  'blitzed',\n",
      "  'flash',\n",
      "  'slipping',\n",
      "  'trail',\n",
      "  'drag',\n",
      "  'bolt',\n",
      "  'route',\n",
      "  'precipitated',\n",
      "  'track',\n",
      "  'lanes',\n",
      "  'precipitating',\n",
      "  'dart',\n",
      "  'street',\n",
      "  'tracks',\n",
      "  'shoot',\n",
      "  'tracked',\n",
      "  'scrambled',\n",
      "  'runway',\n",
      "  'slugging',\n",
      "  'fleet',\n",
      "  'pad',\n",
      "  'clip',\n",
      "  'car',\n",
      "  'shot',\n",
      "  'fast',\n",
      "  'avenue',\n",
      "  'chase',\n",
      "  'snap',\n",
      "  'steals',\n",
      "  'blitz',\n",
      "  'quick',\n",
      "  'slug',\n",
      "  'poke',\n",
      "  'swift',\n",
      "  'shorts',\n",
      "  'scuttling',\n",
      "  'gating',\n",
      "  'trapped',\n",
      "  'zip',\n",
      "  'slash',\n",
      "  'flush',\n",
      "  'dispatching',\n",
      "  'slashing',\n",
      "  'darts',\n",
      "  'psd',\n",
      "  'lurch',\n",
      "  'flushed',\n",
      "  'shuttling',\n",
      "  'gallop',\n",
      "  'slip',\n",
      "  'jostle',\n",
      "  'gate',\n",
      "  'kicks',\n",
      "  'trip',\n",
      "  'snatching',\n",
      "  'nip',\n",
      "  'spurt',\n",
      "  'shuffle',\n",
      "  'bus',\n",
      "  'dash',\n",
      "  'path',\n",
      "  'trips',\n",
      "  'dashed',\n",
      "  'shuffled',\n",
      "  'scudding',\n",
      "  'flies',\n",
      "  'clearance',\n",
      "  'push',\n",
      "  'hitching',\n",
      "  'passed',\n",
      "  'haste',\n",
      "  'ditch',\n",
      "  'trailer',\n",
      "  'fugitive',\n",
      "  'ripped',\n",
      "  'scoot',\n",
      "  'joh',\n",
      "  'trotting',\n",
      "  'darting',\n",
      "  'poach',\n",
      "  'precipitate',\n",
      "  'jump',\n",
      "  'hastening',\n",
      "  'trot',\n",
      "  'trap',\n",
      "  'bomb',\n",
      "  'scud',\n",
      "  'overshoot',\n",
      "  'flying'],\n",
      " tensor([24395, 34151, 22518,   795, 41677,  1162, 25707, 37618,  3873,  5168,\n",
      "        25796, 34268, 39649, 20462, 32637, 22501, 25004, 15165, 40887, 34101,\n",
      "        38393, 11748, 30092, 12457,   261,  4345, 31980, 16438, 28832, 16359,\n",
      "         8168, 17148, 29298, 37609, 13900,  4241, 20113, 19823, 20026, 32053,\n",
      "        35032, 16414, 13958, 15090, 32961, 29850, 24926,  9379, 10465, 38056,\n",
      "        17942, 12890, 19760, 35765, 37349, 43132,  3244,  2335, 12901,  4855,\n",
      "        14689,  7831,  1040, 22318, 33203,  5682,  1791,  7733, 14050,   619,\n",
      "        11887, 13145,  5065, 40580, 28587, 13620, 26251, 27666, 38324, 37608,\n",
      "        32656, 20797, 37140, 38611, 39341, 36667, 18654, 37312, 19737,  8272,\n",
      "        12496, 41076, 33402, 29513, 10781, 25155, 43277, 43104, 34267,  4955],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a very intelligent person\n",
      "(['brains',\n",
      "  'brain',\n",
      "  'genius',\n",
      "  'intellectual',\n",
      "  'intelligent',\n",
      "  'mandarin',\n",
      "  'wit',\n",
      "  'master',\n",
      "  'monitor',\n",
      "  'mastering',\n",
      "  'brilliant',\n",
      "  'intellect',\n",
      "  'giant',\n",
      "  'pan',\n",
      "  'superman',\n",
      "  'virtuoso',\n",
      "  'intelligence',\n",
      "  'ace',\n",
      "  'expert',\n",
      "  'mouse',\n",
      "  'literate',\n",
      "  'perception',\n",
      "  'knowledgeable',\n",
      "  'knowing',\n",
      "  'elf',\n",
      "  'mind',\n",
      "  'bird',\n",
      "  'iphone',\n",
      "  'bombing',\n",
      "  'engine',\n",
      "  'stat',\n",
      "  'gnostic',\n",
      "  'lisp',\n",
      "  'spying',\n",
      "  'ear',\n",
      "  'mindfulness',\n",
      "  'adept',\n",
      "  'smart',\n",
      "  'tiger',\n",
      "  'scholar',\n",
      "  'smarting',\n",
      "  'dragon',\n",
      "  'brainpower',\n",
      "  'ingenious',\n",
      "  'sights',\n",
      "  'blimp',\n",
      "  'ticked',\n",
      "  'computer',\n",
      "  'bat',\n",
      "  'savvy',\n",
      "  'cd',\n",
      "  'bomb',\n",
      "  'machine',\n",
      "  'spectacle',\n",
      "  'savy',\n",
      "  'sirius',\n",
      "  'sensibility',\n",
      "  'understanding',\n",
      "  'divined',\n",
      "  'monitoring',\n",
      "  'cans',\n",
      "  'fisting',\n",
      "  'bug',\n",
      "  'recorder',\n",
      "  'crafting',\n",
      "  'visionary',\n",
      "  'keys',\n",
      "  'siren',\n",
      "  'mistress',\n",
      "  'proficient',\n",
      "  'bright',\n",
      "  'ape',\n",
      "  'imperial',\n",
      "  'nous',\n",
      "  'spe',\n",
      "  'trojan',\n",
      "  'observer',\n",
      "  'patrician',\n",
      "  'curie',\n",
      "  'psyche',\n",
      "  'android',\n",
      "  'shrew',\n",
      "  'eyeglass',\n",
      "  'prophet',\n",
      "  'booster',\n",
      "  'skill',\n",
      "  'sensed',\n",
      "  'smarts',\n",
      "  'speaker',\n",
      "  'clever',\n",
      "  'perspicacity',\n",
      "  'knocker',\n",
      "  'ticker',\n",
      "  'tich',\n",
      "  'nob',\n",
      "  'informant',\n",
      "  'blue',\n",
      "  'power',\n",
      "  'cleverness',\n",
      "  'dof'],\n",
      " tensor([25579, 38338, 27923, 33895, 12896,  1371, 24897, 40203, 10077, 28376,\n",
      "         9645, 22791, 29538, 14116, 27379, 37772, 18976, 13970, 38183, 12800,\n",
      "        34372, 28690, 21099, 21410, 22744, 30287, 41104, 18451, 35474, 31827,\n",
      "        37802, 44251, 35837, 29236,   596,  5316, 38577, 31720, 25401,  1930,\n",
      "         5311, 28757, 24301, 27231, 13208,    79, 35118, 15344,  9439,  8489,\n",
      "        19913, 43277,  5527, 22083, 23928, 31360,  8443, 42157,  1218,  6213,\n",
      "        41295,  4450, 44918,  9231, 25976, 26837, 42756, 25441,  9629, 26913,\n",
      "        15624, 15401, 42156, 36290, 15281,  7418,   123, 14437, 17321, 21877,\n",
      "        23945,  3237, 14789, 22396, 35880, 11419, 37231, 33125, 29269, 22441,\n",
      "           99, 13162, 11576, 16841, 17229, 12180, 27185, 13714, 19335, 18738],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a very smart person\n",
      "(['smarting',\n",
      "  'smarts',\n",
      "  'smart',\n",
      "  'brains',\n",
      "  'brain',\n",
      "  'genius',\n",
      "  'ace',\n",
      "  'intelligent',\n",
      "  'wit',\n",
      "  'dof',\n",
      "  'clever',\n",
      "  'virtuoso',\n",
      "  'dog',\n",
      "  'blimp',\n",
      "  'cracker',\n",
      "  'master',\n",
      "  'brilliant',\n",
      "  'mastering',\n",
      "  'intellectual',\n",
      "  'bat',\n",
      "  'giant',\n",
      "  'bomb',\n",
      "  'fan',\n",
      "  'mandarin',\n",
      "  'ironed',\n",
      "  'bombing',\n",
      "  'quickness',\n",
      "  'keen',\n",
      "  'tiger',\n",
      "  'fisting',\n",
      "  'blast',\n",
      "  'expert',\n",
      "  'hot',\n",
      "  'thoroughbred',\n",
      "  'engine',\n",
      "  'ingenious',\n",
      "  'sharp',\n",
      "  'punching',\n",
      "  'blower',\n",
      "  'bombe',\n",
      "  'stinger',\n",
      "  'honed',\n",
      "  'pungent',\n",
      "  'patrician',\n",
      "  'nob',\n",
      "  'hammers',\n",
      "  'ticked',\n",
      "  'poignant',\n",
      "  'masterly',\n",
      "  'masterful',\n",
      "  'hammered',\n",
      "  'torpedoing',\n",
      "  'adroit',\n",
      "  'tich',\n",
      "  'dogs',\n",
      "  'hack',\n",
      "  'adept',\n",
      "  'sparking',\n",
      "  'powerful',\n",
      "  'sleight',\n",
      "  'knowledgeable',\n",
      "  'iron',\n",
      "  'hotshot',\n",
      "  'brave',\n",
      "  'booster',\n",
      "  'crafting',\n",
      "  'punch',\n",
      "  'hammer',\n",
      "  'salt',\n",
      "  'proficient',\n",
      "  'jockey',\n",
      "  'crafted',\n",
      "  'jacks',\n",
      "  'sax',\n",
      "  'poo',\n",
      "  'blade',\n",
      "  'gun',\n",
      "  'strong',\n",
      "  'heady',\n",
      "  'pop',\n",
      "  'nyt',\n",
      "  'mouse',\n",
      "  'knack',\n",
      "  'grinder',\n",
      "  'knocker',\n",
      "  'smashing',\n",
      "  'doped',\n",
      "  'epicurean',\n",
      "  'knowing',\n",
      "  'hammering',\n",
      "  'shrew',\n",
      "  'ecstatic',\n",
      "  'torpedo',\n",
      "  'rich',\n",
      "  'hit',\n",
      "  'monitor',\n",
      "  'bright',\n",
      "  'spikes',\n",
      "  'kab',\n",
      "  'acute'],\n",
      " tensor([ 5311, 33125, 31720, 25579, 38338, 27923, 13970, 12896, 24897, 18738,\n",
      "        22441, 37772,  4018,    79, 35759, 40203,  9645, 28376, 33895,  9439,\n",
      "        29538, 43277, 28874,  1371, 37492, 35474, 28057, 21679, 25401,  4450,\n",
      "        39638, 38183,  9961,  4220, 31827, 27231, 22269, 26763, 11628, 15996,\n",
      "         1706, 44621, 33551, 14437, 17229, 34428, 35118,  9856, 30908,  8864,\n",
      "        31412,  6087, 28818, 16841, 19605,  5168, 38577, 43732, 31891, 31043,\n",
      "        21099, 15248, 25770, 14170, 35880, 25976, 30250, 31514, 14222, 26913,\n",
      "        17115,  2646, 16626, 39409, 30444, 40460, 28016, 19269,  5189, 23450,\n",
      "        39933, 12800, 41570, 27589, 13162, 11730, 29760, 13617, 21410, 43131,\n",
      "         3237, 23752, 15093, 17253, 35977, 10077, 15624,  2822, 22472,  7473],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for something you use to measure your temperature\n",
      "(['calorimeter',\n",
      "  'thermometer',\n",
      "  'heat',\n",
      "  'refrigerant',\n",
      "  'cooler',\n",
      "  'het',\n",
      "  'fahrenheit',\n",
      "  'metering',\n",
      "  'pyrometer',\n",
      "  'stove',\n",
      "  'baths',\n",
      "  'meter',\n",
      "  'gasometer',\n",
      "  'celsius',\n",
      "  'thermometry',\n",
      "  'thermostat',\n",
      "  'temperance',\n",
      "  'mileage',\n",
      "  'superheating',\n",
      "  'thermal',\n",
      "  'gauge',\n",
      "  'barometer',\n",
      "  'radiator',\n",
      "  'chronograph',\n",
      "  'pacemaker',\n",
      "  'isotherm',\n",
      "  'digester',\n",
      "  'refrigeration',\n",
      "  'bath',\n",
      "  'thermopile',\n",
      "  'blowpipe',\n",
      "  'fan',\n",
      "  'climate',\n",
      "  'freezer',\n",
      "  'tonometer',\n",
      "  'dosimeter',\n",
      "  'manometer',\n",
      "  'ph',\n",
      "  'radiometer',\n",
      "  'steam',\n",
      "  'ergometer',\n",
      "  'efficiency',\n",
      "  'boiling',\n",
      "  'indicator',\n",
      "  'seismometer',\n",
      "  'cooked',\n",
      "  'cook',\n",
      "  'timepiece',\n",
      "  'stoker',\n",
      "  'heater',\n",
      "  'rheometer',\n",
      "  'heating',\n",
      "  'atmosphere',\n",
      "  'ventilation',\n",
      "  'densitometer',\n",
      "  'cold',\n",
      "  'ammeter',\n",
      "  'condenser',\n",
      "  'sweltering',\n",
      "  'scald',\n",
      "  'joule',\n",
      "  'sextant',\n",
      "  'monitor',\n",
      "  'sweat',\n",
      "  'autoclave',\n",
      "  'clock',\n",
      "  'measurement',\n",
      "  'endothermic',\n",
      "  'gage',\n",
      "  'centigrade',\n",
      "  'steamed',\n",
      "  'measurer',\n",
      "  'telemeter',\n",
      "  'fever',\n",
      "  'equalizer',\n",
      "  'calorific',\n",
      "  'potentiometer',\n",
      "  'accelerometer',\n",
      "  'regulator',\n",
      "  'steamer',\n",
      "  'frost',\n",
      "  'tested',\n",
      "  'glass',\n",
      "  'thermic',\n",
      "  'survey',\n",
      "  'benchmark',\n",
      "  'geyser',\n",
      "  'hydrothermal',\n",
      "  'register',\n",
      "  'breather',\n",
      "  'timekeeper',\n",
      "  'sifted',\n",
      "  'measured',\n",
      "  'arctic',\n",
      "  'resistance',\n",
      "  'thermistor',\n",
      "  'ice',\n",
      "  'test',\n",
      "  'dynamometer',\n",
      "  'graduation'],\n",
      " tensor([43736, 21694, 25497, 39099, 11401, 14356, 23558, 15495, 39573, 32534,\n",
      "          784, 33029, 43191, 13409,  2316, 27127, 23970, 22990,  4899, 37815,\n",
      "        36591, 21219, 12956, 31776, 35752, 35931, 17563, 15343, 29192, 16077,\n",
      "        41788, 28874,  2795,  8170, 26743,  2775, 22133,  9905, 35187, 37781,\n",
      "        12824, 42088,  4530, 34296, 16710, 28764, 40531, 30895, 20253,  8653,\n",
      "        12871, 33404, 17420, 26158, 17738, 13156,  8054, 29915, 13191, 24064,\n",
      "        41046, 12277, 10077, 10893, 10826, 44901,  8899, 12675, 14722, 43549,\n",
      "        29240, 39895, 15353, 12720,  2530, 44924, 26594,  1680, 40195, 13395,\n",
      "        16958, 27122, 39183, 11671, 25347, 30138, 15817, 32559, 36718, 44648,\n",
      "        20397, 19379, 21881, 16367, 24705, 12069,    24, 10502, 27493, 13797],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for a dark time of day\n",
      "(['night',\n",
      "  'darkling',\n",
      "  'fark',\n",
      "  'gloom',\n",
      "  'dusk',\n",
      "  'darken',\n",
      "  'dusky',\n",
      "  'midnight',\n",
      "  'twilight',\n",
      "  'nightly',\n",
      "  'shades',\n",
      "  'dim',\n",
      "  'evening',\n",
      "  'darkness',\n",
      "  'black',\n",
      "  'shade',\n",
      "  'shadow',\n",
      "  'shadowy',\n",
      "  'dimming',\n",
      "  'gloaming',\n",
      "  'shadowed',\n",
      "  'overnight',\n",
      "  'gloomy',\n",
      "  'darkly',\n",
      "  'day',\n",
      "  'dimmed',\n",
      "  'cloudy',\n",
      "  'shady',\n",
      "  'obscurity',\n",
      "  'overcast',\n",
      "  'blinds',\n",
      "  'opacity',\n",
      "  'eclipse',\n",
      "  'moonshine',\n",
      "  'dau',\n",
      "  'brown',\n",
      "  'fog',\n",
      "  'daylight',\n",
      "  'nighttime',\n",
      "  'blue',\n",
      "  'melancholic',\n",
      "  'blackout',\n",
      "  'grays',\n",
      "  'nocturne',\n",
      "  'mist',\n",
      "  'moony',\n",
      "  'melancholy',\n",
      "  'scowl',\n",
      "  'sombre',\n",
      "  'misty',\n",
      "  'noon',\n",
      "  'azure',\n",
      "  'curtains',\n",
      "  'blues',\n",
      "  'bivouac',\n",
      "  'nights',\n",
      "  'sightless',\n",
      "  'eve',\n",
      "  'dimness',\n",
      "  'opaque',\n",
      "  'deep',\n",
      "  'sunset',\n",
      "  'blurring',\n",
      "  'sunshade',\n",
      "  'blindness',\n",
      "  'rainbow',\n",
      "  'occult',\n",
      "  'recess',\n",
      "  'sooty',\n",
      "  'nebula',\n",
      "  'lower',\n",
      "  'ramadan',\n",
      "  'purblind',\n",
      "  'hour',\n",
      "  'secretively',\n",
      "  'fade',\n",
      "  'solstice',\n",
      "  'shabbat',\n",
      "  'obfuscate',\n",
      "  'tenebrous',\n",
      "  'beyond',\n",
      "  'dulled',\n",
      "  'heavy',\n",
      "  'purdah',\n",
      "  'sullen',\n",
      "  'bleak',\n",
      "  'haze',\n",
      "  'spy',\n",
      "  'pales',\n",
      "  'hue',\n",
      "  'scowling',\n",
      "  'outside',\n",
      "  'halloween',\n",
      "  'hazing',\n",
      "  'ghost',\n",
      "  'missed',\n",
      "  'moon',\n",
      "  'east',\n",
      "  'glimmer',\n",
      "  'squint'],\n",
      " tensor([30711, 17315, 38058, 36896, 23883, 42095, 18941,  5123, 18812, 23995,\n",
      "        31799, 41664, 32790, 10330, 34961, 31443, 37961,  9632, 38843,  2067,\n",
      "        44104, 29373, 19554, 21620, 32315, 23961, 16655, 25002, 16352, 12305,\n",
      "        17205,  8269, 35015, 32625, 32386,  3431, 15748, 11277, 39568, 27185,\n",
      "        13000,  4257, 34442, 21653, 43336,  3179, 36427,  1112,  4304, 29682,\n",
      "         7127,  4554, 14860, 37742, 25167, 19595, 18862, 18649, 36479, 39594,\n",
      "        16815,  2201, 31793, 43392, 22954, 16982, 23895, 19837, 41669, 11449,\n",
      "         6867, 11012, 10814, 28253, 37414,  3165, 33062, 34635, 24203,  1886,\n",
      "        32084, 32111,  2622, 36581,  6747,   249, 40598, 21533,  8382, 26227,\n",
      "        11906, 35201, 23705, 10676, 40870, 22775, 31928,  2500, 11293, 13507],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for medieval social hierarchy where peasants and vassals served lords\n",
      "(['aristocracy',\n",
      "  'family',\n",
      "  'estate',\n",
      "  'states',\n",
      "  'hierarchy',\n",
      "  'regiment',\n",
      "  'vassalage',\n",
      "  'commonwealth',\n",
      "  'commune',\n",
      "  'civilization',\n",
      "  'kingdom',\n",
      "  'regimented',\n",
      "  'state',\n",
      "  'communism',\n",
      "  'democracy',\n",
      "  'nation',\n",
      "  'establishment',\n",
      "  'peoples',\n",
      "  'familly',\n",
      "  'clan',\n",
      "  'order',\n",
      "  'vassal',\n",
      "  'barony',\n",
      "  'oligarchy',\n",
      "  'republic',\n",
      "  'peerage',\n",
      "  'tenure',\n",
      "  'clas',\n",
      "  'caste',\n",
      "  'bureaucracy',\n",
      "  'parish',\n",
      "  'government',\n",
      "  'domain',\n",
      "  'servitude',\n",
      "  'lord',\n",
      "  'consistory',\n",
      "  'society',\n",
      "  'civil',\n",
      "  'municipal',\n",
      "  'tyranny',\n",
      "  'colony',\n",
      "  'demesne',\n",
      "  'army',\n",
      "  'organization',\n",
      "  'country',\n",
      "  'division',\n",
      "  'national',\n",
      "  'people',\n",
      "  'culture',\n",
      "  'district',\n",
      "  'province',\n",
      "  'ranked',\n",
      "  'dynasty',\n",
      "  'town',\n",
      "  'protectorate',\n",
      "  'autocracy',\n",
      "  'institution',\n",
      "  'politics',\n",
      "  'sovereignty',\n",
      "  'court',\n",
      "  'theocracy',\n",
      "  'garrison',\n",
      "  'agrarian',\n",
      "  'gens',\n",
      "  'gentry',\n",
      "  'manor',\n",
      "  'princedom',\n",
      "  'borough',\n",
      "  'monarchy',\n",
      "  'lordship',\n",
      "  'suzerainty',\n",
      "  'chivalry',\n",
      "  'nobility',\n",
      "  'prefecture',\n",
      "  'patronage',\n",
      "  'prerogative',\n",
      "  'folk',\n",
      "  'presbytery',\n",
      "  'citizen',\n",
      "  'congregation',\n",
      "  'jurisdiction',\n",
      "  'ruled',\n",
      "  'household',\n",
      "  'phylum',\n",
      "  'royalty',\n",
      "  'gentility',\n",
      "  'house',\n",
      "  'fee',\n",
      "  'police',\n",
      "  'subordination',\n",
      "  'meritocracy',\n",
      "  'principality',\n",
      "  'administer',\n",
      "  'socialism',\n",
      "  'metropolis',\n",
      "  'heritage',\n",
      "  'feud',\n",
      "  'corporation',\n",
      "  'livery',\n",
      "  'city'],\n",
      " tensor([41717, 27443, 28912, 22693, 30647,  3202, 22063, 34000,  4431, 12649,\n",
      "        29070, 35838, 12182,  1003,  2356, 44360, 38518, 23645,  7422,  7779,\n",
      "        15160, 13253,  6389,  1054,  9281, 12372, 38826, 33280, 11967, 24858,\n",
      "        14811, 44981, 10350,  4777, 24469, 20915,   734,  7163, 15273, 17349,\n",
      "        27069, 31617,  3282, 25516, 21905, 22415,   699, 27123, 24577, 18692,\n",
      "         9400, 34716, 17503, 22613, 37178, 42017,  3415,   582, 21852, 29739,\n",
      "        40843, 27798, 24881, 10144, 42087, 37213, 43740, 17760, 23511,  8560,\n",
      "        37846, 25317, 22184,  5431, 13990, 20235, 44400, 10348,  5063, 38257,\n",
      "        36242, 14686, 41851,  1405, 23758, 12807,  7128, 43692, 23854, 15910,\n",
      "        18843, 21036, 21295,  6782, 28657, 27720, 18471, 37607, 38399, 44995],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for to help someone else learn\n",
      "(['help',\n",
      "  'aud',\n",
      "  'aid',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'aif',\n",
      "  'aided',\n",
      "  'learn',\n",
      "  'improve',\n",
      "  'afford',\n",
      "  'doctor',\n",
      "  'nourished',\n",
      "  'doctored',\n",
      "  'teach',\n",
      "  'avail',\n",
      "  'study',\n",
      "  'nourish',\n",
      "  'assisted',\n",
      "  'availing',\n",
      "  'recommend',\n",
      "  'doctoring',\n",
      "  'supporting',\n",
      "  'cover',\n",
      "  'benefit',\n",
      "  'covers',\n",
      "  'disciple',\n",
      "  'read',\n",
      "  'upgrade',\n",
      "  'save',\n",
      "  'saved',\n",
      "  'give',\n",
      "  'retrieve',\n",
      "  'achieve',\n",
      "  'nurture',\n",
      "  'support',\n",
      "  'profits',\n",
      "  'training',\n",
      "  'tutor',\n",
      "  'follow',\n",
      "  'second',\n",
      "  'skillfulness',\n",
      "  'cured',\n",
      "  'seconds',\n",
      "  'foster',\n",
      "  'lesson',\n",
      "  'vetter',\n",
      "  'salving',\n",
      "  'mend',\n",
      "  'master',\n",
      "  'minister',\n",
      "  'edified',\n",
      "  'recovered',\n",
      "  'overhauling',\n",
      "  'practicing',\n",
      "  'skill',\n",
      "  'do',\n",
      "  'redeem',\n",
      "  'exercise',\n",
      "  'heal',\n",
      "  'art',\n",
      "  'supported',\n",
      "  'exploited',\n",
      "  'recover',\n",
      "  'understand',\n",
      "  'instruct',\n",
      "  'discover',\n",
      "  'use',\n",
      "  'get',\n",
      "  'upgraded',\n",
      "  'selling',\n",
      "  'experimenting',\n",
      "  'provide',\n",
      "  'salve',\n",
      "  'cure',\n",
      "  'mending',\n",
      "  'con',\n",
      "  'hear',\n",
      "  'proving',\n",
      "  'mastering',\n",
      "  'assistance',\n",
      "  'school',\n",
      "  'promote',\n",
      "  'spell',\n",
      "  'seeking',\n",
      "  'expert',\n",
      "  'comforted',\n",
      "  'exercising',\n",
      "  'employ',\n",
      "  'better',\n",
      "  'providing',\n",
      "  'dispense',\n",
      "  'accompanying',\n",
      "  'deserve',\n",
      "  'redeemed',\n",
      "  'recollect',\n",
      "  'apprentice',\n",
      "  'tuition',\n",
      "  'salvage',\n",
      "  'render',\n",
      "  'upgrading',\n",
      "  'impart',\n",
      "  'scouting'],\n",
      " tensor([10643, 19707, 10007, 15332,  1202, 33880, 16486, 14142, 30313, 32306,\n",
      "        34487, 39873, 39776,  3500, 38320, 32144, 38748, 33262, 17576, 18938,\n",
      "        29635,  7282, 43230, 42699, 11669,   684, 40481, 18676, 30843, 38796,\n",
      "        25409,  9738, 42581, 38456, 12186, 20819, 24313,  5051, 39525, 12055,\n",
      "         2968,  6592,  2181, 38060, 31859, 29124, 40203, 42557, 44195, 41959,\n",
      "         4825, 36968, 11419, 25183, 29891, 40237, 37685,  8586, 26506, 19611,\n",
      "        42671, 30761, 17617,  9353,  6673, 20976, 27411, 20440,  4035, 32412,\n",
      "        28559,  1565, 19979, 17877, 22772, 20391, 28376, 23258, 17639,  2347,\n",
      "        36846, 37431, 38183,   759, 31777, 22317, 17117, 44108, 40803, 42879,\n",
      "        33353, 29396, 32355,  3653,  5298,  6774, 13422, 19618, 31714,  3029],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for when someone you trust does something that breaks your trust\n",
      "(['trust',\n",
      "  'confidence',\n",
      "  'credit',\n",
      "  'distrust',\n",
      "  'fraud',\n",
      "  'insurance',\n",
      "  'credited',\n",
      "  'cheat',\n",
      "  'pawn',\n",
      "  'pawning',\n",
      "  'security',\n",
      "  'cheated',\n",
      "  'bribing',\n",
      "  'credits',\n",
      "  'surety',\n",
      "  'bet',\n",
      "  'gamble',\n",
      "  'perfidy',\n",
      "  'misconduct',\n",
      "  'negligence',\n",
      "  'betray',\n",
      "  'forfeits',\n",
      "  'insure',\n",
      "  'humbug',\n",
      "  'fraudulent',\n",
      "  'betting',\n",
      "  'venture',\n",
      "  'prevarication',\n",
      "  'default',\n",
      "  'guarantee',\n",
      "  'slip',\n",
      "  'credential',\n",
      "  'venturing',\n",
      "  'hedge',\n",
      "  'forfeiture',\n",
      "  'gull',\n",
      "  'mislead',\n",
      "  'bets',\n",
      "  'bribery',\n",
      "  'treason',\n",
      "  'sell',\n",
      "  'discredit',\n",
      "  'mistrust',\n",
      "  'confide',\n",
      "  'error',\n",
      "  'stakes',\n",
      "  'pledge',\n",
      "  'fiduciary',\n",
      "  'barratry',\n",
      "  'delinquency',\n",
      "  'steals',\n",
      "  'danger',\n",
      "  'dependance',\n",
      "  'trusty',\n",
      "  'falsification',\n",
      "  'shame',\n",
      "  'bribe',\n",
      "  'escrow',\n",
      "  'staking',\n",
      "  'scandal',\n",
      "  'blunder',\n",
      "  'prejudiced',\n",
      "  'embezzling',\n",
      "  'trespass',\n",
      "  'steal',\n",
      "  'caution',\n",
      "  'accredit',\n",
      "  'damage',\n",
      "  'delusion',\n",
      "  'seduction',\n",
      "  'accident',\n",
      "  'misfortune',\n",
      "  'stake',\n",
      "  'flaw',\n",
      "  'blackmail',\n",
      "  'deceit',\n",
      "  'piracy',\n",
      "  'borrow',\n",
      "  'disrepute',\n",
      "  'stumble',\n",
      "  'swindling',\n",
      "  'confidential',\n",
      "  'insanity',\n",
      "  'mortgaging',\n",
      "  'pledging',\n",
      "  'judas',\n",
      "  'miscount',\n",
      "  'investment',\n",
      "  'bilk',\n",
      "  'infidelity',\n",
      "  'misuse',\n",
      "  'hazard',\n",
      "  'theft',\n",
      "  'sham',\n",
      "  'traitor',\n",
      "  'indemnity',\n",
      "  'fallacy',\n",
      "  'pledged',\n",
      "  'gulls',\n",
      "  'guile'],\n",
      " tensor([20311, 26847, 42735, 38624,  4721, 21479,  2909, 13001, 36288, 44747,\n",
      "        44038, 34030, 38603, 28446,  8063, 12423, 15901, 41753, 35327, 14458,\n",
      "        17674,  7813, 12558, 34088, 17369, 22670, 36813, 36424, 31901, 39284,\n",
      "        14689, 23784,  1374, 14940,  2232,  1337, 18708, 11641, 42494,  5002,\n",
      "        27317, 20735, 11633,  8244, 36017, 10844, 41945, 20516, 41553, 20974,\n",
      "        32053, 27656, 17043,  2512,  5998,  1612, 28370, 35393, 26929, 16044,\n",
      "        40631, 33032,  3232, 44645,  5694, 32912, 29252, 25952,  1361, 18180,\n",
      "        36429, 35444, 28236, 17784, 21692, 38884,  1667, 24852,  5627, 44864,\n",
      "         6391, 36153, 23349, 39397, 18409, 30372, 24063, 22306, 23838,  3262,\n",
      "        32435, 32466,  1724, 15497, 31755,  5689, 35945, 42774, 39531, 35889],\n",
      "       device='cuda:0'))\n",
      "\n",
      "Results for deep learning\n",
      "(['study',\n",
      "  'learning',\n",
      "  'lesson',\n",
      "  'education',\n",
      "  'research',\n",
      "  'scholarship',\n",
      "  'lore',\n",
      "  'reading',\n",
      "  'philosophy',\n",
      "  'homework',\n",
      "  'science',\n",
      "  'pedagogy',\n",
      "  'academy',\n",
      "  'analyze',\n",
      "  'read',\n",
      "  'researching',\n",
      "  'school',\n",
      "  'knowledge',\n",
      "  'studious',\n",
      "  'culture',\n",
      "  'learn',\n",
      "  'enlightenment',\n",
      "  'teach',\n",
      "  'psychology',\n",
      "  'tutorial',\n",
      "  'scholasticism',\n",
      "  'method',\n",
      "  'educate',\n",
      "  'methodology',\n",
      "  'intellect',\n",
      "  'profundity',\n",
      "  'cognition',\n",
      "  'interpretation',\n",
      "  'studied',\n",
      "  'experimenting',\n",
      "  'lecture',\n",
      "  'experience',\n",
      "  'training',\n",
      "  'student',\n",
      "  'theory',\n",
      "  'literature',\n",
      "  'instruction',\n",
      "  'analysis',\n",
      "  'examination',\n",
      "  'cet',\n",
      "  'intelligence',\n",
      "  'schooling',\n",
      "  'art',\n",
      "  'lecturing',\n",
      "  'etymology',\n",
      "  'contemplation',\n",
      "  'psychoanalysis',\n",
      "  'lexicon',\n",
      "  'exposition',\n",
      "  'recollection',\n",
      "  'scholastic',\n",
      "  'epistemology',\n",
      "  'deconstruction',\n",
      "  'recitation',\n",
      "  'seminary',\n",
      "  'intuition',\n",
      "  'empiricism',\n",
      "  'erudition',\n",
      "  'cca',\n",
      "  'inhalant',\n",
      "  'literary',\n",
      "  'ced',\n",
      "  'analyst',\n",
      "  'literacy',\n",
      "  'orientalism',\n",
      "  'ology',\n",
      "  'brainstorming',\n",
      "  'educational',\n",
      "  'scholar',\n",
      "  'educated',\n",
      "  'interpret',\n",
      "  'experiment',\n",
      "  'graduate',\n",
      "  'metaphysics',\n",
      "  'canvassing',\n",
      "  'literate',\n",
      "  'skillfulness',\n",
      "  'seminar',\n",
      "  'academe',\n",
      "  'statistician',\n",
      "  'campus',\n",
      "  'narrative',\n",
      "  'prep',\n",
      "  'encyclopedia',\n",
      "  'bookish',\n",
      "  'formalism',\n",
      "  'statistics',\n",
      "  'inquiry',\n",
      "  'university',\n",
      "  'postgraduate',\n",
      "  'curriculum',\n",
      "  'linguistics',\n",
      "  'wisdom',\n",
      "  'definition',\n",
      "  'perception'],\n",
      " tensor([ 3500, 29078,  2181, 36247, 40975, 35224,  3138, 41191, 41042,  4487,\n",
      "        32959, 20320, 25031, 33743, 11669, 18693, 17639,  8441,  9175, 24577,\n",
      "        33880, 14644, 39873,   490,  7615, 14614, 15379, 38938, 25354, 22791,\n",
      "        13896, 10494,  5624, 30520,  4035,  5440,  8832, 12186, 19574, 36984,\n",
      "        10273, 30971, 32210, 41461, 32682, 18976, 27489,  8586, 42030, 32500,\n",
      "        31746, 16747, 25677, 44449, 26939,  2525,  9741, 30097, 37905,  7595,\n",
      "         4680,  8472, 14530, 42466, 17132, 43511,  2091,  6487, 13532,  5687,\n",
      "        21089, 19970, 15763,  1930, 38902, 38484, 28944, 17675,  4722, 30205,\n",
      "        34372, 39525, 11034, 28636, 27867, 32372, 17991,  8099, 37920, 30582,\n",
      "        41303, 44528, 44266, 37240,  7371, 20995, 29531,    39, 24954, 28690],\n",
      "       device='cuda:0'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for q in queries:\n",
    "    print(f'Results for {q}')\n",
    "    pprint(getPredFromDesc(model, q, 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "049faeb3947c48ac1b8702363c1a3bc597f6c2e1e1396be70d54511d980ab606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
